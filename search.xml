<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ES深入2-搜索原理</title>
      <link href="/2024/07/02/ES%E6%B7%B1%E5%85%A52-%E6%90%9C%E7%B4%A2%E5%8E%9F%E7%90%86/"/>
      <url>/2024/07/02/ES%E6%B7%B1%E5%85%A52-%E6%90%9C%E7%B4%A2%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h2><p>ES底层基于lucene实现，而lucene全文索引使用到的核心技术就是倒排索引。倒排索引（Inverted Index）是一种广泛应用于全文检索系统中的数据结构，如搜索引擎、数据库等。它的主要目的是为了高效地支持关键词搜索，即通过一个关键词快速找到包含该关键词的所有文档。倒排索引的基本原理是将文档中出现的关键词作为索引项，每个索引项记录了该关键词在哪些文档中出现过，以及在这些文档中的具体位置。</p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><ol><li><p><strong>分词处理</strong>：在构建倒排索引前，首先需要对文档进行分词处理，即将文档拆分为单个词汇或短语。这个过程称为分词（Tokenization）。</p></li><li><p><strong>创建索引项</strong>：对于每个词汇，创建一个索引项，该索引项记录了该词汇所出现的所有文档的标识符（通常是文档ID）以及在文档中的位置信息。</p></li><li><p><strong>数据结构</strong>：倒排索引通常使用哈希表、字典树、B树等高效数据结构来存储索引项，以便快速查询。每个关键词对应一个列表或集合，其中包含该词出现的所有文档ID。</p></li></ol><h3 id="样例"><a href="#样例" class="headerlink" title="样例"></a>样例</h3><p>假设我们有两个文档：</p><ul><li>文档1（ID&#x3D;1）：“The quick brown fox jumps over the lazy dog.”</li><li>文档2（ID&#x3D;2）：“A quick brown dog jumps over the fence.”</li></ul><p>经过分词处理，我们得到以下词汇集合：</p><ul><li>“the”, “quick”, “brown”, “fox”, “jumps”, “over”, “lazy”, “dog”, “a”, “fence”</li></ul><p>接下来，构建倒排索引：</p><ul><li>“the”: [1, 2]</li><li>“quick”: [1, 2]</li><li>“brown”: [1, 2]</li><li>“fox”: [1]</li><li>“jumps”: [1, 2]</li><li>“over”: [1, 2]</li><li>“lazy”: [1]</li><li>“dog”: [1, 2]</li><li>“a”: [2]</li><li>“fence”: [2]</li></ul><p>在这个例子中，每个关键词都指向一个文档ID列表，表明了该词出现在哪些文档中。例如，关键词”quick”对应的列表是[1, 2]，意味着”quick”出现在文档1和文档2中。</p><h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>当用户输入查询关键词时，搜索引擎只需直接在倒排索引中查找该关键词，即可立即获取包含该关键词的所有文档ID，从而大大加快了搜索的速度。此外，通过进一步分析这些文档ID集合（如计算交集、并集），搜索引擎还能支持更复杂的查询需求，如布尔查询、短语查询等。</p><h2 id="分词与标准化"><a href="#分词与标准化" class="headerlink" title="分词与标准化"></a>分词与标准化</h2><h3 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h3><p>分词（Tokenization）是将文本数据切分成更小的有意义单位（称为tokens或词元）的过程，这对于全文搜索至关重要。标准化（Normalization）则是将这些词元转换为标准形式，以提高搜索的一致性和准确性。</p><ul><li>比如：可以按照空格分割，将 “the quick brown fox jumps” 切分为[“the”, “quick”, “brown”, “fox”, “jumps”]；</li><li>也可以按照语言的词汇语法分割，将 “一只白色的狐狸跳进草丛” 切分为[“一”, “只”, “白色”, “的”, “狐狸”, “跳进”, “草丛”]</li></ul><h3 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h3><p>标准化是将分词后的词元转换成统一的格式，以便于比较和匹配。常见的标准化操作包括：</p><ul><li><p><strong>小写转换</strong>：将所有词元转换为小写，确保搜索时大小写不敏感。比如：”Fox”转换为”fox”；</p></li><li><p><strong>词干提取</strong>：通过去除词缀（如复数形式、时态变化等），将词元还原为其词根形式，有助于匹配变体形式的词汇。比如：”foxes” 转换为 “fox”；</p></li><li><p><strong>去除停用词</strong>：从词元流中移除常见但无实际意义的词汇，如“is”、“the”等，以减少噪音并提高搜索效率；</p></li><li><p><strong>同义词处理</strong>：将同义词或近义词映射到同一个标准化的词形，增强查询的召回率。</p></li></ul><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>假设我们有一个句子：“Running quickly in the park.”，处理流程可能如下：</p><ol><li><p><strong>分词</strong>：句子被分割成 <code>[&quot;running&quot;, &quot;quickly&quot;, &quot;in&quot;, &quot;the&quot;, &quot;park&quot;]</code>，同时转换为小写。</p></li><li><p><strong>标准化</strong>：</p><ul><li><strong>去除停用词</strong>：移除 “in” 和 “the”，剩下 <code>[&quot;running&quot;, &quot;quickly&quot;, &quot;park&quot;]</code>。</li><li><strong>词干提取</strong>：如果启用了，可能会将 “running” 转换为 “run”，最终得到 <code>[&quot;run&quot;, &quot;quickly&quot;, &quot;park&quot;]</code>。</li></ul></li></ol><p>通过这样的分词和标准化流程，搜索引擎能够有效地索引和检索文档，提供准确的搜索结果。</p><h2 id="ES分析器（Analyzer）"><a href="#ES分析器（Analyzer）" class="headerlink" title="ES分析器（Analyzer）"></a>ES分析器（Analyzer）</h2><p>Elasticsearch（ES）的分析器（Analyzer）正是基于上文的分词与标准化原理。分析器（Analyzer）是负责文本分析处理的关键组件，主要由以下三个部分组成：</p><ol><li><p><strong>字符过滤器（Character Filters）</strong>:<br>字符过滤器位于分析流程的起始端，它们在文本被分词之前对原始文本进行处理。字符过滤器可以用来删除或转换不需要的字符，比如HTML标签、XML实体、表情符号等，以便于后续的分词步骤更加准确。一个分析器可以有零个或多个字符过滤器。</p></li><li><p><strong>分词器（Tokenizer）</strong>:<br>分词器是分析器的核心，负责将经过字符过滤器处理的文本切分成一个个基本的文本单位，称为词元（tokens）。分词器根据预设的规则或算法来决定在哪里分割文本，不同的分词器适用于不同的语言特性和需求，如标准分词器（Standard Analyzer）、IK分词器（针对中文）等。一个分析器只能包含一个分词器。</p></li><li><p><strong>词元过滤器（Token Filters）</strong>:<br>词元过滤器在分词之后运行，对生成的词元序列进行进一步的加工。它们可以执行诸如转换词元大小写、去除停用词、词干提取（如将“running”变为“run”）、同义词替换等多种操作，以优化索引过程或提升搜索结果的相关性。</p></li></ol><p>这三个组成部分共同作用，使Elasticsearch能够高效地处理和索引文本数据，同时也支持用户根据具体需求自定义分析器，以适应不同的搜索场景和语言特性。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li>通义千问</li></ul>]]></content>
      
      
      <categories>
          
          <category> ES </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES </tag>
            
            <tag> 搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2024/07/02/ES%E5%AD%A6%E4%B9%A05-%E6%9F%A5%E8%AF%A2/"/>
      <url>/2024/07/02/ES%E5%AD%A6%E4%B9%A05-%E6%9F%A5%E8%AF%A2/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>ES学习4-分页</title>
      <link href="/2024/06/18/ES%E5%AD%A6%E4%B9%A04-%E5%88%86%E9%A1%B5/"/>
      <url>/2024/06/18/ES%E5%AD%A6%E4%B9%A04-%E5%88%86%E9%A1%B5/</url>
      
        <content type="html"><![CDATA[<p>业务需求中我们经常会遇到需要分页展示搜索结果的情况。ES支持多种分页查询方式，包括from+size、scroll、search after等三种方式。</p><p>再开始详细介绍前，我们先初始化一个索引表：</p><pre><code class="sql">PUT books&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;id&quot;: &#123;        &quot;type&quot;: &quot;integer&quot;      &#125;,      &quot;name&quot;: &#123;        &quot;type&quot;: &quot;text&quot;      &#125;,      &quot;author&quot;: &#123;        &quot;type&quot;: &quot;text&quot;      &#125;,      &quot;price&quot;: &#123;        &quot;type&quot;: &quot;float&quot;      &#125;    &#125;  &#125;&#125;POST _bulk&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;books&quot;&#125;&#125;&#123;&quot;id&quot;: 1, &quot;name&quot;: &quot;Java Core Technology&quot;, &quot;author&quot;: &quot;Cay S. Horstmann&quot;, &quot;price&quot;: 88.20&#125;&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;books&quot;&#125;&#125;&#123;&quot;id&quot;: 2, &quot;name&quot;: &quot;The Beauty Of Math&quot;, &quot;author&quot;: &quot;Wujun&quot;, &quot;price&quot;: 50.50&#125;&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;books&quot;&#125;&#125;&#123;&quot;id&quot;: 3, &quot;name&quot;: &quot;Shakespeare: Romeo and Juliet&quot;, &quot;author&quot;: &quot;William Shakespeare&quot;, &quot;price&quot;: 100.00&#125;&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;books&quot;&#125;&#125;&#123;&quot;id&quot;: 4, &quot;name&quot;: &quot;Pride and Prejudice&quot;, &quot;author&quot;: &quot;Austen&quot;, &quot;price&quot;: 32.30&#125;&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;books&quot;&#125;&#125;&#123;&quot;id&quot;: 5, &quot;name&quot;: &quot;Animal Farm&quot;, &quot;author&quot;: &quot;Orwell&quot;, &quot;price&quot;: 93.00&#125;&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;books&quot;&#125;&#125;&#123;&quot;id&quot;: 6, &quot;name&quot;: &quot;Great Expectations&quot;, &quot;author&quot;: &quot;Dickens&quot;, &quot;price&quot;: 93.00&#125;&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;books&quot;&#125;&#125;&#123;&quot;id&quot;: 7, &quot;name&quot;: &quot;Lord of the Flies&quot;, &quot;author&quot;: &quot;Golding&quot;, &quot;price&quot;: 83.00&#125;&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;books&quot;&#125;&#125;&#123;&quot;id&quot;: 8, &quot;name&quot;: &quot;The Good Earth&quot;, &quot;author&quot;: &quot;Buck&quot;, &quot;price&quot;: 93.00&#125;&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;books&quot;&#125;&#125;&#123;&quot;id&quot;: 9, &quot;name&quot;: &quot;A Connecticut Yankee in King Arthur&#39;s Court&quot;, &quot;author&quot;: &quot;Twain&quot;, &quot;price&quot;: 22.00&#125;&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;books&quot;&#125;&#125;&#123;&quot;id&quot;: 10, &quot;name&quot;: &quot;Oliver Twist&quot;, &quot;author&quot;: &quot;Dickens&quot;, &quot;price&quot;: 212.00&#125;&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;books&quot;&#125;&#125;&#123;&quot;id&quot;: 11, &quot;name&quot;: &quot;Brave New World&quot;, &quot;author&quot;: &quot;Huxley&quot;, &quot;price&quot;: 42.00&#125;&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;books&quot;&#125;&#125;&#123;&quot;id&quot;: 12, &quot;name&quot;: &quot;the Canterbury Tales&quot;, &quot;author&quot;: &quot;Chaucer&quot;, &quot;price&quot;: 24.00&#125;&#123;&quot;index&quot;: &#123;&quot;_index&quot;: &quot;books&quot;&#125;&#125;&#123;&quot;id&quot;: 13, &quot;name&quot;: &quot;the Old Man and the Sea&quot;, &quot;author&quot;: &quot;Hemingway&quot;, &quot;price&quot;: 66.00&#125;</code></pre><h2 id="From-Size"><a href="#From-Size" class="headerlink" title="From+Size"></a>From+Size</h2><p>ES的search API支持指定from、size参数实现翻页功能。这种分页方式与MySQL的from+size方式非常类似。例如:</p><pre><code class="sql">select * from table_books order by price desc limit N size M</code></pre><p>MySQL里为了实现该查询需要顺序先找出N条数据并丢弃，然后再取M条数据。当页数N越大时候，性能越差。</p><p>而在ES中实现from+size分页查询的样例如下：</p><pre><code class="sql">GET /books/_search&#123; &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;, &quot;sort&quot;: [   &#123;     &quot;price&quot;: &#123;       &quot;order&quot;: &quot;desc&quot;     &#125;   &#125; ],  &quot;from&quot;: 0, &quot;size&quot;: 10&#125;</code></pre><p>同样的，ES的这种分页方式通常会将请求广播到索引表的每一个分片，待每个分片都检索出（N+M条）数据后再汇总数据再进行翻页检索。因此，这种深翻页也存在非常大的性能问题。默认情况下，ES通过index.max_result_window参数限制最多只能翻页10000个文档。</p><h2 id="Search-After"><a href="#Search-After" class="headerlink" title="Search After"></a>Search After</h2><p>Search After方式支持使用前一页返回的排序值来检索下一页数据。与MySQL的下边语句类似：</p><pre><code class="sql">select * from table_books where id &gt; $&#123;last_id&#125; order by id desc limit 10</code></pre><p>ES在每个查询返回结果中的每一个文档都会携带一个索引值，可用于下一页的查询：</p><pre><code class="sql">GET /books/_search&#123;  &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;,  &quot;sort&quot;: [    &#123;&quot;price&quot;: &quot;desc&quot;&#125;,    &#123;&quot;id&quot;: &quot;desc&quot;&#125;        ],  &quot;size&quot;: 2&#125;// response -&gt; &#123;  &quot;took&quot;: 0,  &quot;timed_out&quot;: false,  &quot;_shards&quot;: &#123;    &quot;total&quot;: 1,    &quot;successful&quot;: 1,    &quot;skipped&quot;: 0,    &quot;failed&quot;: 0  &#125;,  &quot;hits&quot;: &#123;    &quot;total&quot;: &#123;      &quot;value&quot;: 13,      &quot;relation&quot;: &quot;eq&quot;    &#125;,    &quot;max_score&quot;: null,    &quot;hits&quot;: [      &#123;        &quot;_index&quot;: &quot;books&quot;,        &quot;_id&quot;: &quot;ce2kI5ABzT8j3ZAE2smo&quot;,        &quot;_score&quot;: null,        &quot;_source&quot;: &#123;          &quot;id&quot;: 10,          &quot;name&quot;: &quot;Oliver Twist&quot;,          &quot;author&quot;: &quot;Dickens&quot;,          &quot;price&quot;: 212        &#125;,        &quot;sort&quot;: [          212,          10        ]      &#125;,      &#123;        &quot;_index&quot;: &quot;books&quot;,        &quot;_id&quot;: &quot;au2kI5ABzT8j3ZAE2smo&quot;,        &quot;_score&quot;: null,        &quot;_source&quot;: &#123;          &quot;id&quot;: 3,          &quot;name&quot;: &quot;Shakespeare: Romeo and Juliet&quot;,          &quot;author&quot;: &quot;William Shakespeare&quot;,          &quot;price&quot;: 100        &#125;,        &quot;sort&quot;: [          100,          3        ]      &#125;    ]  &#125;&#125;</code></pre><p>那么查询下一页则可以使用上一页的索引值[100, “3”]，如下：</p><pre><code class="sql">GET /books/_search&#123;  &quot;query&quot;: &#123;    &quot;match_all&quot;: &#123;&#125;  &#125;,  &quot;sort&quot;: [    &#123;&quot;price&quot;: &quot;desc&quot;&#125;,    &#123;&quot;id&quot;: &quot;asc&quot;&#125;  ],  &quot;search_after&quot;: [    100,    &quot;3&quot;  ],  &quot;size&quot;: 2&#125;// response -&gt; &#123;  &quot;took&quot;: 0,  &quot;timed_out&quot;: false,  &quot;_shards&quot;: &#123;    &quot;total&quot;: 1,    &quot;successful&quot;: 1,    &quot;skipped&quot;: 0,    &quot;failed&quot;: 0  &#125;,  &quot;hits&quot;: &#123;    &quot;total&quot;: &#123;      &quot;value&quot;: 13,      &quot;relation&quot;: &quot;eq&quot;    &#125;,    &quot;max_score&quot;: null,    &quot;hits&quot;: [      &#123;        &quot;_index&quot;: &quot;books&quot;,        &quot;_id&quot;: &quot;bO2kI5ABzT8j3ZAE2smo&quot;,        &quot;_score&quot;: null,        &quot;_source&quot;: &#123;          &quot;id&quot;: 5,          &quot;name&quot;: &quot;Animal Farm&quot;,          &quot;author&quot;: &quot;Orwell&quot;,          &quot;price&quot;: 93        &#125;,        &quot;sort&quot;: [          93,          5        ]      &#125;,      &#123;        &quot;_index&quot;: &quot;books&quot;,        &quot;_id&quot;: &quot;be2kI5ABzT8j3ZAE2smo&quot;,        &quot;_score&quot;: null,        &quot;_source&quot;: &#123;          &quot;id&quot;: 6,          &quot;name&quot;: &quot;Great Expectations&quot;,          &quot;author&quot;: &quot;Dickens&quot;,          &quot;price&quot;: 93        &#125;,        &quot;sort&quot;: [          93,          6        ]      &#125;    ]  &#125;&#125;</code></pre><p>上边的排序请求中为了找到价格高到低的书籍，使用了两个字段[{“price”: “desc”},  {“id”: “desc”}]进行排序。这里为何还要使用id字段？原因是为确保相同价格的书籍在分页排序时候不会重复、丢失或者顺序不可控，这里需要额外增加一个唯一键以保障顺序。</p><p>这种方式不存在深翻页问题，但无法支持随机跳页。另外当数据被变更并刷新的情况下，页面的返回结果并不是稳定的，会出现重复数据的情况。为了避免这种情况，可以使用ES 7.10版本后提供的point in time (PIT)来构建索引数据的轻量级视图，在该视图下ES会保障数据的稳定性，使用如下：</p><pre><code class="sql">-- 启动PIT视图POST /books/_pit?keep_alive=5m-- reponse:&#123;  &quot;id&quot;: &quot;gbuKBAEFYm9va3MWNzZ6WmNZMHBUWTZtQWJqWDVCVDFqZwAWdlpSWmRScFBUdHlqVXF2YTZnc0x6ZwAAAAAAAAAsDBZlcjFaMjUxSVQ4R1BrM2Q2a2R2UWVRAAEWNzZ6WmNZMHBUWTZtQWJqWDVCVDFqZwAA&quot;&#125;-- 查询第一页GET _search&#123;  &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;,  &quot;sort&quot;: [    &#123;&quot;price&quot;: &quot;desc&quot;&#125;,    &#123;&quot;_shard_doc&quot;: &quot;desc&quot;&#125;  ],  &quot;size&quot;: 2,  &quot;pit&quot;: &#123;    &quot;id&quot;: &quot;gbuKBAEFYm9va3MWNzZ6WmNZMHBUWTZtQWJqWDVCVDFqZwAWdlpSWmRScFBUdHlqVXF2YTZnc0x6ZwAAAAAAAAAsDBZlcjFaMjUxSVQ4R1BrM2Q2a2R2UWVRAAEWNzZ6WmNZMHBUWTZtQWJqWDVCVDFqZwAA&quot;,    &quot;keep_alive&quot;: &quot;5m&quot;  &#125;&#125;-- response:&#123;  &quot;pit_id&quot;: &quot;gbuKBAEFYm9va3MWNzZ6WmNZMHBUWTZtQWJqWDVCVDFqZwAWdlpSWmRScFBUdHlqVXF2YTZnc0x6ZwAAAAAAAAAsDBZlcjFaMjUxSVQ4R1BrM2Q2a2R2UWVRAAEWNzZ6WmNZMHBUWTZtQWJqWDVCVDFqZwAA&quot;,  &quot;took&quot;: 1,  &quot;timed_out&quot;: false,  &quot;_shards&quot;: &#123;    &quot;total&quot;: 1,    &quot;successful&quot;: 1,    &quot;skipped&quot;: 0,    &quot;failed&quot;: 0  &#125;,  &quot;hits&quot;: &#123;    &quot;total&quot;: &#123;      &quot;value&quot;: 13,      &quot;relation&quot;: &quot;eq&quot;    &#125;,    &quot;max_score&quot;: null,    &quot;hits&quot;: [      &#123;        &quot;_index&quot;: &quot;books&quot;,        &quot;_id&quot;: &quot;Bl7ZKJAB2vthpLOOy9ge&quot;,        &quot;_score&quot;: null,        &quot;_source&quot;: &#123;          &quot;id&quot;: 10,          &quot;name&quot;: &quot;Oliver Twist&quot;,          &quot;author&quot;: &quot;Dickens&quot;,          &quot;price&quot;: 212        &#125;,        &quot;sort&quot;: [          212,          9        ]      &#125;,      &#123;        &quot;_index&quot;: &quot;books&quot;,        &quot;_id&quot;: &quot;_17ZKJAB2vthpLOOy9ce&quot;,        &quot;_score&quot;: null,        &quot;_source&quot;: &#123;          &quot;id&quot;: 3,          &quot;name&quot;: &quot;Shakespeare: Romeo and Juliet&quot;,          &quot;author&quot;: &quot;William Shakespeare&quot;,          &quot;price&quot;: 100        &#125;,        &quot;sort&quot;: [          100,          2        ]      &#125;    ]  &#125;&#125;--翻下一页 GET _search&#123;  &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;,  &quot;sort&quot;: [    &#123;&quot;price&quot;: &quot;desc&quot;&#125;,    &#123;&quot;_shard_doc&quot;: &quot;desc&quot;&#125;  ],  &quot;size&quot;: 2,  &quot;pit&quot;: &#123;    &quot;id&quot;: &quot;gbuKBAEFYm9va3MWNzZ6WmNZMHBUWTZtQWJqWDVCVDFqZwAWdlpSWmRScFBUdHlqVXF2YTZnc0x6ZwAAAAAAAAAsDBZlcjFaMjUxSVQ4R1BrM2Q2a2R2UWVRAAEWNzZ6WmNZMHBUWTZtQWJqWDVCVDFqZwAA&quot;,    &quot;keep_alive&quot;: &quot;5m&quot;  &#125;,  &quot;search_after&quot;: [      100,      2    ]&#125;</code></pre><p>从上边的例子可以看到，当使用了PIT后，返回结果里的排序值除了包含price，还会多出一个_shard_doc值。例如[100, 2]。这个值是由分片索引和lucene内部文档Id组合而来。ES会确保在该PIT中每一个文档的_shard_doc都是唯一的。另外，你也可以显式指定 {“_shard_doc”: “desc”}来控制返回文档的顺序。</p><h2 id="Scroll"><a href="#Scroll" class="headerlink" title="Scroll"></a>Scroll</h2><p>除了上述两种方法以外，ES还支持Scroll命令分页。Scroll命令可用于非实时地分页检索大量数据。该命令是通过开始执行时构建一个快照以屏蔽掉所有数据变更，从而实现稳定的翻页。但这也决定了使用Scroll命令获取的翻页数据并不是实时的。另外快照需要保持所有旧数据不被删除，相比之下PIT轻量级视图的性能开销要更加小。因此当然在最新的ES版本中，已经建议使用Search After代替Scroll命令。</p><p>下边简单了解下Scroll命令：</p><pre><code class="sql">-- 首页查询POST /books/_search?scroll=5m&#123;  &quot;query&quot;: &#123;&quot;match_all&quot;: &#123;&#125;&#125;,  &quot;sort&quot;: [&#123;&quot;price&quot;:&quot;desc&quot;&#125;],  &quot;size&quot;: 2&#125;-- response&#123;  &quot;_scroll_id&quot;: &quot;FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFldkampjR3VmUzdDXzRTcXBtckQ3bEEAAAAAAAAKSRZ2WlJaZFJwUFR0eWpVcXZhNmdzTHpn&quot;,  &quot;took&quot;: 1,  &quot;timed_out&quot;: false,  &quot;_shards&quot;: &#123;    &quot;total&quot;: 1,    &quot;successful&quot;: 1,    &quot;skipped&quot;: 0,    &quot;failed&quot;: 0  &#125;,  &quot;hits&quot;: &#123;    &quot;total&quot;: &#123;      &quot;value&quot;: 13,      &quot;relation&quot;: &quot;eq&quot;    &#125;,    &quot;max_score&quot;: null,    &quot;hits&quot;: [      &#123;        &quot;_index&quot;: &quot;books&quot;,        &quot;_id&quot;: &quot;Bl7ZKJAB2vthpLOOy9ge&quot;,        &quot;_score&quot;: null,        &quot;_source&quot;: &#123;          &quot;id&quot;: 10,          &quot;name&quot;: &quot;Oliver Twist&quot;,          &quot;author&quot;: &quot;Dickens&quot;,          &quot;price&quot;: 212        &#125;,        &quot;sort&quot;: [          212        ]      &#125;,      &#123;        &quot;_index&quot;: &quot;books&quot;,        &quot;_id&quot;: &quot;_17ZKJAB2vthpLOOy9ce&quot;,        &quot;_score&quot;: null,        &quot;_source&quot;: &#123;          &quot;id&quot;: 3,          &quot;name&quot;: &quot;Shakespeare: Romeo and Juliet&quot;,          &quot;author&quot;: &quot;William Shakespeare&quot;,          &quot;price&quot;: 100        &#125;,        &quot;sort&quot;: [          100        ]      &#125;    ]  &#125;&#125;-- 下一页POST _search/scroll&#123;  &quot;scroll&quot;: &quot;5m&quot;,  &quot;scroll_id&quot;: &quot;FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFldkampjR3VmUzdDXzRTcXBtckQ3bEEAAAAAAAAJExZ2WlJaZFJwUFR0eWpVcXZhNmdzTHpn&quot;&#125;-- 再下一页POST _search/scroll&#123;  &quot;scroll&quot;: &quot;5m&quot;,  &quot;scroll_id&quot;: &quot;FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFldkampjR3VmUzdDXzRTcXBtckQ3bEEAAAAAAAAJExZ2WlJaZFJwUFR0eWpVcXZhNmdzTHpn&quot;&#125;-- ...</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table><thead><tr><th>分页方式</th><th>优点</th><th>缺点</th><th>适用场景</th></tr></thead><tbody><tr><td>from+size</td><td>简单直观容易理解；<br>小数据集下表现良好；<br>支持跳页查询；</td><td>大数据集下性能较差；<br>有深度分页限制(默认10000)</td><td>需要支持跳页但没有深翻页的情景</td></tr><tr><td>scroll</td><td>使用快照保障数据的稳定；<br>没有深翻页性能问题；<br>适用于大量数据处理情景；</td><td>不支持实时查询；<br>快照占用较多性能，用完需要及时删除；</td><td>适用于导出大量数据、离线批处理任务等场景</td></tr><tr><td>search after</td><td>没有深翻页性能问题；<br></td><td>数据不稳定；<br> 需要正确选择排序ID避免重复数据问题；</td><td>适用于实时性要求高且存在深翻页的场景，如无限滚动列表</td></tr><tr><td>search after (PIT)</td><td>使用PIT轻量级视图保障数据稳定性；<br >没有深翻页性能问题；<br></td><td>数据稳定；需要正确选择排序ID避免重复数据问题；</td><td>适用于不要求实时性并存在深翻页的场景，如无限滚动列表</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> ES </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES </tag>
            
            <tag> 搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ES深入1-整体结构</title>
      <link href="/2024/06/18/ES%E6%B7%B1%E5%85%A51-%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84%20copy/"/>
      <url>/2024/06/18/ES%E6%B7%B1%E5%85%A51-%E6%95%B4%E4%BD%93%E7%BB%93%E6%9E%84%20copy/</url>
      
        <content type="html"><![CDATA[<h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>掌握了ES的基本用法后，我们来深入了解一下ES的整体架构。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FES%2Fes%E6%9E%B6%E6%9E%84%E8%8D%89%E5%9B%BE.png" alt="es架构草图.png"></p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FES%2Fes-th-2-3.png" alt="es-th-2-3.png"></p><ul><li><p>ES集群模式下，有多个节点（node）组成一个完整集群。每个节点可以承担不同的角色从而构成不同的节点，包括但不限于：</p><ul><li>主节点（Master Node）<ul><li>负责集群的管理和协调工作，比如创建或删除索引、跟踪集群中节点的状态、分配碎片（shards）等；</li><li>主节点并不直接参与文档的索引或搜索操作，以减轻其负担；</li><li>通常建议设置较少数量的专用主节点，以确保集群的稳定性；</li></ul></li><li>数据节点（Data Node）:<ul><li>存储数据片段（shards）并参与文档的索引和搜索操作。</li><li>数据节点是集群中最耗费资源的部分，因为它们需要处理数据的存储和检索。</li><li>根据集群规模和硬件配置，可以有多台数据节点。</li></ul></li><li>协调节点（Coordinating Node）<ul><li>虽然不是一个官方的节点角色，但在实践中，可以配置节点不承担数据存储或主节点职责，专门负责接收客户端请求、协调搜索和索引操作。</li><li>这有助于分散主节点和数据节点的压力，提高集群的整体响应速度。</li></ul></li><li>专用主节点（Dedicated Master-Eligible Node）:<ul><li>仅具有主节点资格，不承担数据存储任务，专注于集群管理。</li><li>用于避免主节点因其他任务过载。</li></ul></li><li>冻结节点（Frozen Node）:<ul><li>专门用于存储冻结索引，这些索引的数据访问频率较低，但需要长期保存。</li></ul></li></ul></li><li><p>数据节点（Data Node负责持有数据分片（包括主分片和副本分片），参与文档的索引、搜索、更新以及删除等数据处理操作。当索引数据时，Elasticsearch 会根据配置的分片策略将数据分布在网络中的各个数据节点上，实现数据的水平扩展和负载均衡。此外，数据节点还负责维护分片的状态，确保数据的完整性和高可用性；</p></li><li><p>每一个Index由多个分片构成，这些分片会分散在不同数据节点上；</p></li><li><p>每一个分片是一个最小级别的工作单元，本质上是一个功能完备且独立的Luncene 索引实例。每个ES索引可以被分成多个分片，每个分片都包含索引中部分数据的文档集合。分片有两种类型：主分片（Primary Shards） 和 副本分片（Replica Shards）。主分片是索引数据存储的基本单位，而副本分片则是主分片的拷贝，用于提高数据的可用性和读取性能；</p></li><li><p>段（Segments）在分片内部，数据被组织成多个段。每个段都是一个不可变的倒排索引结构，包含了文档的一部分。随着时间推移，新的文档被写入新的段中，旧的段可能被合并以优化查询性能和磁盘使用。</p></li></ul><h2 id="索引流程"><a href="#索引流程" class="headerlink" title="索引流程"></a>索引流程</h2><p>Elasticsearch（ES）文档插入到索引的过程大致遵循以下步骤：</p><ul><li><strong>客户端请求</strong>：首先，客户端（比如一个应用程序或者API请求）向Elasticsearch集群发送一个HTTP PUT或POST请求，请求中包含要插入文档的具体信息，比如文档的JSON内容、目标索引名称以及可选的ID。</li><li><strong>节点接收</strong>：请求被发送到集群中的任何节点，这个节点被称为协调节点。协调节点负责接收请求并进行后续的路由操作，而不直接处理数据的存储或检索。</li><li>路由决策**：协调节点根据文档ID和索引的配置计算出该文档应存储在哪个主分片上。这个过程基于一种散列算法，确保相同ID的文档总是被路由到同一个分片上。<br>转发请求：协调节点将请求转发给存储目标主分片的数据节点。如果请求中包含写操作（如索引或更新），则直接转发到该主分片所在节点。</li><li><strong>文档处理</strong>：<ul><li><strong>分析</strong>：数据节点接收到请求后，首先对文档内容进行分析，这包括分词（tokenization）、去除停用词、转换为小写等，以便创建适合搜索的结构。</li><li><strong>索引文档</strong>：经过分析后，文档被序列化为Lucene的内部格式，并添加到相应的主分片中。这个过程涉及到倒排索引的构建或更新，确保文档可以被快速检索。</li></ul></li><li><strong>事务日志记录</strong>：在文档被实际写入到内存或磁盘之前，Elasticsearch会先将其操作记录在事务日志（Translog）中，这是为了确保数据的持久性。</li><li><strong>刷新（Refresh）</strong>：Elasticsearch有一个可配置的刷新周期（默认为1秒），在这个周期内，内存中的文档会被刷新到一个新的Lucene段中，并打开供搜索。这意味着文档在被索引后很快（几乎是实时的）就能被搜索到，但这个过程比直接写入硬盘更快，因为段还在内存中。</li><li><strong>副本同步</strong>：一旦文档被成功写入主分片，协调节点还会确保副本分片也得到更新，以维持索引的高可用性。这个过程是异步的，可以配置副本数量来增强数据冗余。</li><li><strong>确认响应</strong>：一旦主分片和所有副本分片（根据配置的副本确认级别）都确认了写入操作，协调节点会向客户端发送一个成功的响应，表明文档已被成功索引。</li><li><strong>段合并</strong>：在后台，Elasticsearch会定期进行段合并，将小的段合并成更大的段，以优化存储和查询性能。这个过程发生在索引和搜索操作之外，不会影响正常的读写操作。</li></ul><h2 id="搜索流程"><a href="#搜索流程" class="headerlink" title="搜索流程"></a>搜索流程</h2><p>在Elasticsearch (ES) 集群中执行一次搜索请求的大致过程如下：</p><ol><li><p><strong>请求接收</strong>：</p><ul><li>客户端发送搜索请求到Elasticsearch集群中的任意一个节点，这个节点称为**协调节点(coordinating node)**。</li></ul></li><li><p><strong>解析与路由</strong>：</p><ul><li>协调节点解析搜索请求，包括查询条件、过滤器、排序方式等，并根据索引信息确定哪些分片可能包含相关数据。在ES中，数据被分割成多个分片(shards)，每个分片可以有零个或多个副本(replicas)。协调节点会根据分片信息决定需要向哪些分片发起搜索请求。</li></ul></li><li><p><strong>查询转发</strong>：</p><ul><li>协调节点将搜索请求转发给持有相关数据分片的节点。这一步骤会根据网络往返次数最小化或非最小化策略进行。如果是最小化策略，协调节点尝试减少与各个分片的交互次数，可能一次性向多个节点发送请求；非最小化策略则可能涉及更多次的交互。</li></ul></li><li><p><strong>分片级别搜索</strong>：</p><ul><li>每个持有相关分片的节点在其本地分片上执行搜索操作，生成该分片上的匹配结果集。这一步可能包括倒排索引的查询、文档评分、排序等操作。</li></ul></li><li><p><strong>结果汇总</strong>：</p><ul><li>各个分片节点将搜索结果返回给协调节点。协调节点对这些结果进行汇总处理，可能包括去重、合并、排序以及根据请求参数执行后续的聚合操作。</li></ul></li><li><p><strong>结果剪裁与排序</strong>：</p><ul><li>协调节点根据请求中的分页参数、排序规则等对汇总的结果进行剪裁和排序，以准备最终返回给客户端的数据集。</li></ul></li><li><p><strong>响应构建与返回</strong>：</p><ul><li>协调节点将最终的搜索结果封装成响应体，并通过HTTP响应的形式返回给客户端。</li></ul></li></ol><p>整个过程中，Elasticsearch利用其分布式特性并行处理请求，提高了搜索效率。此外，Elasticsearch还提供了丰富的API和机制来优化搜索性能，如预处理节点(ingest node)可以对数据进行预处理，而复制机制确保了数据的高可用性。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://pdai.tech/md/db/nosql-es/elasticsearch-y-th-2.html">https://pdai.tech/md/db/nosql-es/elasticsearch-y-th-2.html</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> ES </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES </tag>
            
            <tag> 搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ES学习3-文档管理</title>
      <link href="/2024/06/10/ES%E5%AD%A6%E4%B9%A03-%E6%96%87%E6%A1%A3%E7%AE%A1%E7%90%86/"/>
      <url>/2024/06/10/ES%E5%AD%A6%E4%B9%A03-%E6%96%87%E6%A1%A3%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>上一节我们了解了ES的索引管理。当我们建立好索引后，就可以往索引中添加文档记录，也可以更新、删除索引中的文档记录。这一节我们来快速了解如何管理ES中的文档。</p><p>先初始化一个索引，比如维护员工信息的索引employee：</p><pre><code class="go">PUT /employee&#123;  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;name&quot;: &#123;        &quot;type&quot;: &quot;text&quot;      &#125;,      &quot;age&quot;: &#123;        &quot;type&quot;: &quot;integer&quot;      &#125;,      &quot;salary&quot;: &#123;        &quot;type&quot;: &quot;integer&quot;      &#125;,      &quot;address&quot;: &#123;        &quot;type&quot;: &quot;text&quot;      &#125;    &#125;  &#125;&#125;</code></pre><h2 id="索引文档（Index）"><a href="#索引文档（Index）" class="headerlink" title="索引文档（Index）"></a>索引文档（Index）</h2><p>将文档添加进索引的语法有多种：</p><pre><code class="go">PUT /&lt;target&gt;/_doc/&lt;_id&gt;   // 指定id插入(或更新)POST /&lt;target&gt;/_doc/      // 不指定id插入(或更新)PUT /&lt;target&gt;/_create/&lt;_id&gt;  // 当id不存在时候插入POST /&lt;target&gt;/_create/&lt;_id&gt; // 当id不存在时候插入</code></pre><p>例如：</p><pre><code class="go">PUT /employee/_doc/1&#123;  &quot;name&quot;:&quot;duval&quot;,  &quot;age&quot;: 30,  &quot;salary&quot;:100000,  &quot;address&quot;: &quot;北京市朝阳区朝阳公园南路十九号&quot;&#125;</code></pre><h2 id="查询文档"><a href="#查询文档" class="headerlink" title="查询文档"></a>查询文档</h2><p>将上述id&#x3D;1的文档查询出来：</p><pre><code class="go">GET /employee/_doc/1// response -&gt; &#123;  &quot;_index&quot; : &quot;employee&quot;,  &quot;_type&quot; : &quot;_doc&quot;,  &quot;_id&quot; : &quot;1&quot;,  &quot;_version&quot; : 1,  &quot;_seq_no&quot; : 0,  &quot;_primary_term&quot; : 1,  &quot;found&quot; : true,  &quot;_source&quot; : &#123;    &quot;name&quot; : &quot;duval&quot;,    &quot;age&quot; : 30,    &quot;salary&quot; : 100000,    &quot;address&quot; : &quot;北京市朝阳区朝阳公园南路十九号&quot;  &#125;&#125;</code></pre><h2 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h2><p>将上述id&#x3D;1的文档删除：</p><pre><code class="go">DELETE /employee/_doc/1</code></pre><p>除了根据id来删除，也可以根据查询条件来删除文档：</p><pre><code class="go">POST /employee/_delete_by_query&#123;  &quot;query&quot;: &#123;    &quot;match&quot;: &#123;      &quot;name&quot;: &quot;duval&quot;    &#125;  &#125;&#125;</code></pre><h2 id="更新文档"><a href="#更新文档" class="headerlink" title="更新文档"></a>更新文档</h2><p>可以直接使用索引文档的方式进行数据更新：</p><pre><code class="go">PUT /&lt;target&gt;/_doc/&lt;_id&gt;   // 指定id插入(或更新)POST /&lt;target&gt;/_doc/      // 不指定id插入(或更新)</code></pre><p>也可以通过使用Update Api通过指定脚本更新。比如将id为1的文档的年龄字段递增1：</p><pre><code class="go">POST employee/_update/1&#123;  &quot;script&quot; : &#123;    &quot;source&quot;: &quot;ctx._source.age += params.inc&quot;,    &quot;lang&quot;: &quot;painless&quot;,    &quot;params&quot; : &#123;      &quot;inc&quot; : 1    &#125;  &#125;&#125;</code></pre><p>也可以新增或更新部分字段，例如：更新name字段并插入一个新的title字段。</p><pre><code class="go">POST employee/_update/1&#123;  &quot;doc&quot;: &#123;    &quot;name&quot;:&quot;duval1024&quot;,       &quot;title&quot;:&quot;研发工程师&quot;  &#125;&#125;</code></pre><p>另外也支持upsert操作，更多使用方法见：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-update.html#update-api-example">Update API</a></p><h2 id="批量操作"><a href="#批量操作" class="headerlink" title="批量操作"></a>批量操作</h2><p>相比单个，批量的效率会更加高。语法如下：</p><pre><code>POST /_bulkPOST /&lt;target&gt;/_bulk</code></pre><p>例如索引多个新文档：</p><pre><code class="go">POST _bulk&#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;employee&quot;, &quot;_id&quot; : &quot;2&quot; &#125; &#125;&#123;&quot;name&quot; : &quot;john&quot;, &quot;age&quot; : 28, &quot;salary&quot; : 80000, &quot;address&quot; :&quot;广州市白云区黄石路119号&quot;&#125;&#123; &quot;index&quot; : &#123; &quot;_index&quot; : &quot;employee&quot;, &quot;_id&quot; : &quot;3&quot; &#125; &#125;&#123; &quot;name&quot; : &quot;tom&quot;, &quot;age&quot; : 35, &quot;salary&quot; : 200000, &quot;address&quot; :&quot;杭州市滨江区网商路299号&quot;&#125;</code></pre><p>批量操作还支持其他更多命令，详见：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html#docs-bulk-api-request">Bulk API</a></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/docs.html</a></p>]]></content>
      
      
      <categories>
          
          <category> ES </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ES学习2-索引管理</title>
      <link href="/2024/05/22/ES%E5%AD%A6%E4%B9%A02-%E7%B4%A2%E5%BC%95%E7%AE%A1%E7%90%86/"/>
      <url>/2024/05/22/ES%E5%AD%A6%E4%B9%A02-%E7%B4%A2%E5%BC%95%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>索引(Index)类似于MySQL里的数据库（database）或者表（table）概念。不同于MySQL需要提前建表，ES其实支持在插入数据的时候自动建立默认索引。当然，ES 也支持自定义索引的属性以及结构。</p><h2 id="新建索引"><a href="#新建索引" class="headerlink" title="新建索引"></a>新建索引</h2><p>在Kibana管理页面，我们可以通过REST APIs快速创建一个索引：</p><pre><code class="go">PUT /my-index-000001</code></pre><p>也可以在创建时候指定索引的属性。比如：指定分片数为3，副本数为2（默认情况都是1），则有：</p><pre><code class="go">PUT /my-index-000001&#123;  &quot;settings&quot;: &#123;    &quot;index&quot;: &#123;      &quot;number_of_shards&quot;: 3,        &quot;number_of_replicas&quot;: 2     &#125;  &#125;&#125;</code></pre><p>更多其他属性可以参考<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html">这里</a>。</p><p>也可以在创建时候使用<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html">Mapping</a>指定索引结构里的字段，例如：</p><pre><code class="go">PUT /test&#123;  &quot;settings&quot;: &#123;    &quot;number_of_shards&quot;: 1  &#125;,  &quot;mappings&quot;: &#123;    &quot;properties&quot;: &#123;      &quot;field1&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125;    &#125;  &#125;&#125;</code></pre><h2 id="更新索引"><a href="#更新索引" class="headerlink" title="更新索引"></a>更新索引</h2><h3 id="更新索引属性"><a href="#更新索引属性" class="headerlink" title="更新索引属性"></a>更新索引属性</h3><p>创建好索引后，也可以更新该索引的属性（仅限<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html#dynamic-index-settings">动态属性</a>）：</p><pre><code class="go">PUT /my-index-000001/_settings&#123;  &quot;index&quot; : &#123;    &quot;number_of_replicas&quot; : 2  &#125;&#125;</code></pre><h3 id="更新mapping"><a href="#更新mapping" class="headerlink" title="更新mapping"></a>更新mapping</h3><p>也可以更新索引的映射信息，比如新增字段或者修改字段设置：</p><pre><code class="go">PUT /my-index-00000/_mapping&#123;  &quot;properties&quot;: &#123;    &quot;title&quot;:  &#123; &quot;type&quot;: &quot;text&quot;&#125;  &#125;&#125;</code></pre><p>还可以为上边的title字段再增加一个内嵌字段subtitle：</p><pre><code class="go">PUT /my-index-00000/_mapping&#123;  &quot;properties&quot;: &#123;    &quot;title&quot;: &#123;      &quot;properties&quot;: &#123;        &quot;subtitle&quot;: &#123;          &quot;type&quot;: &quot;text&quot;        &#125;      &#125;    &#125;  &#125;&#125;</code></pre><p>注意，存量索引里的字段类型是不能修改的。因为修改字段类型会导致其与存量数据类型不匹配。你如果想修改字段类型，唯一办法是新建一个索引，然后使用<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html">reindex</a>命令将存量数据导入新的索引中。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html</a><br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-reindex.html</a></p>]]></content>
      
      
      <categories>
          
          <category> ES </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ES学习1-认识</title>
      <link href="/2024/05/12/ES%E5%AD%A6%E4%B9%A01-%E8%AE%A4%E8%AF%86/"/>
      <url>/2024/05/12/ES%E5%AD%A6%E4%B9%A01-%E8%AE%A4%E8%AF%86/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是-ElasticSearch"><a href="#什么是-ElasticSearch" class="headerlink" title="什么是 ElasticSearch"></a>什么是 ElasticSearch</h2><p>ElasticSearch (下称ES)是基于 Apache Lucene 实现的一个分布式搜索引擎。借助ES，你可以为数据建立索引，并在索引上以准实时的方式搜索或者分析你的数据。所以，ES与常见的关系型数据库的应用场景大不相同。ES可以有以下应用场景：</p><ul><li>在App或者网站中增加搜索功能；</li><li>保存并且分析日志数据、指标数据、事件数据等；</li><li>使用机器学习实时自动建模数据的行为；</li><li>使用Elasticsearch作为存储引擎自动化业务工作流；</li><li>使用Elasticsearch作为地理信息系统(GIS)管理、整合和分析空间信息；</li><li>使用Elasticsearch作为生物信息学研究工具存储和处理遗传数据</li></ul><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/8.13/elasticsearch-intro.html">learn more</a></p><h2 id="为什么要学习-ElasticSearch"><a href="#为什么要学习-ElasticSearch" class="headerlink" title="为什么要学习 ElasticSearch"></a>为什么要学习 ElasticSearch</h2><p>根据DB Engine的排名显示，ElasticSearch是最受欢迎的企业级搜索引擎。根据<a href="https://db-engines.com/en/ranking"> DB Engines </a>网站排名可知，比较靠前的有三家大数据搜索引擎公司，除了ElasticSearch，还有Splunk和Solr。其中Solr也是基于Lucene。</p><ul><li><p>1、在当前软件行业中，搜索是一个软件系统或平台的基本功能， 学习ElasticSearch就可以为相应的软件打造出良好的搜索体验。</p></li><li><p>2、其次，ElasticSearch具备非常强的大数据分析能力。虽然Hadoop也可以做大数据分析，但是ElasticSearch的分析能力非常高，具备Hadoop不具备的能力。比如有时候用Hadoop分析一个结果，可能等待的时间比较长。</p></li><li><p>3、ElasticSearch可以很方便的进行使用，可以将其安装在个人的笔记本电脑，也可以在生产环境中，将其进行水平扩展。</p></li><li><p>4、国内比较大的互联网公司都在使用，比如小米、滴滴、携程等公司。另外，在腾讯云、阿里云的云平台上，也都有相应的ElasticSearch云产品可以使用。</p></li><li><p>5、在当今大数据时代，掌握近实时的搜索和分析能力，才能掌握核心竞争力，洞见未来。（涨工资）</p></li></ul><h2 id="Elastic-Stack-生态"><a href="#Elastic-Stack-生态" class="headerlink" title="Elastic Stack 生态"></a>Elastic Stack 生态</h2><blockquote><p>ELK Stack 核心产品包括 Elasticsearch、Kibana、Beats 和 Logstash等等。能够安全可靠地从任何来源获取任何格式的数据，然后对数据进行搜索、分析和可视化</p></blockquote><ul><li><strong>Beats</strong> 是一组轻量级守护进程的集合，它们从服务器收集操作数据并将其发送到Elasticsearch或Logstash。Elastic 社区提供了很多开源的 beats，包括：AuditBeat、FileBeat、FunctionBeat、HeartBeat等等。你也可以开发定制自己想要的beats。</li></ul><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FES%E5%AD%A6%E4%B9%A01-%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8%2Fbeats-platform.png" alt="beats-platform.png"></p><p>具体见：<a href="https://www.elastic.co/guide/en/beats/libbeat/current/beats-reference.html">beats-reference</a></p><ul><li><strong>Logstash</strong> 是一个具有实时流水线功能的开源的数据收集引擎。Logstash可以动态地统一来自不同来源的数据，并将数据规范化到你指定的地方。说人话就是：Logstash是一个实时洗数的数据通道。<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FES%E5%AD%A6%E4%B9%A01-%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8%2Fbasic_logstash_pipeline.png" alt="basic_logstash_pipeline.png">。</li></ul><p>具体见：<a href="https://www.elastic.co/guide/en/logstash/current/introduction.html">logstash introduction</a></p><ul><li><strong>Kibana</strong> 是用来驾驭ELK Stack的可视化管理页面，可以实现：<ul><li>搜索、观察、保护你的数据。</li><li>分析你的数据</li><li>管理、监控、守护你的ELK Stack。</li></ul></li></ul><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FES%E5%AD%A6%E4%B9%A01-%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8%2Fanalytics-home-page.png" alt="analytics-home-page.png"></p><p>具体见：<a href="https://www.elastic.co/guide/en/kibana/current/introduction.html">kibana introduction</a> </p><ul><li><strong>ElasticSearch</strong> 对数据进行存储、搜索、分析，其是基于JSON的分布式搜索和分析引擎，专门为实现水平可扩展性、高可靠性和管理便捷性而设计的。它的实现原理主要分为以下几个步骤：<ul><li>首先用户将数据提交到ElasticSearch数据库中；</li><li>再通过分词控制器将对应的语句分词；</li><li>将分词结果及其权重一并存入，以备用户在搜索数据时，根据权重将结果排名和打分，将返回结果呈现给用户；</li></ul></li></ul><p>基于以上四大组件，常见的日志收集系统可以有如下架构：<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FES%E5%AD%A6%E4%B9%A01-%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8%2Fadvanced_log_system.png" alt="advanced_log_system.png"></p><p>引入消息队列等组件，也可以有以下更灵活的架构：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FES%E5%AD%A6%E4%B9%A01-%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8%2Fflexible_log_system.png" alt="flexible_log_system.png"></p><h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><ul><li><strong>索引 Index</strong>：类似MySQL中database的概念。一个Index下包含多种类型（type）的数据，在类型（type）概念在6.0.0版本废弃后，Index其实更类似于MySQL的表概念（table）；</li><li><strong>类型 Type</strong>：已废弃，忽略；</li><li><strong>文档 Document</strong>：插入的每条数据为一个document。这个概念和mongodb的document相同，也和MySQL的数据行(Row)等价；</li><li><strong>字段 Field</strong>：ES是以JSON的格式插入数据的，数据中的每个字段都类似于MySQL中的一列；</li><li><strong>映射 Mapping</strong>：ES支持自动创建索引，但更常用的方式是通过Mapping指定索引的结构。Mapping类似于MySQL中的表结构定义；</li><li><strong>倒排索引</strong>：注意区分与上边的Index（索引）概念区分开来。ES是通过倒排索引来实现高效的数据搜索。</li></ul><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FES%E5%AD%A6%E4%B9%A01-%E5%85%A5%E9%97%A8%E4%BD%BF%E7%94%A8%2Fes-introduce-1-3.png" alt="es-introduce-1-3.png"></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://www.elastic.co/guide/index.html">https://www.elastic.co/guide/index.html</a><br><a href="https://www.cnblogs.com/supersnowyao/p/11110703.html">https://www.cnblogs.com/supersnowyao/p/11110703.html</a><br><a href="https://pdai.tech/md/db/nosql-es/elasticsearch-x-introduce-1.html">https://pdai.tech/md/db/nosql-es/elasticsearch-x-introduce-1.html</a><br><a href="https://www.elastic.co/pdf/architecture-best-practices.pdf">https://www.elastic.co/pdf/architecture-best-practices.pdf</a><br><a href="https://pdai.tech/md/db/nosql-es/elasticsearch-x-introduce-2.html">https://pdai.tech/md/db/nosql-es/elasticsearch-x-introduce-2.html</a></p>]]></content>
      
      
      <categories>
          
          <category> ES </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES </tag>
            
            <tag> 搜索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 虚拟机原理 (六) ZGC 垃圾收集器</title>
      <link href="/2021/04/08/Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86-6-ZGC-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/"/>
      <url>/2021/04/08/Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86-6-ZGC-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<p>ZGC 是 JVM 生态最新最先进的一款垃圾收集器，具有可扩展低延迟高吞吐量等特性，其设计目标包括：</p><ul><li>亚毫秒级停顿时间（ &lt;&#x3D; 10ms)；</li><li>停顿时间长短与堆大小、存活对象数量、根节点数量无关；</li><li>支持堆大小从8MB到16TB不等；</li></ul><span id="more"></span><h2 id="总览"><a href="#总览" class="headerlink" title="总览"></a>总览</h2><p>ZGC 主要特点包括：</p><ul><li>尽可能的并发；</li><li>基于 Region 的堆空间划分；</li><li>空间整理；</li><li>支持 NUMA-aware；</li><li>使用染色指针（colored pointers）</li><li>使用读屏障；</li></ul><h2 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h2><p>ZGC 之所以能实现10ms以内的低延迟，最核心原因是实现了并发的对象转移。<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FZGC%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E9%98%B6%E6%AE%B5%E5%9B%BE.png" alt="ZGC垃圾收集阶段图.png"></p><p>ZGC 只有三个停顿阶段：开始标记（Mark Start）、结束标记（Mark End）、开始转移（Relocate Start）。这仨阶段的最大停顿时间不超过10ms，而开始标记和开始转移两个节点只是扫描 GC Root，与堆内活跃对象数量多少没有关系。而结束标记阶段（也称重新标记阶段）的停顿时间一般小于1ms，如果超过1ms会重新进入并发标记阶段。</p><p>此外，在每一个 GC 周期的并发标记阶段都会顺便进行上一个阶段的并发对象重定位。</p><h2 id="Region"><a href="#Region" class="headerlink" title="Region"></a>Region</h2><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2Fzgc%20region%20%E5%88%92%E5%88%86.png" alt="zgc region 划分.png"></p><p>ZGC 也是采用 Region 来划分堆空间，这点与 G1 类似，但有略有不同：</p><ul><li>ZGC 不采用分代划分；</li><li>ZGC 包含三种大小类型的 Region：Small（2MB)、Medium（32MB)、Large（N * 2MB）；</li><li>ZGC 中的 Region 也称为 ZPage，空闲的 ZPage 会被记录在 ZPageCache；而空闲的 ZPage 有可能会被归还给操作系统；</li></ul><h2 id="染色指针"><a href="#染色指针" class="headerlink" title="染色指针"></a>染色指针</h2><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F%E6%9F%93%E8%89%B2%E6%8C%87%E9%92%88%E5%AF%BB%E5%9D%80%E7%A9%BA%E9%97%B4.png" alt="染色指针寻址空间.png"></p><p>ZGC 只支持64位地址系统，其中，[0~4TB) 对应Java堆，[4TB ~ 8TB) 称为M0地址空间，[8TB ~ 12TB) 称为M1地址空间，[12TB ~ 16TB) 预留未使用，[16TB ~ 20TB) 称为 Remapped 空间。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FHeap%20Multi-Mapping%20on%20Linux%3Ax86_64.png" alt="Heap Multi-Mapping on Linux_x86_64.png"></p><p>因此，同一个时间点下，堆空间的某一个位置会同时有三个虚拟地址与之对应。ZGC 用这三个地址来标识该对象所处的状态，在对象转移和重定位过程中会用到这三个虚拟地址。</p><h2 id="读屏障"><a href="#读屏障" class="headerlink" title="读屏障"></a>读屏障</h2><p>ZGC 在并发转移的时候会转移对象，并变更对象指针为 Remapped 空间指针。但此时应用程序中的指针还是 M0 或者 M1 空间指针，该指针也称为坏指针（bad pointer）。</p><p>如果应用线程或者GC线程访问到该坏指针并尝试从堆中读取指针背后的对象，则会尝试在读取之后通过读屏障进行指针修复，类似伪代码如下：</p><pre><code class="c++">Object o = obj.fieldA; // Loading an object reference from heap&lt;load barrier needed here&gt;Object p = o; // No barrier, not a load from heapo.doSomething(); // No barrier, not a load from heapint i = obj.fieldB; // No barrier, not an object reference</code></pre><p>如上，假定 fieldA 对象已经被转移，需要被重定向。那么，第一行代码其后会被插入一段读屏障代码，代码里所做的事情就是修正当前指针为 M0 或者 M1 指针：</p><pre><code class="c++">Object o = obj.fieldA; // Loading an object reference from heapif (!(o &amp; good_bit_mask)) &#123;    if (o != null) &#123;        slow_path(register_for(o), address_of(obj.fieldA));    &#125;&#125;</code></pre><p>这个修改过程大概有4%的执行开销。</p><h2 id="ZGC-回收过程详解"><a href="#ZGC-回收过程详解" class="headerlink" title="ZGC 回收过程详解"></a>ZGC 回收过程详解</h2><h3 id="初始标记-Pause-Mark-Start"><a href="#初始标记-Pause-Mark-Start" class="headerlink" title="初始标记&#x2F;Pause Mark Start"></a>初始标记&#x2F;Pause Mark Start</h3><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FPause%20Mark%20Start.png" alt="Pause Mark Start.png"></p><p>从 GC Roots 出发快速标记并其引用的对象。由于根节点集合很小，这个阶段时间会很短。</p><p>假如当前 GC 周期使用 M0 地址空间，那么被标记存活的对象1、2、4会被更新为 M0 指针。</p><h3 id="并发标记以及并发重定位-Concurrent-Mark-Remapped"><a href="#并发标记以及并发重定位-Concurrent-Mark-Remapped" class="headerlink" title="并发标记以及并发重定位&#x2F; Concurrent Mark &amp;&amp; Remapped"></a>并发标记以及并发重定位&#x2F; Concurrent Mark &amp;&amp; Remapped</h3><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2Fconcurrent%20mark.png" alt="concurrent mark.png"></p><p>并发阶段会遍历整个堆，所有活跃对象都将得到标记。</p><p>假如当前 GC 周期使用 M0 地址空间，则对象1、2、4、5、8会被更新为 M0 地址空间。而3、6、7可能还处于上一个阶段，也就是 M1 指针。另外，坏指针也会被修复为 M0 指针。</p><h3 id="重新标记-Pause-Mark-End"><a href="#重新标记-Pause-Mark-End" class="headerlink" title="重新标记&#x2F;Pause Mark End"></a>重新标记&#x2F;Pause Mark End</h3><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FPause%20Mark%20End.png" alt="Pause Mark End.png"></p><p>重新阶段会 STW，并做一些收尾工作。这个阶段会控制在1ms以内，超过1ms会重新回到并发标记阶段。</p><h3 id="并发迁移准备-Concurrent-Prepare-for-Reloc"><a href="#并发迁移准备-Concurrent-Prepare-for-Reloc" class="headerlink" title="并发迁移准备&#x2F;Concurrent Prepare for Reloc"></a>并发迁移准备&#x2F;Concurrent Prepare for Reloc</h3><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FConcurrent%20Prepare%20for%20Relocate.png" alt="Concurrent Prepare for Relocate.png"></p><p>经过之前的标记工作，已经掌握了整个堆中的存活对象。那么在并发迁移准备过程中，会计算迁移集合。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FConcurrent%20Prepare%20for%20Relocate%202.png" alt="Concurrent Prepare for Relocate 2.png"></p><p>同时会初始化一个空的 forwarding tables，用于保存迁移前后的映射关系。</p><h3 id="初始迁移-Pause-Relacate-Start"><a href="#初始迁移-Pause-Relacate-Start" class="headerlink" title="初始迁移&#x2F;Pause Relacate Start"></a>初始迁移&#x2F;Pause Relacate Start</h3><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FPause%20Relocate%20Start.png" alt="Pause Relocate Start.png"></p><p>初始迁移阶段只是扫描与根节点直接关联的对象，并进行迁移，被迁移对象会被变更为 Remapped 指针，并把映射映射关系保存到  forwarding tables。该阶段只扫描少量对象，速度非常快。</p><h3 id="并发迁移-Concurrent-Relocate"><a href="#并发迁移-Concurrent-Relocate" class="headerlink" title="并发迁移&#x2F;Concurrent Relocate"></a>并发迁移&#x2F;Concurrent Relocate</h3><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2Fconcurrent%20reloacate%201.png" alt="concurrent reloacate 1.png"></p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2Fconcurrent%20reloacate%202.png" alt="concurrent reloacate 2.png"></p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2Fconcurrent%20reloacate%203.png" alt="concurrent reloacate 3.png"></p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2Fconcurrent%20reloacate%204.png" alt="concurrent reloacate 4.png"></p><p>并发转移阶段会遍历所有的迁移集合，进行存活对象迁移，并回收空区块。被迁移的对象指针都会被变更为 Remapped 指针，并把映射映射关系保存到  forwarding tables。</p><p>假如当前 GC 周期使用 M0 地址空间，那么对象4、5、6都发生了迁移，此时其指针处于 Remapped 地址空间。而对象2、4、5所引用的指针都是处于 M2 指针。这些指针都已经失效，也就是坏指针，后续对象重定向阶段会修复它们。</p><h3 id="对象重定位"><a href="#对象重定位" class="headerlink" title="对象重定位"></a>对象重定位</h3><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FGC%20Cycle%20Completed.png" alt="GC Cycle Completed.png"></p><p>上一个 GC 周期结束后，JVM 内部还有很多坏指针，如果应用线程线程加载了这些指针，则会在读屏障阶段修复这些指针。剩下的未修复指针将延迟到第二个 GC 周期来进行修复。</p><p>假如上一个 GC 周期使用的是 M0 地址空间，那么新的 GC 周期就会使用 M1 地址空间进行活跃对象标记。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FPause%20Mark%20Start%28Second%20Cycle%29.png" alt="Pause Mark Start(Second Cycle).png"></p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FConcurrent%20Mark%28Second%20Cycle%29.png" alt="Concurrent Mark(Second Cycle).png"></p><p>下一个周期的初始标记和并发标记会顺带把上一个周期的坏指针修复。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FConcurrent%20Prepare%20for%20Relocate%28Second%20Cycle%29.png" alt="Concurrent Prepare for Relocate(Second Cycle).png"></p><p>然后清空上一个阶段的 forwarding table。</p><h2 id="ZGC-触发条件"><a href="#ZGC-触发条件" class="headerlink" title="ZGC 触发条件"></a>ZGC 触发条件</h2><p>CMS 调优中一般会调整 CMSInitiatingOccupancyFraction 参数，然后在老年代占用达到一定比例的时候，触发一次 GC；</p><p>G1 中也有类似的参数 InitiatingHeapOccupancyPercent，在老年代占用达到堆空间的一定比例的时候，触发一次混合 GC；此外，G1 还会评估当前收集时间是否超过阈值 MaxGCPauseMillis ，如果超过阈值也会触发一次 GC；</p><p>无论是 CMS 或者是 G1 的触发方式都存在一些不足。因此，ZGC 使用了更复杂的一套机制：</p><ul><li><p><strong>元空间分配触发</strong>：元空间分配不足的时候触发。使用 G1 的时候一般建议配置，因为默认会占满所有剩余内存。但在 ZGC 中不存在这个问题，所以一般不用关心元空间分配。</p><pre><code class="text">  [2021-04-07T03:17:58.763-0400][14855][gc          ] GC(0) Garbage Collection (Metadata GC Threshold) 196M(0%)-&gt;196M(0%)  [2021-04-07T03:18:00.052-0400][14855][gc          ] GC(1) Garbage Collection (Metadata GC Threshold) 444M(0%)-&gt;202M(0%)  [2021-04-07T03:18:04.429-0400][14855][gc          ] GC(2) Garbage Collection (Metadata GC Threshold) 1038M(1%)-&gt;206M(0%)</code></pre></li><li><p><strong>固定时间间隔触发</strong>：通过 <em>-XX:ZCollectionInterval&#x3D;&lt;seconds&gt;</em> 来控制。如果服务压力不大的话，这是最主要的 GC 方式。这种方式是为了在流量平稳的情况下定时触发 GC，避免流量突增的时候才触发 GC，从而导致线程阻塞。如果 G1 用得比较多话，就会发现 G1 就存在这个比较严重的问题。</p><pre><code class="text">  [2021-04-07T10:00:24.610-0400][14855][gc          ] GC(203) Garbage Collection (Timer) 48674M(32%)-&gt;336M(0%)  [2021-04-07T10:02:24.709-0400][14855][gc          ] GC(204) Garbage Collection (Timer) 54888M(36%)-&gt;360M(0%)  [2021-04-07T10:04:24.804-0400][14855][gc          ] GC(205) Garbage Collection (Timer) 50482M(33%)-&gt;362M(0%)  [2021-04-07T10:06:24.904-0400][14855][gc          ] GC(206) Garbage Collection (Timer) 46962M(31%)-&gt;370M(0%)  [2021-04-07T10:08:25.006-0400][14855][gc          ] GC(207) Garbage Collection (Timer) 49444M(32%)-&gt;340M(0%)</code></pre></li><li><p><strong>基于分配速率的自适应算法触发</strong>：ZGC 根据对象分配速率和 GC 时间来计算内存占用达到什么阈值的时候才触发 GC。通过ZAllocationSpikeTolerance参数控制阈值大小，该参数默认2，数值越大，越早的触发GC。</p><pre><code class="text">[2021-04-07T09:30:41.600-0400][22575][gc          ] GC(166) Garbage Collection (Allocation Rate) 7854M(96%)-&gt;340M(4%)[2021-04-07T09:31:16.474-0400][22575][gc          ] GC(167) Garbage Collection (Allocation Rate) 7798M(95%)-&gt;330M(4%)[2021-04-07T09:31:54.769-0400][22575][gc          ] GC(168) Garbage Collection (Allocation Rate) 7812M(95%)-&gt;312M(4%)[2021-04-07T09:32:34.672-0400][22575][gc          ] GC(169) Garbage Collection (Allocation Rate) 7894M(96%)-&gt;330M(4%)[2021-04-07T09:33:09.872-0400][22575][gc          ] GC(170) Garbage Collection (Allocation Rate) 7886M(96%)-&gt;314M(4%)</code></pre></li><li><p><strong>阻塞内存触发分配</strong>：当垃圾来不及回收并堆满整个堆的情况下，会触发这种 GC。调优良好情况下，应该尽量避免这种 GC：</p><pre><code class="text">  [2021-04-07T10:08:14.458-0400][23755][gc          ] Allocation Stall (nioEventLoopGroup-12-1) 0.749ms  [2021-04-07T10:08:14.458-0400][23783][gc          ] Allocation Stall (nioEventLoopGroup-16-1) 1.019ms  [2021-04-07T11:13:08.556-0400][23764][gc          ] Allocation Stall (nioEventLoopGroup-13-1) 0.115ms</code></pre></li><li><p>主动触发规则：类似于固定间隔规则，但时间间隔不固定，是ZGC自行算出来的时机，我们的服务因为已经加了基于固定时间间隔的触发机制，所以通过-ZProactive参数将该功能关闭，以免GC频繁，影响服务可用性。 日志中关键字是”Proactive”</p></li><li><p>预热规则：服务刚启动时出现，一般不需要关注。日志中关键字是”Warmup”</p></li><li><p>外部触发：代码中显式调用System.gc()触发。 日志中关键字是”System.gc()”</p></li></ul><blockquote><p>后边三种较少见，没在生产服务里找到案例，所以直接复制了<a href="https://tech.meituan.com/2020/08/06/new-zgc-practice-in-meituan.html">美团的技术文章</a>里的片段。</p></blockquote><h2 id="ZGC-与-G1-案例对比"><a href="#ZGC-与-G1-案例对比" class="headerlink" title="ZGC 与 G1 案例对比"></a>ZGC 与 G1 案例对比</h2><p>简单做了下测试对比下 ZGC 和 G1，无论是大堆或者小堆，ZGC 在收集停顿上都控制得非常好，基本不会超过10ms，这点远胜于 G1；但是可能 ZGC 的触发策略保守了，总的停顿时间要比 G1 多。</p><p>但总体来说，ZGC 是一款低延迟高吞吐量的收集器，是 G1 的良好替代！</p><h3 id="大堆（150G）"><a href="#大堆（150G）" class="headerlink" title="大堆（150G）"></a>大堆（150G）</h3><h4 id="ZGC"><a href="#ZGC" class="headerlink" title="ZGC"></a>ZGC</h4><pre><code class="bash">-Xmx150g -Xms150g -XX:ReservedCodeCacheSize=256m -XX:InitialCodeCacheSize=256m -XX:+UnlockExperimentalVMOptions -XX:+UseZGC -XX:ConcGCThreads=80 -XX:ParallelGCThreads=80 -XX:ZCollectionInterval=120 -XX:ZAllocationSpikeTolerance=5 -XX:+UnlockDiagnosticVMOptions -XX:-ZProactive -Xlog:safepoint,classhisto*=trace,age*,gc*=info:file=gc.log:time,tid,tags:filecount=5,filesize=500m</code></pre><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FZGC%E5%A4%A7%E5%A0%86%E5%81%9C%E9%A1%BF%E6%97%B6%E9%97%B4%E5%9B%BE.png" alt="ZGC大堆停顿时间图.png"></p><p><a href="https://gceasy.io/diamondgc-report.jsp?oTxnId_value=0232678d-bae8-4b29-8347-a4630972754e">GC分析报告</a></p><h4 id="G1"><a href="#G1" class="headerlink" title="G1"></a>G1</h4><pre><code class="bash">-Xmx150g -Xms150g -XX:+UseG1GC -XX:MaxGCPauseMillis=500 -XX:MetaspaceSize=150m -XX:MaxMetaspaceSize=150M -XX:+UnlockExperimentalVMOptions -Xlog:safepoint,classhisto*=trace,age*,gc*=info:file=gc.log:time,tid,tags:filecount=5,filesize=500m</code></pre><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FG1%E5%A4%A7%E5%A0%86%E5%81%9C%E9%A1%BF%E6%97%B6%E9%97%B4%E5%9B%BE.png" alt="G1大堆停顿时间图.png"></p><p><a href="https://gceasy.io/diamondgc-report.jsp?oTxnId_value=93be8dc7-a1bc-47bf-8a41-576354036acd">GC分析报告</a></p><h3 id="小堆（8G）"><a href="#小堆（8G）" class="headerlink" title="小堆（8G）"></a>小堆（8G）</h3><h4 id="ZGC-1"><a href="#ZGC-1" class="headerlink" title="ZGC"></a>ZGC</h4><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FZGC%E5%B0%8F%E5%A0%86%E5%81%9C%E9%A1%BF%E6%97%B6%E9%97%B4.png" alt="ZGC小堆停顿时间.png"></p><p><a href="https://gceasy.io/diamondgc-report.jsp?oTxnId_value=83a0415a-5a27-457b-b807-ec1d91a14ef5">GC分析报告</a></p><h4 id="G1-1"><a href="#G1-1" class="headerlink" title="G1"></a>G1</h4><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FG1%E5%B0%8F%E5%A0%86%E5%81%9C%E9%A1%BF%E6%97%B6%E9%97%B4.png" alt="G1小堆停顿时间.png"></p><p><a href="https://gceasy.io/diamondgc-report.jsp?oTxnId_value=bcd74765-2660-473a-a0d9-27ff6c4076cb">GC分析报告</a></p><h2 id="ZGC-案例记录"><a href="#ZGC-案例记录" class="headerlink" title="ZGC 案例记录"></a>ZGC 案例记录</h2><h3 id="案例1：ZGC-大堆满了"><a href="#案例1：ZGC-大堆满了" class="headerlink" title="案例1：ZGC 大堆满了"></a>案例1：ZGC 大堆满了</h3><p>生产遇到 Java 进程阻塞导致 ZGC 大堆被堆满，发生了一些有趣的事情：</p><ul><li><p>停顿时间变短，但是停顿频率变大<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FZGC%E5%A4%A7%E5%A0%86%E6%BB%A1%E5%90%8E%E5%81%9C%E9%A1%BF%E6%97%B6%E9%97%B4%E5%9B%BE.png" alt="ZGC大堆满后停顿时间图.png"></p></li><li><p>并发阶段时间变长<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FZGC%E5%A4%A7%E5%A0%86%E6%BB%A1%E5%90%8E%E5%B9%B6%E5%8F%91%E6%97%B6%E9%97%B4%E5%9B%BE.png" alt="ZGC大堆满后并发时间图.png"></p></li><li><p>服务器的用户态CPU占用很高<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%20%28%E5%85%AD%29%20ZGC%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2FZGC%E5%A4%A7%E5%A0%86%E6%BB%A1%E5%90%8ECPU%E5%8D%A0%E7%94%A8%E5%9B%BE.png" alt="ZGC大堆满后CPU占用图.png"></p></li></ul><p>结论是：ZGC 停顿阶段主要是扫描根节点，最大停顿时间都不会超过 10ms，没有传统收集器的 Full GC 阶段，堆满的时候会增加并发阶段时间，与应用线程形成 CPU 资源竞争。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://cr.openjdk.java.net/~pliden/slides/ZGC-Jfokus-2018.pdf">ZGC-Jfokus-2018</a>：本文大部分内容参考这个PPT。PPT 对应的视频在这 <a href="https://www.youtube.com/watch?v=tShc0dyFtgw">https://www.youtube.com/watch?v=tShc0dyFtgw</a></li><li><a href="https://tech.meituan.com/2020/08/06/new-zgc-practice-in-meituan.html">新一代垃圾回收器ZGC的探索与实践</a>：美团出品，真是精品</li><li><a href="http://cr.openjdk.java.net/~pliden/slides/ZGC-OracleDevLive-2020.pdf">ZGC-OracleDevLive-2020</a>：ZGC最新的一些展望以及性能分析</li><li><a href="https://wiki.openjdk.java.net/display/zgc/Main">ZGC</a>:官方文档右侧有很多PPT和油管视频</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
            <tag> 垃圾回收器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生产问题(3) 应用开发过程中的海恩法则</title>
      <link href="/2021/02/09/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98-3-%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E6%B5%B7%E6%81%A9%E6%B3%95%E5%88%99/"/>
      <url>/2021/02/09/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98-3-%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E6%B5%B7%E6%81%A9%E6%B3%95%E5%88%99/</url>
      
        <content type="html"><![CDATA[<p>海恩法则，是航空界关于飞行安全的法则。海恩法则指出: 每一起严重事故的背后，必然有29次轻微事故和300起未遂先兆以及1000起事故隐患。</p><p>最近在生产上遇到一个应用案例，正好完美体现了海恩法则的价值！</p><span id="more"></span><h2 id="事故表现"><a href="#事故表现" class="headerlink" title="事故表现"></a>事故表现</h2><p>北京时间晚上十点半美股开盘后，某板块的数据却没有更新。所有的相关人员都没有提前收到告警，直到事故发生后，开发才紧急介入恢复。开发接入后，先紧急重启服务无法恢复；于是紧急切换到热备服务，才恢复成功。</p><p>该事故持续了超过30分钟，导致所有用户无法查看该板块数据，也无法提交订单。该事故影响非常恶劣，其定级考虑为灾难级别事故。</p><h2 id="事故原因"><a href="#事故原因" class="headerlink" title="事故原因"></a>事故原因</h2><p>每个严重事故背后都是多次轻微事故，我们来按照时间顺序，理清楚背后发生的事情：</p><ul><li><p><strong>网络抖动</strong>：下午六点许，机房A与机房B之间的网络发生了一次轻微抖动，导致机房A内的数据处理服务P与机房B的数据源S之间的 TCP 连接发生假死断开；</p></li><li><p><strong>业务缺陷</strong>：机房A内部的数据处理服务P存在缺陷，并没有实现心跳检查并自动重连的功能；</p></li><li><p><strong>运维缺陷</strong>：数据处理服务P内部监控模块检测到连接异常，并发出告警。但告警地址没有添加机器白名单，告警信息被503错误拦截；</p></li><li><p><strong>业务缺陷</strong>：数据处理服务P启动后预热数据量过大，盘中上游推送数据量也非常大。这导致 JVM 压力非常巨大，大量对象迅速进入老年代，服务无法在盘中重启成功。盘中重启后的GC情况如下图所示，可以看到 JVM（CMS，12G堆，新生代5G，8:1） 在重启两分钟后迅速崩溃掉：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98%283%29%20%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E6%B5%B7%E6%81%A9%E6%B3%95%E5%88%99%2F%E4%BA%8B%E6%95%85GC%E5%81%9C%E9%A1%BF%E6%97%B6%E9%97%B4%E5%9B%BE.png" alt="事故GC停顿时间图.png"></p></li></ul><h2 id="事故总结"><a href="#事故总结" class="headerlink" title="事故总结"></a>事故总结</h2><ul><li><strong>服务健壮性</strong>：业务逻辑要强制实现心跳检测、失活重连这种基本功能；</li><li><strong>监控告警</strong>：核心服务需要完备的监控和告警，并且对各机房的监控告警要充分测试，确保紧急时候能够得到响应；</li><li><strong>备点服务方案</strong>：核心服务不能允许只有一套，必须有备点服务，用于紧急情况下的切换；</li><li><strong>高可用快速切换</strong>：尽量确保服务在故障情况下能够自动切换到备用服务，如果无法实现自动切换，需要确保有快速手动切换的方案。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生产问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入 MySQL (六) 常见问题汇总</title>
      <link href="/2021/02/07/%E6%B7%B1%E5%85%A5-MySQL-6-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"/>
      <url>/2021/02/07/%E6%B7%B1%E5%85%A5-MySQL-6-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</url>
      
        <content type="html"><![CDATA[<p>本文汇总关于 MySQL 底层原理常见问题。</p><span id="more"></span><h2 id="问题汇总"><a href="#问题汇总" class="headerlink" title="问题汇总"></a>问题汇总</h2><ul><li><p>1.如何避免长事务对业务的影响？</p><blockquote><p> 这个问题，我们可以从应用开发端和数据库端来看。</p><ul><li>首先，从应用开发端来看：确认是否使用了 set autocommit&#x3D;0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。</li><li>确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin&#x2F;commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。</li><li>业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。</li></ul></blockquote><blockquote><p> 其次，从数据库端来看：</p><ul><li>监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 &#x2F; 或者 kill；</li><li>Percona 的 pt-kill 这个工具不错，推荐使用；</li><li>在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；</li><li>如果使用的是 MySQL  5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更&gt;大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。</li></ul></blockquote></li><li><p>2.如果针对InnoDB表进行索引重建，对二级索引执行：</p><pre><code class="sql">alter table T drop index k;alter table T add index(k);</code></pre><p>  以及对主键索引执行：</p><pre><code class="sql">alter table T drop primary key;alter table T add primary key(id);</code></pre><p>  这两者有啥异同，或者存在什么问题？</p><blockquote><ul><li>索引可能因为删除或页分裂，而使得数据页存在空洞，重建索引会重新创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。</li><li>对二级索引使用该SQL重建是可行的合理的。</li><li>对于主键索引，无论是删除主键还是新建主键，都会导致整个表发生重建。而应该使用<em>alter table T engine&#x3D;InnoDB；</em> 语句进行主键重建。</li></ul></blockquote></li><li><p>3.字段k上有二级索引，现有如下两个功能相同的SQL语句，哪个更优：</p><pre><code class="sql">select * from T where k in(1,2,3,4,5)select * from T where k between 1 and 5</code></pre><blockquote><p>SQL1需要搜索5次，并回表5次；SQL2只需要搜索1次，并回表5次。SQL充分利用了B+树叶子节点顺序排序的特点，可以加速范围查询。</p></blockquote></li><li><p>4.如何解决热点行更新导致的性能问题？</p><blockquote><ul><li>1、如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关闭掉。一般不建议采用</li><li>2、控制并发度，对应相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。</li><li>3、将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高。</li></ul></blockquote></li><li><p>5.MySQL出现抖动原因</p><blockquote><p>很有可能在刷脏页。刷脏页触发原因有：</p><ul><li>redo log写满；</li><li>内存不足（其实是buffer pool）的时候淘汰了脏页；</li><li>MySQL在认为空闲的时段，会自行刷脏页；</li><li>MySQL关闭前会刷脏页；<br>刷脏页的策略调优：</li><li>磁盘能力。能力越大，脏页刷的越快。参数：innodb_io_capacity；</li><li>脏页比例上限。参数innodb_max_dirty_pages_pct，默认值:75%。生产中应该调控innodb_io_capacity使得脏页比例不要接近innodb_max_dirty_pages_pct 。查看脏页比例方法：<pre><code class="sql">  set global show_compatibility_56=on;select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = &#39;Innodb_buffer_pool_pages_dirty&#39;;select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = &#39;Innodb_buffer_pool_pages_total&#39;;select @a/@b;</code></pre></li><li>刷相邻脏页。机械磁盘建议打开（1），SSD磁盘可以关闭（0）。参数：innodb_flush_neighbors</li></ul></blockquote></li><li><p>6.删除了数据，但是表文件没有缩小？</p><blockquote><p>表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的：</p><ul><li>这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起，此时drop表不会回收表空间。</li><li>这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中，此时drop表会回收表空间。</li></ul></blockquote><blockquote><p>删除数据记录不一定回收空间，一般只是标记为可复用，此时数据页会留下空洞的，等待新的数据插入复用这些空洞。</p><p>主动回收表空间的方法：</p><ul><li>使用alter table t engine &#x3D; InnoDB；该命令会使用<a href="https://www.cnblogs.com/cchust/p/4639397.html">Online DDL</a>重建新表（MySQL5.6+），因此可以在业务低峰期执行。；</li><li>使用analyze table t 。该命令会对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；</li><li>使用optimize table t 相当于重建表+重新统计索引信息。</li></ul></blockquote></li><li><p>7.count效率</p><blockquote><p>按照效率排序的话，count(字段)&lt;count(主键 id)&lt;count(1)≈count(*)</p></blockquote></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>深入 MySQL (五) 锁</title>
      <link href="/2021/02/06/%E6%B7%B1%E5%85%A5-MySQL-5-%E9%94%81/"/>
      <url>/2021/02/06/%E6%B7%B1%E5%85%A5-MySQL-5-%E9%94%81/</url>
      
        <content type="html"><![CDATA[<p>本文我们介绍 MySQL 锁的相关内容。</p><span id="more"></span><h1 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h1><ul><li>根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。其中全局锁和表锁都是Server层支持的，而行锁是引擎层实现的，InnoDB支持行锁，而MyISAM不支持行锁。</li></ul><h2 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h2><ul><li>加全局锁办法：<em>flush table with read lock；</em> （解锁使用<em>unlock table;</em>)会使得整个数据库实例处于只读状态。一般用在MySIAM引擎下进行全库逻辑备份，而在InnoDB下一般不采用这种办法，应该使用mysqldump –single-transaction 通过事务来获得一致性视图，而不用加全局锁。</li><li>不要使用 <em>set global readonly&#x3D;true；</em> 来加全局锁。因为readonly值会被用在其他用途，并且当客户端发生异常，readonly值会持久化到数据库上，导致数据库锁不能释放。读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。</li></ul><h2 id="表锁"><a href="#表锁" class="headerlink" title="表锁"></a>表锁</h2><ul><li>MySQL支持表锁，一般使用 <em>lock tables [tablename] read&#x2F;write</em> 进行加锁。该命令的加锁会对所有的线程生效。</li><li>MDL（metadata lock)是另一类表锁，不需要显式使用，在访问一个表的时候会被自动加上。在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。因此，MDL锁作用是防止增删改数据（DML)和加字段等修改表结构的操作（DDL）互相冲突。</li></ul><h2 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h2><ul><li>在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。因此，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</li><li>行锁的算法可以分为三种：Record Lock（单行记录上的锁）、Gap Lock(间隙锁，锁定一个范围不包含记录本身)和Next-Key Lock(锁定一个范围并包含记录本身)。具体参考：<a href="https://juejin.im/post/6844903735500472333">MySQL探秘(七):InnoDB行锁算法</a></li><li>InnoDB通过给索引项加锁来实现行锁，如果没有索引，则通过隐藏的聚簇索引来对记录加锁。如果操作不通过索引条件检索数据，InnoDB 则对表中的所有记录加锁，实际效果就和表锁一样。</li><li>当查询的索引是唯一索引(不存在两个数据行具有完全相同的键值)时，InnoDB存储引擎会将Next-Key Lock降级为Record Lock，即只锁住索引本身，而不是范围。如果是范围查询，则边界的Next-Key Lock也有可能不会降级。<a href="https://time.geekbang.org/column/article/75659">21 | 为什么我只改一行的语句，锁这么多？</a></li><li>InnoDB对于辅助索引使用Next-Key Lock锁，也就是说不仅会锁住辅助索引值所在的范围以及记录本身，还会将其下一键值加上Gap LOCK。</li><li>Next-Key Lock本质是Record Lock + Gap Lock；</li><li>Next-Key Lock是前开后闭区间</li></ul><h2 id="加锁原则"><a href="#加锁原则" class="headerlink" title="加锁原则"></a>加锁原则</h2><p>两个“原则”、两个“优化”和一个“bug”。</p><ul><li>原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。</li><li>原则 2：查找过程中访问到的对象才会加锁。</li><li>优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。</li><li>优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。</li><li>一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。</li></ul><h2 id="意向排他锁"><a href="#意向排他锁" class="headerlink" title="意向排他锁"></a>意向排他锁</h2><ul><li>InnoDB支持多粒度锁，允许行锁和表锁共存。而意向锁属于一种表锁，意向锁互相之间不会排斥，但意向锁和表级的X锁存在互斥关系。具体参考：<a href="https://juejin.im/post/6844903666332368909">详解 MySql InnoDB 中意向锁的作用</a></li></ul><h2 id="死锁检测策略"><a href="#死锁检测策略" class="headerlink" title="死锁检测策略"></a>死锁检测策略</h2><ul><li><p>一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。</p></li><li><p>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。但注意，如果打开死锁检测，事务执行过程中发生阻塞，都会进行检测，从而CPU性能损耗。</p></li><li><p>尽管会带来性能损耗，但正常来说都应该开启死锁检测。</p></li><li><p>减少死锁的主要方向，就是控制访问相同资源的并发事务量。</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入 MySQL (四) 索引</title>
      <link href="/2021/02/05/%E6%B7%B1%E5%85%A5-MySQL-4-%E7%B4%A2%E5%BC%95/"/>
      <url>/2021/02/05/%E6%B7%B1%E5%85%A5-MySQL-4-%E7%B4%A2%E5%BC%95/</url>
      
        <content type="html"><![CDATA[<p>本文我们将探讨 MySQL 索引的重要概念以及实现原理。</p><span id="more"></span><h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><h2 id="常见索引模型"><a href="#常见索引模型" class="headerlink" title="常见索引模型"></a>常见索引模型</h2><table><thead><tr><th>模型</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>哈希表</td><td>等值查询和范围查询都非常高效</td><td>插入数据成本高，只适合静态数据存储引擎</td></tr><tr><td>二叉搜索树</td><td>查询和插入都很高效</td><td>树高过大，实际生产中要多次读取磁盘，查询效率不高</td></tr><tr><td>N叉树</td><td>查询和插入都高效、且树高较低</td><td>–</td></tr></tbody></table><h2 id="InnoDB索引模型"><a href="#InnoDB索引模型" class="headerlink" title="InnoDB索引模型"></a>InnoDB索引模型</h2><ul><li><p>InnoDB使用B+树索引模型，每一个索引都是一棵独立的B+树；</p></li><li><p>主键索引的叶子节点存的是<strong>整行数据</strong>。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。注意B+树的节点都对应着InnoDB的一个数据页，默认大小16K。也就是说叶子节点里包含着多行数据；</p></li><li><p>非主键索引的叶子节点内容是<strong>主键的值</strong>。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2Fmysql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%B8%80%20%E5%9F%BA%E7%A1%80%E7%AF%87%2FInnoDB%E7%B4%A2%E5%BC%95%E6%A8%A1%E5%9E%8B%E5%9B%BE.png" alt="InnoDB索引模型图.png"></p></li><li><p><strong>页分裂</strong>：插入新数据的时候，B+树节点所在的数据页满了之后，节点会发生分裂，需要申请新的数据页来保存新节点，这个过程叫做页分裂。  –&gt; 页分裂会使得空间利用率下降，并降低性能。</p></li><li><p><strong>页大小</strong>：InnoDB页大小（innodb_page_size）默认值为16kb，可以通过调整页大小来间接改变B+树分叉数量</p></li><li><p><strong>自增主键</strong>：考虑到页分裂的性能影响，使用自增主键要比其他业务字段作为主键ID要更优。因为自增主键的每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。</p></li><li><p><strong>不必使用自增主键的场景</strong>：如果该表只有一个索引，且该索引为唯一索引，则适合让该索引直接作为主键索引。这样子可以避免生成两棵索引树以节省空间，并且避免回表以增加查询性能。</p></li><li><p><strong>回表</strong> ：使用非主键索引查询数据的时候，如果所查数据包含了主键以外的数据，则需要回到主键索引进行二次查询，这个过程称为回表。  –&gt; 因此应该尽量使用主键索引查询。</p></li><li><p><strong>覆盖索引</strong>：当二级索引已经“覆盖”了查询需求的时候，该索引可称为覆盖索引。使用覆盖索引可以回表操作，减少搜索B+树的次数。因此，可以为高频查询建立覆盖索引。</p></li><li><p><strong>最左前缀原则</strong>：只要查询条件能够满足联合索引的最左前缀，则可以使用该联合索引来加速检索。因此，建立联合索引时候，需要合理安排字段顺序，充分利用最左前缀原则来减少索引数量。</p></li><li><p>**索引下推优化（index condition pushdown)**：MySQL5.6之后引入了索引下推，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p></li><li><p><strong>Change Buffer</strong>:当对二级索引数据页进行变更，而这些数据页又不在buffer pool中的时候，会使用Change Buffer来缓存这些变更。这些INSERT, UPDATE, 或者 DELETE 操作（DML）带来的变更会在这些数据页被其他读操作加载进缓存的时候被合并。简单来讲，Change Buffer是用来”懒合并”，将非必需的磁盘读写延后。因此适合写多读少的业务情景。另外，唯一索引无法使用ChangeBuffer，因此一般推荐优先使用普通索引。</p></li></ul><h2 id="MySQL误判索引解决办法"><a href="#MySQL误判索引解决办法" class="headerlink" title="MySQL误判索引解决办法"></a>MySQL误判索引解决办法</h2><ul><li>对于由于索引统计信息不准确导致的问题，你可以用 analyze table 来解决；例如，使用delete来删除数据，会导致统计信息不准。</li><li>对于其他优化器误判的情况，你可以在应用端用 force index 来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入 MySQL (三) 事务</title>
      <link href="/2021/02/04/%E6%B7%B1%E5%85%A5-MySQL-3-%E4%BA%8B%E5%8A%A1/"/>
      <url>/2021/02/04/%E6%B7%B1%E5%85%A5-MySQL-3-%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<p>从前文，我们了解到有一部分存储引擎是支持事务的。本文我们将探讨事务的重要概念以及实现原理。</p><span id="more"></span><h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><h2 id="ACID概念"><a href="#ACID概念" class="headerlink" title="ACID概念"></a>ACID概念</h2><p>ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）</p><h2 id="隔离性和隔离级别"><a href="#隔离性和隔离级别" class="headerlink" title="隔离性和隔离级别"></a>隔离性和隔离级别</h2><p>SQL标准里定义了四种事务隔离级别：</p><ul><li><strong>读未提交</strong>：一个事务还没提交时，它做的变更就能被别的事务看到；</li><li><strong>读提交</strong>：一个事务提交之后，它做的变更才会被其他事务看到；</li><li><strong>可重复读</strong>：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的；</li><li><strong>串行化</strong>：对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li></ul><p>四种隔离级别区别：</p><table><thead><tr><th>隔离级别</th><th>脏读可能性</th><th>不可重复读可能性</th><th>幻读可能性</th><th>加锁读</th></tr></thead><tbody><tr><td>读未提交</td><td>Y</td><td>Y</td><td>Y</td><td>N</td></tr><tr><td>读提交</td><td>N</td><td>Y</td><td>Y</td><td>N</td></tr><tr><td>可重复读</td><td>N</td><td>N</td><td>Y</td><td>N</td></tr><tr><td>串行化</td><td>N</td><td>N</td><td>N</td><td>Y</td></tr></tbody></table><h2 id="MySQL中的事务"><a href="#MySQL中的事务" class="headerlink" title="MySQL中的事务"></a>MySQL中的事务</h2><p>MySQL提供了两种事务型存储引擎：InnoDB 和 NDB Cluster，而MyISAM并不支持事务。</p><h3 id="MVCC与事务隔离实现"><a href="#MVCC与事务隔离实现" class="headerlink" title="MVCC与事务隔离实现"></a>MVCC与事务隔离实现</h3><h2 id="四种隔离级别的在InnoDB实现：-读未提交：直接返回记录上的最新值，没有视图概念；-读提交：在每个SQL语句开始执行的时候创建视图；-可重复读：在事务启动时创建视图，整个事务存在期间都用这个视图；（注意，InnoDB利用MVCC已经在可重复读隔离级别下避免了幻读问题！！注意和上边的表格内容区分清楚！！！）-串行化：隔离级别下直接用加锁的方式来避免并行访问。"><a href="#四种隔离级别的在InnoDB实现：-读未提交：直接返回记录上的最新值，没有视图概念；-读提交：在每个SQL语句开始执行的时候创建视图；-可重复读：在事务启动时创建视图，整个事务存在期间都用这个视图；（注意，InnoDB利用MVCC已经在可重复读隔离级别下避免了幻读问题！！注意和上边的表格内容区分清楚！！！）-串行化：隔离级别下直接用加锁的方式来避免并行访问。" class="headerlink" title="四种隔离级别的在InnoDB实现：- 读未提交：直接返回记录上的最新值，没有视图概念；- 读提交：在每个SQL语句开始执行的时候创建视图；- 可重复读：在事务启动时创建视图，整个事务存在期间都用这个视图；（注意，InnoDB利用MVCC已经在可重复读隔离级别下避免了幻读问题！！注意和上边的表格内容区分清楚！！！）- 串行化：隔离级别下直接用加锁的方式来避免并行访问。"></a>四种隔离级别的在InnoDB实现：<br>- <strong>读未提交</strong>：直接返回记录上的最新值，没有视图概念；<br>- <strong>读提交</strong>：在每个SQL语句开始执行的时候创建视图；<br>- <strong>可重复读</strong>：在事务启动时创建视图，整个事务存在期间都用这个视图；（注意，InnoDB利用MVCC已经在可重复读隔离级别下避免了幻读问题！！注意和上边的表格内容区分清楚！！！）<br>- <strong>串行化</strong>：隔离级别下直接用加锁的方式来避免并行访问。</h2><blockquote><p>这个所谓的视图其实是通过多版本并发控制（MVCC）来实现。（详情见《高性能MySQL》第三版 1.4 多版本并发控制）</p></blockquote><h3 id="事务的启动"><a href="#事务的启动" class="headerlink" title="事务的启动"></a>事务的启动</h3><p>事务启动方式：</p><ul><li>1.显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。</li><li>2.set autocommit&#x3D;0，这个命令会将这个线程的自动提交关掉（注意，仅影响当前线程。）。这意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。一般建议总是使用 set autocommit&#x3D;1, 然后通过显式语句的方式来启动事务。</li></ul><p>长事务会导致数据库空间，并且占用所资源，生产中应该尽量避免长事务。查询长事务方法：</p><pre><code class="sql">// 查询超过60秒的事务select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60</code></pre><h3 id="查看修改事务隔离级别"><a href="#查看修改事务隔离级别" class="headerlink" title="查看修改事务隔离级别"></a>查看修改事务隔离级别</h3><p>MySQL默认的事务隔离级别是可重复读（REPEATABLE READ）。</p><p>可以通过sql查看MySQL事务隔离级别：</p><pre><code class="sql">show variables like &quot;%isolation%&quot;;</code></pre><p>MySQL提供了SET TRANSACTION语句，该语句可以改变单个会话或全局的事务隔离级别。语法格式如下：</p><pre><code class="sql">SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL &#123;READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE&#125;</code></pre><p>其中，SESSION 和 GLOBAL 关键字用来指定修改的事务隔离级别的范围：</p><ul><li>SESSION：表示修改的事务隔离级别将应用于当前 session（当前 cmd 窗口）内的所有事务；</li><li>GLOBAL：表示修改的事务隔离级别将应用于所有 session（全局）中的所有事务，且当前已经存在的 session (包括当前session）不受影响；</li><li>如果省略 SESSION 和 GLOBAL，表示修改的事务隔离级别将应用于当前 session 内的下一个还未开始的事务。</li></ul><p>任何用户都能改变会话的事务隔离级别，但是只有拥有 SUPER 权限的用户才能改变全局的事务隔离级别。</p><h3 id="其他注意"><a href="#其他注意" class="headerlink" title="其他注意"></a>其他注意</h3><ul><li>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。具体见：<a href="https://time.geekbang.org/column/article/70562">08 | 事务到底是隔离的还是不隔离的？</a></li></ul><h1 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h1><p>-<a href="https://juejin.im/post/6874330052461330446">理解MySQL的锁机制和事务原理</a></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入 MySQL (二) 文件系统</title>
      <link href="/2021/01/30/%E6%B7%B1%E5%85%A5-MySQL-2-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
      <url>/2021/01/30/%E6%B7%B1%E5%85%A5-MySQL-2-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<p>本文介绍 MySQL 的几个重要的日志文件以及两阶段提交的原理。</p><span id="more"></span><h1 id="binlog（二进制日志）"><a href="#binlog（二进制日志）" class="headerlink" title="binlog（二进制日志）"></a>binlog（二进制日志）</h1><ul><li>binlog 是MySQL Server 层的逻辑日志，可以被所有存储引擎使用；</li><li>binlog 日志常用于数据恢复、复制以及审计；</li><li>binlog 可以是 ROW、 STATEMENT、MIXED 三种格式：<ul><li>ROW 格式下 binlog 日志记录的是每个数据行变化前和变化后的内容，因此占用空间相对较大；</li><li>STATEMENT格式 下，binlog 日志记录的是执行的 SQL 语句；</li><li>MIXED 格式下，默认采用 STATEMENT 格式，某些情况下会选择性地采用 ROW 格式；</li></ul></li><li>仅凭 binlog 日志是不能确保MySQL crash-safe的；</li><li>binlog日志是顺序追加写到磁盘文件，文件达到一定大小后会切换到下一个，因此不会发生数据覆盖；</li><li>重要主库推荐配置 <em>sync_binlog&#x3D;1</em> ，可以使得MySQL每次提交事务都会将binlog日志同步到磁盘上，保证服务器崩溃的时候不会丢失数据；此外，如果是 Innodb 引擎，还需要配置 innodb_support_xa 为 1，才能确保二进制日志与 InnoDB 存储数据文件的同步（也就是下文的两阶段提交确保不丢失数据）。</li></ul><h1 id="redo-log（重做日志）"><a href="#redo-log（重做日志）" class="headerlink" title="redo log（重做日志）"></a>redo log（重做日志）</h1><ul><li><p>redo log是InnoDB引擎特有的物理日志；</p></li><li><p>WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘数据；</p></li><li><p>redo log记录的是某个数据页做了什么修改；</p></li><li><p>凭借redo log可以确保InnoDB的crash-safe；凭借redo log和binlog实现的两阶段提交可以保障MySQL的crash-safe；</p></li><li><p>redo log日志是固定大小的循环写，超过文件大小会擦除老日志；</p><p>  <img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2Fmysql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%B8%80%20%E5%9F%BA%E7%A1%80%E7%AF%87%2Fredo%20log%E5%BE%AA%E7%8E%AF%E5%86%99.png" alt="redo log循环写.png"></p></li><li><p>重做日志并不是直接写日志文件，而是先写一个重做日志缓冲（redo log buffer），然后再按照一定条件顺序写入日志文件。常见条件包括：</p><ul><li>主库配置 <em>innodb_flush_log_at_trx_commit&#x3D;1</em> ，可以使得每次提交事务都会将 buffer 刷到日志文件，保证服务器崩溃的时候不会丢失数据；</li><li>主线程每秒会将重做日志缓冲写入日志文件，不论事务是否已经提交。</li></ul></li></ul><h1 id="undo-log-回滚日志"><a href="#undo-log-回滚日志" class="headerlink" title="undo log (回滚日志)"></a>undo log (回滚日志)</h1><ul><li>回滚日志记录的是事务的行为，当事务由于某种原因执行失败或者用户手动回滚的时候，便可以通过回滚日志来恢复缓冲池数据至历史版本；</li><li>回滚日志默认保存在共享表空间中（也就是 ibdata 文件中）；如果配置了 innodb_undo_tablespaces&#x3D;N，则会保存到单独的undo001~undoN 文件中；</li></ul><h1 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h1><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E6%B7%B1%E5%85%A5%20MySQL%20%28%E4%BA%8C%29%20MySQL%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%2F%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4.png" alt="两阶段提交.png"></p><p>两阶段提交过程：</p><ul><li>1.新数据更新到内存；</li><li>2.新数据写入redo log，并处于prepare状态；</li><li>3.写入binlog；</li><li>4.提交事务，使redo log 更新为commit状态。</li></ul><p>crash-safe保障原理：</p><ul><li>如果在步骤2之前数据库宕机，因为redo log 和binlog都没写入，内存数据丢失，所以不影响一致性；</li><li>如果在步骤3之前数据库宕机，因为redo log存在且处于prepare状态，但检查binlog发现不存在，则回滚事务。所以不影响数据一致性；</li><li>如果在步骤4之前数据库宕机，因为redo log存在且处于prepare状态，而检查binlog发现存在，则执行步骤4。所以事务成功，也不影响数据一致性；</li><li>如果在步骤4之后数据库宕机，因为redo log存在且处于commit状态。所以不影响数据一致性。</li></ul><p>binlog和redo log的联系：</p><blockquote><p>它们有一个共同的数据字段，叫XID。崩溃恢复的时候，会按顺序扫描redo log：如果碰到commit状态的redo log，就直接提交；如果碰到只有 parepare状态的redo log，就拿着XID去binlog找对应的事务。</p></blockquote><h1 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h1><ul><li><a href="https://time.geekbang.org/column/intro/100020801">MySQL实战45讲</a>: 非常适合入门的MySQL学习资料；</li><li>《高性能MySQL》</li><li>《MySQL技术内幕（InnoDB存储引擎）》</li><li><a href="https://blog.51cto.com/gfsunny/1566683">浅谈参数innodb_undo_tablespaces</a></li><li><a href="https://www.cnblogs.com/andy6/p/9734885.html">MySQL 5.7新特性之在线收缩undo表空间</a></li><li><a href="https://juejin.im/post/6844903621495095309">分布式理论(三) - 2PC协议</a></li><li><a href="https://time.geekbang.org/column/article/207508">05 | 分布式事务：如何保证多个系统间的数据是一致的？</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入 MySQL (一) 体系结构</title>
      <link href="/2021/01/29/%E6%B7%B1%E5%85%A5-MySQL-1-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
      <url>/2021/01/29/%E6%B7%B1%E5%85%A5-MySQL-1-%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<p>工作中常常用到 MySQL，但对 MySQL 底层原理不够熟悉。知其然，知其所以然。所以我决定深入学习 MySQL 底层知识，并产出一些备忘笔记。本文主要介绍 MySQL 的体系结构。</p><span id="more"></span><h1 id="MySQL-体系结构"><a href="#MySQL-体系结构" class="headerlink" title="MySQL 体系结构"></a>MySQL 体系结构</h1><p>MySQL主要划分为两个部分：Server 层和存储引擎层。</p><p><strong>Server层</strong>：实现了大部分核心功能（内置函数、存储过程、触发器、视图等等），组成模块包括连接器、查询缓存、解析器、优化器以及执行器等等；<br><strong>存储引擎层</strong>：实现数据的存储和读取，向 Server 层提供操作数据的接口。支持插拔，可选的类型包括：InnoDB、MyISAM、Memory等。最常用的是 InnoDB，它从MySQL 5.5.8后成为默认存储引擎。</p><p>下图展示 MySQL 官方文档提供的体系结构图：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E6%B7%B1%E5%85%A5%20MySQL%20%28%E4%B8%80%29%20MySQL%20%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%2FMySQL%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.png" alt="MySQL体系架构.png"></p><p>下图展示的是简化后的 MySQL 的基本架构图。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2Fmysql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E4%B8%80%20%E5%9F%BA%E7%A1%80%E7%AF%87%2Fmysql%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" alt="MySQL架构图.jpg"></p><p>下面展示使用 InnoDB 引擎的体系结构图以及 SQL 执行过程：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E6%B7%B1%E5%85%A5%20MySQL%20%28%E4%B8%80%29%20MySQL%20%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%2FMySQL%2BInnoDB%20%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E5%9B%BE.png" alt="MySQL+InnoDB 体系结构图.png"></p><h2 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h2><p>连接器就像是MySQL的“门神”，它负责跟客户端建立连接、获取权限、维持和管理连接。</p><ul><li><p>查看连接情况</p><pre><code class="sql">mysql&gt; show processlist;+------+------+-----------+------+---------+-------+----------+------------------+| Id   | User | Host      | db   | Command | Time  | State    | Info             |+------+------+-----------+------+---------+-------+----------+------------------+| 1530 | root | localhost | NULL | Sleep   | 44800 |          | NULL             || 1531 | root | localhost | qds  | Query   |     0 | starting | show processlist |+------+------+-----------+------+---------+-------+----------+------------------+2 rows in set (0.03 sec)</code></pre></li><li><p>连接空闲超时会自动断开，可以通过 wait_timeout 参数控制，默认8小时；</p></li><li><p>客户端不应频繁新建连接，尽量使用长连接；</p></li><li><p>连接应该定时断开或者执行 mysql_reset_connection 重新初始化连接资源，避免占用过多内存；</p></li><li><p>数据库账号权限的变更不会影响已建立的连接，只有该连接断开重连才会生效。常见的 JDBC 连接池都带有定时重连的功能，比如 HikariPool：</p><pre><code class="java">private PoolEntry createPoolEntry() &#123;  try &#123;     final PoolEntry poolEntry = newPoolEntry();     // 连接最大存活时间     final long maxLifetime = config.getMaxLifetime();     if (maxLifetime &gt; 0) &#123;        // variance up to 2.5% of the maxlifetime        final long variance = maxLifetime &gt; 10_000 ? ThreadLocalRandom.current().nextLong( maxLifetime / 40 ) : 0;        final long lifetime = maxLifetime - variance;        // 定时任务检查连接是否空闲，空闲的连接将会被关闭        poolEntry.setFutureEol(houseKeepingExecutorService.schedule(new Runnable() &#123;           @Override           public void run() &#123;              softEvictConnection(poolEntry, &quot;(connection has passed maxLifetime)&quot;, false /* not owner */);           &#125;        &#125;, lifetime, MILLISECONDS));     &#125;     LOGGER.debug(&quot;&#123;&#125; - Added connection &#123;&#125;&quot;, poolName, poolEntry.connection);     return poolEntry;  &#125;  catch (Exception e) &#123;     if (poolState == POOL_NORMAL) &#123;        LOGGER.debug(&quot;&#123;&#125; - Cannot acquire connection from data source&quot;, poolName, e);     &#125;     return null;  &#125;&#125;</code></pre></li></ul><h2 id="解析器"><a href="#解析器" class="headerlink" title="解析器"></a>解析器</h2><p>解析器有两个功能：</p><ul><li><strong>词法分析</strong>：将SQL语句数据库表列建立关联；</li><li><strong>语法分析</strong>：检测SQL语句是否符合MySQL语法规则。</li></ul><h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p>优化器负责从不同的执行计划中选出效率最高的方案，包括决定表的连接顺序、选择哪个索引等等。此外还会涉及查询重写。</p><h2 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h2><p>执行器主要是负责检查表权限，并且调用存储引擎的接口完成执行计划，写binlog日志等。</p><h2 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h2><p>对于SELECT语句，在解析查询之前，服务器会先检查查询缓存。如果能在缓存中找到对应的查询，服务器可以直接返回缓存的结果，而不必进行解析、优化和执行等过程。</p><blockquote><p>注意，频繁更新的表的查询缓存会频繁失效，不建议开启查询缓存。MySQL 8.0 版本后不再支持查询缓存。</p></blockquote><h2 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h2><p>MySQL 支持多种存储引擎，用户在新建表的时候可以自定义指定该表采用的存储引擎。用户也可以根据 MySQL 提供的接口定义，实现自定义的存储引擎。</p><p>最常用的第三方存储引擎是 InnoDB。在MySQL 5.5.8后，它成为默认存储引擎。</p><h3 id="InnoDB-存储引擎"><a href="#InnoDB-存储引擎" class="headerlink" title="InnoDB 存储引擎"></a>InnoDB 存储引擎</h3><p>InnoDB 主要特点是：</p><ul><li>支持行锁、支持外键，并支持非锁定的读；</li><li>每张表数据单独保存到一个独立的 idb 文件中；</li><li>通过多版本并发控制（MVCC）来实现高并发特性，并且实现 SQL 标准的4种事务隔离级别，默认为可重复读；</li><li>使用间隙锁（next-key locking）来避免幻读现象产生；</li><li>每张表的主键都采用聚簇索引，如果没有显式指定主键，则默认自动生成一个6字节的 row_id 作为主键。</li></ul><h3 id="MyISAM-存储引擎"><a href="#MyISAM-存储引擎" class="headerlink" title="MyISAM 存储引擎"></a>MyISAM 存储引擎</h3><p>MyISAM 主要特点是：</p><ul><li>MySQL 5.5.8 版本之前的默认存储引擎；</li><li>不支持事务；</li><li>不支持行锁，只支持表锁；</li><li>支持全文索引；</li><li>存储引擎表由 MYD 和 MYI 组成，MYD 用来存放数据文件，MYI 用来存放索引文件。</li></ul><h3 id="其他存储引擎"><a href="#其他存储引擎" class="headerlink" title="其他存储引擎"></a>其他存储引擎</h3><p>NDB 存储引擎、Memory 存储引擎、Archive 存储引擎、Federated 存储引擎、Maria 存储引擎等等。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://time.geekbang.org/column/intro/100020801">MySQL实战45讲</a>: 非常适合入门的MySQL学习资料；</li><li>《高性能MySQL》</li><li>《MySQL技术内幕（InnoDB存储引擎）》</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> 数据库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 虚拟机原理 (五) G1垃圾收集器深入</title>
      <link href="/2021/01/11/Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86-5-G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E6%B7%B1%E5%85%A5/"/>
      <url>/2021/01/11/Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86-5-G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E6%B7%B1%E5%85%A5/</url>
      
        <content type="html"><![CDATA[<p>深入了解G1垃圾收集器背后的核心原理。</p><span id="more"></span><h2 id="三色标记"><a href="#三色标记" class="headerlink" title="三色标记"></a>三色标记</h2><p>CMS收集器使用了Incremental Update算法，而G1收集器使用的是SATB算法。这两者背后的思想都使用了三色标记算法，标记算法如下：</p><ul><li>黑色(black):自己已经被标记，且字段全部标记完毕的对象；</li><li>灰色(gray): 自己已经被标记，但尚有字段未被标记的对象（collector正在访问的对象）；</li><li>白色(white):尚未标记对象。</li></ul><p><strong>注意：</strong> 标记结束后，被标记的对象是存活对象，没有被标记的对象会被回收。</p><p>在并行GC阶段，应用线程和GC形成并行。如果一个白对象被灰对象引用着，那么这个白对象被漏标的充分必要条件是：</p><ul><li>1.mutator 新增了一个黑对象到该白对象的引用；</li><li>2.mutator 删除了所有灰对象到该白对象的引用。</li></ul><blockquote><p>解释：<br>黑对象持有了指向白对象的引用。根据定义，collector已经不会再去遍历黑对象的字段，所以发现不了这里还有一个活引用指向这个白对象。如果还有某个灰对象持有直接或间接引用能到达这个白对象，那就没关系；如果从灰对象出发的所有引用到这个白对象的路径都不幸被切断了，那这个白对象就要被漏扫描了。<br>所以如果同时发生以上两种情况，会导致对象漏标而被回收掉。</p></blockquote><p>为了解决漏标问题。</p><ul><li>CMS 采用写屏障和 Incremental Update 算法，致力于打破第一个条件。做法是只要在写屏障里发现要有一个白对象的引用被赋值到一个黑对象的字段里，那就把这个白对象变成灰色的（就是标记为存活对象，常见做法是标记并压到marking stack上，或者是记录在类似mod-union table里）。这样就强力杜绝了上述第一种情况的发生。</li><li>G1 则采用写屏障和 SATB 算法，致力于打破第二个条件。SATB 的原理是是把标记开始时的逻辑快照里所有的活对象都看作时活的，而 NextTAMS 指针之后的的对象也在这一个周期里隐式存活，并且在写屏障中把变更前的对象引用都记录下来，都作为存活对象保留到下一个周期。（已经黑灰就不用管，还是白的就变成灰的）。</li></ul><p>无论 CMS 抑或是 G1 都会产生浮动垃圾。</p><h2 id="SATB"><a href="#SATB" class="headerlink" title="SATB"></a>SATB</h2><p>SATB（snapshot at the beginning)是G1并发理论的基础，用于维护确保回收过程的正确性。从名字上理解，就是GC在开始的时候先对活着的对象保存一个快照；</p><p>接下来，在GC过程中新分配的对象都是活的。</p><p>很容易知道哪些对象是一次GC开始之后新分配的：每个region记录着两个top-at-mark-start（TAMS）指针，分别为prevTAMS和nextTAMS。并发标记开始时候Top指针和NextTAMS指针是重合的（如下图所示），并发阶段分配的对象对位于[Next TAMS，Top]区间。这个区间内的对象默认都是存活的，这也叫做隐式标记。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E6%B7%B1%E5%85%A5%2Fg1gc-tams.png" alt="g1gc-tams.png"></p><p>但如果在Next TAMS之前有一个白色对象A被一个灰色对象B作为字段而引用，在并发标记扫描到这个字段之前，被赋值为null，那么B–&gt;A的引用关系被切断，可能会导致白色对象A被漏标。</p><p>G1为了解决这个问题，在引用关系修改之前，插入一层pre-write barrier。pre-write barrier会把每次引用关系变化时旧的引用值记录下来。这些引用值会被放置到satb mark queue中，在下一次的并发标记阶段，会依次处理satb mark queue中的对象，确保这部分对象在本轮GC是存活的。</p><pre><code class="c++">void G1SATBCardTableModRefBS::enqueue(oop pre_val) &#123;  // Nulls should have been already filtered.  assert(pre_val-&gt;is_oop(true), &quot;Error&quot;);  if (!JavaThread::satb_mark_queue_set().is_active()) return;  Thread* thr = Thread::current();  if (thr-&gt;is_Java_thread()) &#123;    JavaThread* jt = (JavaThread*)thr;    jt-&gt;satb_mark_queue().enqueue(pre_val);  &#125; else &#123;    MutexLockerEx x(Shared_SATB_Q_lock, Mutex::_no_safepoint_check_flag);    JavaThread::satb_mark_queue_set().shared_satb_queue()-&gt;enqueue(pre_val);  &#125;&#125;</code></pre><p>但这很可能有对象在snapshot中是活的，但随着并发GC的进行它可能本来已经死了，但SATB还是会让它活过这次GC。这就导致所谓的浮动垃圾。</p><h2 id="RSet"><a href="#RSet" class="headerlink" title="RSet"></a>RSet</h2><p> <strong>该章节摘录自<a href="https://tech.meituan.com/2016/09/23/g1.html">Java Hotspot G1 GC的一些关键技术</a></strong></p><p>全称是Remembered Set，是辅助GC过程的一种结构，典型的空间换时间工具，和Card Table有些类似。还有一种数据结构也是辅助GC的：Collection Set（CSet），它记录了GC要收集的Region集合，集合里的Region可以是任意年代的。在GC的时候，对于old-&gt;young和old-&gt;old的跨代对象引用，只要扫描对应的CSet中的RSet即可。 逻辑上说每个Region都有一个RSet，RSet记录了其他Region中的对象引用本Region中对象的关系，属于points-into结构（谁引用了我的对象）。而Card Table则是一种points-out（我引用了谁的对象）的结构，每个Card 覆盖一定范围的Heap（一般为512Bytes）。G1的RSet是在Card Table的基础上实现的：每个Region会记录下别的Region有指向自己的指针，并标记这些指针分别在哪些Card的范围内。 这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。</p><p>下图表示了RSet、Card和Region的关系（<a href="http://www.infoq.com/articles/tuning-tips-G1-GC">出处</a>）：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E6%B7%B1%E5%85%A5%2FRemembered%20Sets.jpg" alt="Remembered Sets.jpg"></p><p>上图中有三个Region，每个Region被分成了多个Card，在不同Region中的Card会相互引用，Region1中的Card中的对象引用了Region2中的Card中的对象，蓝色实线表示的就是points-out的关系，而在Region2的RSet中，记录了Region1的Card，即红色虚线表示的关系，这就是points-into。 而维系RSet中的引用关系靠post-write barrier和Concurrent refinement threads来维护，操作伪代码如下（<a href="http://hllvm.group.iteye.com/group/topic/44381">出处</a>）：</p><pre><code class="c++">void oop_field_store(oop* field, oop new_value) &#123;  pre_write_barrier(field);             // pre-write barrier: for maintaining SATB invariant  *field = new_value;                   // the actual store  post_write_barrier(field, new_value); // post-write barrier: for tracking cross-region reference&#125;</code></pre><p>post-write barrier记录了跨Region的引用更新，更新日志缓冲区则记录了那些包含更新引用的Cards。一旦缓冲区满了，Post-write barrier就停止服务了，会由Concurrent refinement threads处理这些缓冲区日志。 RSet究竟是怎么辅助GC的呢？在做YGC的时候，只需要选定young generation region的RSet作为根集，这些RSet记录了old-&gt;young的跨代引用，避免了扫描整个old generation。 而mixed gc的时候，old generation中记录了old-&gt;old的RSet，young-&gt;old的引用由扫描全部young generation region得到，这样也不用扫描全部old generation region。所以RSet的引入大大减少了GC的工作量。</p><p><strong>学习资料</strong></p><ul><li><a href="https://github.com/authorNari/g1gc-impl-book">彻底解剖G1GC</a></li><li><a href="https://tech.meituan.com/2016/09/23/g1.html">Java Hotspot G1 GC的一些关键技术</a></li><li><a href="https://hllvm-group.iteye.com/group/topic/44381">RednaxelaFX的论坛回复帖</a></li><li><a href="http://fleurer.github.io/2018/07/11/note-on-g1gc-barriers/">F叔的学习笔记</a></li><li><a href="https://www.oracle.com/technical-resources/articles/java/g1gc.html">Garbage First Garbage Collector Tuning</a></li><li><a href="http://book.douban.com/subject/6809987/">The Garbage Collection Handbook</a></li><li><a href="https://www.jianshu.com/p/9e70097807ba">G1垃圾收集器之SATB</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
            <tag> 垃圾回收器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 虚拟机原理 (四) G1垃圾收集器入门</title>
      <link href="/2021/01/10/Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86-4-G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8/"/>
      <url>/2021/01/10/Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86-4-G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<p>本文翻译自<a href="https://www.oracle.com/webfolder/technetwork/tutorials/obe/java/G1GettingStarted/index.html">《Getting Started with the G1 Garbage Collector》</a></p><span id="more"></span><h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><h3 id="本文目的"><a href="#本文目的" class="headerlink" title="本文目的"></a>本文目的</h3><p>本教程介绍了如何使用G1垃圾收集器以及如何在Hostspot虚拟机中使用它。你可以学习到G1垃圾收集器的内部运行机制、切换到使用G1垃圾回收器的命令行关键参数以及打印GC日志的选项参数。</p><h3 id="预估阅读时间"><a href="#预估阅读时间" class="headerlink" title="预估阅读时间"></a>预估阅读时间</h3><p>大概1小时</p><h3 id="本文简介"><a href="#本文简介" class="headerlink" title="本文简介"></a>本文简介</h3><p>本教程详细介绍了Java语言的G1垃圾收集器。主要内容分为五部分：</p><ul><li>通过介绍垃圾收集器以及性能来了解JVM虚拟机；</li><li>逐步分析G1垃圾收集器的每一个过程；</li><li>回顾CMS收集器的每一个过程；</li><li>介绍G1垃圾收集器可用的一些选项参数；</li><li>介绍G1垃圾收集器的日志参数。</li></ul><h2 id="软硬件配置要求"><a href="#软硬件配置要求" class="headerlink" title="软硬件配置要求"></a>软硬件配置要求</h2><p>以下是软硬件要求列表：</p><ul><li>PC(Window XP或更新、Mac OS X、Linux)</li><li>Java 7u9 或更新版本</li><li>最新的Java 7样例以及压缩包</li></ul><h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><p>在开始本教程之前，你需要：</p><ul><li>下载安装最新的JDK（JDK 7u9或更新版本）<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">JDK 7下载地址</a></li><li>下载解压样例压缩包到相应目录，例如：C:\javademos</li></ul><h2 id="Java以及JVM技术"><a href="#Java以及JVM技术" class="headerlink" title="Java以及JVM技术"></a>Java以及JVM技术</h2><h3 id="Java概览"><a href="#Java概览" class="headerlink" title="Java概览"></a>Java概览</h3><p>Java是Sun Microsystems公司在1995年第一次发布的一门编程语言。它是构建包括游戏、商业、基础设施等Java应用程序的底层技术。在全世界范围内，Java运行在超过8.5亿个人电脑以及数十亿的手机电视设备上。总体上看，Java平台由以下几个关键的组件构成。</p><h4 id="Java运行时版本"><a href="#Java运行时版本" class="headerlink" title="Java运行时版本"></a>Java运行时版本</h4><p>当你下载Java的时候，你可以获取Java运行时环境（JRE）。JRE是由Java虚拟机（JVM）、Java平台核心类和支撑Java平台的库构成。这三者都是Java应用运行所必需的组件。通过Java7，Java应用在个人电脑上的运行形式可以是操作系统桌面应用，也可以是通过Java Web Start从Web上安装的桌面应用，或者是内嵌在浏览器中的Web应用（使用JavaFX)</p><h4 id="Java编程语言"><a href="#Java编程语言" class="headerlink" title="Java编程语言"></a>Java编程语言</h4><p>Java是一门面向对象编程语言，包含以下特性：</p><ul><li>平台独立性 - Java应用会被编译成保存在class文件中的字节码，并且被加载进虚拟机中。因为Java应用总是运行在虚拟机中，所以Java应用可以运行在各种不同的操作系统和设备上；</li><li>面向对象 - Java是一门面向对象的编程语言，具有很多与C、C++类似特性，并对其进行了改进；</li><li>全自动垃圾收集 - Java会自动分配和回收内存，程序中无需关心这个过程；</li><li>丰富的库资源 - Java有大量预置的类库可以进行诸如IO、网络传输、日期操作等任务。</li></ul><h4 id="Java开发工具包"><a href="#Java开发工具包" class="headerlink" title="Java开发工具包"></a>Java开发工具包</h4><p>Java开发工具包 The Java Development Kit (JDK) 是用来开发Java应用的一系列工具。通过JDK，你可以编译Java应用，并且运行在JVM中。此外JDK提供了打包和分发你的应用的工具。</p><p>JDK和JRE共用了Java应用编程接口（Java API）。Java API是用来创建Java应用的一系列预编译库。它使得开发一些常用的程序更加便捷，比如：字符串操作、日期时间处理、网络传输、实现数据结构（例如 lists, maps, stacks, and queues)。</p><h4 id="Java虚拟机"><a href="#Java虚拟机" class="headerlink" title="Java虚拟机"></a>Java虚拟机</h4><p>Java虚拟机（JVM）是一个抽象的计算机器。JVM本质上是一个程序，它就像一台机器一样写入程序并且执行。因此，所有的Java程序都按照同一套接口和库写入到JVM中。每一个针对特定操作系统的JVM实现都将Java程序指令翻译为本地操作系统中的指令。这样，Java就实现了平台独立性。</p><p>Java虚拟机的第一个原型是由Sun Microsystems完成的，它在一个类似现在的个人数字代理（PDA）的手持设备上模拟了Java虚拟机指令集。现在Oracle已经实现在移动、桌面和服务器设备上模拟 Java 虚拟机，但Java虚拟机不承担任何特定的实现技术、主机硬件或操作系统。</p><p>（非关键内容，此处略）</p><h3 id="探究JVM架构"><a href="#探究JVM架构" class="headerlink" title="探究JVM架构"></a>探究JVM架构</h3><h4 id="Hotspot架构"><a href="#Hotspot架构" class="headerlink" title="Hotspot架构"></a>Hotspot架构</h4><p>HotSpot JVM 拥有一个支持强大特性和功能基础的架构，并支持实现高性能和大规模扩展性。例如HostSpot JVM JIT编译器生成动态优化。换句话说，是在运行 Java 应用程序时做出优化决策，并生成针对底层系统体系结构的高性能本地指令。此外，经过对它的运行时环境和多线程垃圾收集器的不断的成熟进化和持续的研发，HostSpot JVM在现今所有操作系统中都有很高的可拓展性。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog/G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8/HotspotJVM%E6%9E%B6%E6%9E%84.png" alt="HotSpot JVM架构图"></p><p>JVM主要的组件包括类加载器、运行时数据区域以及执行引擎。（the class loader, the runtime data areas, and the execution engine）</p><h4 id="HotSpot核心组件"><a href="#HotSpot核心组件" class="headerlink" title="HotSpot核心组件"></a>HotSpot核心组件</h4><p>JVM中与性能表现有关的核心组件已在下图高亮显示。<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog/G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8/JVM%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6.png" alt="JVM核心组件"></p><p>在调优JVM性能的时候，主要关注这三个组件。堆(heap)是你的对象数据存储的区域。该区域由程序启动指定的垃圾收集器管理。大多数调优选项都跟调整堆大小和选择最合适的垃圾回收器相关。JIT编译器对性能也有很大影响，但是在较新版本的JVM里很少需要调优。</p><h3 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h3><p>通常在调优Java应用的时候，会关注两个主要的指标：响应时间和吞吐量。</p><h4 id="响应时间"><a href="#响应时间" class="headerlink" title="响应时间"></a>响应时间</h4><p>响应时间就是应用或者系统应答所请求的数据的用时。例如：</p><ul><li>桌面UI响应时间用时；</li><li>网站返回一个页面用时；</li><li>数据库查询返回用时。</li></ul><p>对所有的对响应时间敏感的应用来说，很长的暂停时间是不能接受的。此时应当关注实现更短的应答时间。</p><h4 id="吞吐量"><a href="#吞吐量" class="headerlink" title="吞吐量"></a>吞吐量</h4><p>吞吐量指标关注的是该应用在一段时间内能处理的最大工作量。例如：</p><ul><li>一段时间内完成的事务数量；</li><li>一个批处理程序一个小时内完成的任务数量；</li><li>数据库在一个小时内完成的查询数量。</li></ul><p>长暂停对这些关注吞吐量的应用来说是可以接受的。因为高吞吐量应用关注的一段时间内的基准测试，而快速响应并不是一个考量点。</p><h2 id="G1垃圾收集器"><a href="#G1垃圾收集器" class="headerlink" title="G1垃圾收集器"></a>G1垃圾收集器</h2><p>G1垃圾收集器（Garbage-First collector）是一个面向多核心大内存机器的服务端收集器。<br>它能以大概率满足垃圾收集暂停时间目标，同时实现高吞吐量。Oracle JDK 7u4以及更新版本完全支持G1垃圾收集器。G1收集器专门为以下应用而设计：</p><ul><li>能够像CMS垃圾收集器一样和应用线程并发执行；</li><li>无需较长的GC停顿时间来实现内存压缩；</li><li>需要更可预测的GC暂停时间；</li><li>不希望牺牲大量的吞吐量性能；</li><li>不需要更大的Java堆空间。</li></ul><p>G1计划作为CMS的长期替代。G1和CMS相比，两者的许多不同点使得G1成为更好的解决方案。其中一个不同就是G1是一个能内存压缩的收集器。G1的内存压缩使得能够完全避免使用细粒度的空闲列表来分配内存，而是依靠regions。这大大简化了垃圾收集器，并大大消除了潜在的碎片化问题。另外，G1比CMS提供了更可预测的垃圾收集暂停时间，允许用户指定期望的暂停时间。</p><h3 id="G1-回收过程概览"><a href="#G1-回收过程概览" class="headerlink" title="G1 回收过程概览"></a>G1 回收过程概览</h3><p>以前的垃圾收集器（serial, parallel, CMS）都将堆划分为特定内存大小的3部分：年轻代、老年代和永久代。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog/G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8/Hotspot%20Heap%20Structure.png" alt="Hotspot Heap Structure"></p><p>所有的内存对象最终都会位于这三部分之一。<br>但G1垃圾收集器采用了不同的方法。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog/G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8/G1%20Heap%20Allocation.png" alt="G1 Heap Allocation"></p><p>堆内存被划分成一系列相同大小的连续虚拟内存的区块（region）。这些区块都被分配了和以前收集器相同的角色（比如 eden, survivor, old），但相同角色的区块数量不是确定的。这使得堆内存使用上有非常大的灵活性。</p><p>当执行垃圾收集的时候，G1的工作方式和CMS类似。G1执行并发全局标记阶段来决定堆内的存活对象。当标记阶段完成后，G1知道哪些区块（regions）是最空闲的。它会优先收集这些区块，因为回收它们通常可以获得大量空闲内存。这也是为什么这种垃圾回收方式被称为Garbage-First。顾名思义，G1在它的收集和压缩阶段关注堆里最有可能包含大量可回收对象（也就是垃圾）的区域。G1使用一个暂停预测模型来满足用户指定的暂停时间目标，并根据指定的暂停时间目标来选择回收的区块数量。</p><p>被G1标记为可回收的区块会通过疏散方法(evacuation)来进行垃圾回收。G1从一个或者多个区块中复制对象到堆内的一个区块，在这个过程中会同时压缩和释放内存空间。为了减少停顿时间和提高吞吐量，这个疏散过程在多核心机器上是并发执行的。因此，在每一个垃圾收集过程中，G1在用户指定的停顿时间目标内不断地减少内存碎片。这超过了以往的两种回收方法的功能。CMS（Concurrent Mark Sweep）垃圾收集器没有进行内存压缩。ParallelOld垃圾回收器只进行全堆的压缩，会导致非常长的暂停时间。</p><p>但值得注意的是G1不是一个实时收集器。它会以较高概率但并不绝对保证满足用户设定的停顿时间。G1根据之前回收的数据来评估在用户指定的停顿时间内能够回收多少个区块（region）。</p><p><strong>注意：</strong> G1既有并行阶段（与应用线程并行运行，例如：refinement, marking, cleanup等过程），也有并发阶段（多线程并发运行，例如stop the world）。Full GC依然是单线程的，但是如果调优到位的话，你的应用应该避免Full GC发生。</p><h3 id="G1占用空间"><a href="#G1占用空间" class="headerlink" title="G1占用空间"></a>G1占用空间</h3><p>如果你从ParallelOldGC或者CMS迁移到G1，你会发现JVM占用的进程空间更大。这主要是因为一些记录数据（”accounting” data structures），例如 RSets和CSets（Remembered Sets and Collection Sets）。</p><p>RSets跟踪了那些指向这个区块的对象。在堆中，每一个Region都对应着一个RSet。RSets使得区块能够并行且独立地进行回收。全部RSets占用的空间不超过5%。</p><p>CSets记录了在一次GC中将会被回收的区块集合。CSets里的所有存活的数据在GC中都会被压缩（复制整理）。这些区块角色可以是Eden, survivor, 或者 old generation。全部CSets占用的空间不会超过1%。</p><h3 id="G1使用案例建议"><a href="#G1使用案例建议" class="headerlink" title="G1使用案例建议"></a>G1使用案例建议</h3><p>G1首要关注的是在一个大堆中以有限的GC延迟运行用户应用。这意味着堆的大小应该在6GB或者更大，而且稳定运行的期望暂停时间应该在0.5s以内。</p><p>现在已经运行在CMS 或者 ParallelOldGC 垃圾收集器上的应用，如果考虑切换到G1，应当考虑是否满足以下一个或者多个条件：</p><ul><li>Full GC持续时间太长太频繁；</li><li>对象的分配速度和对象的晋升速度差异非常大；</li><li>不希望长时间的GC收集以及压缩停顿时间。</li></ul><p><strong>注意：</strong> 如果你正在使用CMS 或者 ParallelOldGC，并且你的应用没有较长的GC停顿时间，那你应该继续使用当前的GC收集器。最新的JDK并不要求一定使用G1垃圾收集器。</p><h2 id="回顾CMS垃圾收集器"><a href="#回顾CMS垃圾收集器" class="headerlink" title="回顾CMS垃圾收集器"></a>回顾CMS垃圾收集器</h2><p>接下来，让我们回顾CMS垃圾收集器的各个阶段。</p><h3 id="堆内存结构"><a href="#堆内存结构" class="headerlink" title="堆内存结构"></a>堆内存结构</h3><p>堆被划分为三个空间。<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog/G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8/CMS%20Heap%20Structure.png"></p><p>年轻代被划分为Eden区和两个Suvivor区。老年代是一个连续的内存空间。除非Full GC发生，否则不会发生内存压缩。</p><h3 id="如何进行Young-GC"><a href="#如何进行Young-GC" class="headerlink" title="如何进行Young GC"></a>如何进行Young GC</h3><p>下图中，新生代以绿色表示，而老年代用蓝色表示。当你的应用运行了一段时间后，CMS的运行情况大概如图所示。对象分散在老年代的各个角落。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog/G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8/How%20young%20GC%20Works.png" alt="How young GC works"></p><p>在CMS回收过程中，老年代对象会原地回收。它们不会被移动到其他地方。堆空间在Full GC发生前不会被压缩。</p><h3 id="年轻代收集过程"><a href="#年轻代收集过程" class="headerlink" title="年轻代收集过程"></a>年轻代收集过程</h3><p>存活对象会从Eden区和其中一个Suvivor区复制到另外一个Suvivor区域。所有的超过老化阈值（aging threshold）的较老对象都会被晋升到老年代中。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog/G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8/Young%20Generration%20Collection.png" alt="Young Generration Collection"></p><h3 id="年轻代收集之后"><a href="#年轻代收集之后" class="headerlink" title="年轻代收集之后"></a>年轻代收集之后</h3><p>年轻代收集结束后，Eden区和其中一个Survivor区会被清空。<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog/G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8/After%20Young%20GC.png" alt="After Young GC"></p><p>刚被晋升的对象在图里以深蓝色标注。绿色标注的对象是那些在新生代收集中存活且没有被晋升到老年代的对象。</p><h3 id="CMS的老年代收集过程"><a href="#CMS的老年代收集过程" class="headerlink" title="CMS的老年代收集过程"></a>CMS的老年代收集过程</h3><p>这过程会有两个步骤发生stop the world，分别是：初始标记和重新标记。当老年代到达指定的占有率，CMS会被触发。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog/G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8/Old%20gen%20collection%20in%20CMS.png" alt="Old gen collection in CMS"></p><ul><li>初始标记是一个很短的阶段，用来标记那些存活的（可达的）对象；</li><li>并发标记会在应用运行过程中寻找存活对象；</li><li>最后那些在并发标记中被漏掉的对象会在重新标记阶段被标记。</li></ul><h3 id="老年代收集过程-—-并发清除"><a href="#老年代收集过程-—-并发清除" class="headerlink" title="老年代收集过程 — 并发清除"></a>老年代收集过程 — 并发清除</h3><p>那些在之前的阶段中没有被标记的对象会被清除掉。但在这个过程中并没有内存压缩。<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog/G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8/Old%20Gen%20Collection%20---%20concurrent%20sweep.png" alt="Old Gen Collection - concurrent sweep"></p><p><strong>注意：</strong> 未标记对象 &#x3D;&#x3D; 死亡对象</p><h3 id="老年代收集过程-—-并发清除之后"><a href="#老年代收集过程-—-并发清除之后" class="headerlink" title="老年代收集过程 — 并发清除之后"></a>老年代收集过程 — 并发清除之后</h3><p>在并发清除结束之后，大量的内存空间会被释放出来。此外，你还会注意到并没有发生内存压缩。<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8%2FOld%20Gen%20Collection%20-%20After%20Sweep.png" alt="Old Gen Collection - After Sweep.png"></p><p>最后CMS垃圾收集器会进入重置阶段，然后等待下一次达到GC触发阈值。</p><h2 id="G1垃圾收集器步骤分析"><a href="#G1垃圾收集器步骤分析" class="headerlink" title="G1垃圾收集器步骤分析"></a>G1垃圾收集器步骤分析</h2><h3 id="G1垃圾收集器步骤分析-1"><a href="#G1垃圾收集器步骤分析-1" class="headerlink" title="G1垃圾收集器步骤分析"></a>G1垃圾收集器步骤分析</h3><p>G1垃圾收集器使用了一种不同的方式去分配堆空间。下面各图会逐步介绍G1的各个步骤。</p><h4 id="1-G1堆空间（G1-Heap-Structure）"><a href="#1-G1堆空间（G1-Heap-Structure）" class="headerlink" title="1.G1堆空间（G1 Heap Structure）"></a>1.G1堆空间（G1 Heap Structure）</h4><p>堆空间会被分割成许多相同大小的区块（regions）。<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8%2FG1%20Heap%20Structure.png" alt="G1 Heap Structure.png"></p><p>区块大小在JVM启动之初就会决定。JVM通常会分配大小为1Mb到32Mb大小范围内的大约2000个区块。</p><h4 id="2-G1堆空间分配（G1-Heap-Allocation）"><a href="#2-G1堆空间分配（G1-Heap-Allocation）" class="headerlink" title="2.G1堆空间分配（G1 Heap Allocation）"></a>2.G1堆空间分配（G1 Heap Allocation）</h4><p>实际上，这些区块会被分配为Eden、Survivor和Old Generation等逻辑区域。<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8%2FG1%20Heap%20Allocation.png" alt="G1 Heap Allocation.png"></p><p>上图中不同颜色的区块表示的是不同的角色。存活的对象会从一个区块撤离到另一个区块。区块被设计为并发地进行收集，而不停止其他的应用线程。</p><p>就像上图展示的，所有的区块都被分配为Eden、Suvivor和Old等角色。此外，还有第四种类型 – 大区块（Humongous regions）。这些大区块被设计为存放那些占用一半或者更大的区块大小的对象。他们被存放在若干个连续的区块中。最后一种类型的区块就是堆中还没使用的部分。</p><p><strong>注意：</strong> 在写这篇文章的时候，大对象的回收还没被优化。因此，你应该尽量避免创建大对象。</p><h4 id="3-G1的年轻代（Young-Generation-in-G1）"><a href="#3-G1的年轻代（Young-Generation-in-G1）" class="headerlink" title="3.G1的年轻代（Young Generation in G1）"></a>3.G1的年轻代（Young Generation in G1）</h4><p>堆空间被划分为大概2000个区块。区块的大小在1Mb~32Mb之间。蓝色的区块存放的是老年代对象，而绿色的区块存放着年轻代对象。<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8%2FYoung%20Generation%20in%20G1.png" alt="Young Generation in G1.png"></p><p>值得注意的是，不像以前的垃圾收集器那样，G1里这些区块并不要求是连续的内存空间。</p><h4 id="4-G1的一次-Young-GC（A-Young-GC-in-G1）"><a href="#4-G1的一次-Young-GC（A-Young-GC-in-G1）" class="headerlink" title="4.G1的一次 Young GC（A Young GC in G1）"></a>4.G1的一次 Young GC（A Young GC in G1）</h4><p>存活对象会被疏散（复制或者移动）到一个或者多个suvivor区块。如果对象超过了老化阈值，则会被晋升到老年代区块中。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8%2FA%20Young%20GC%20in%20G1.png" alt="A Young GC in G1.png"></p><p>这个是一个stop the world (STW)的过程。这时候会为下一次Young GC计算Eden区和Suvivor区的大小。</p><p>这种方式可以非常容易地按照需要调整区块大小。</p><h4 id="5-G1的Young-GC结束之后（End-of-a-Young-GC-with-G1）"><a href="#5-G1的Young-GC结束之后（End-of-a-Young-GC-with-G1）" class="headerlink" title="5.G1的Young GC结束之后（End of a Young GC with G1）"></a>5.G1的Young GC结束之后（End of a Young GC with G1）</h4><p>存活对象都被疏散到Suvivor区块或者Old区块。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8%2FEnd%20of%20Young%20GC%20with%20G1.png" alt="End of Young GC with G1.png"></p><p>上图中，最新被晋升老年代的对象以深蓝色标注，而Suvivor区块以深绿色标注。</p><p>总结上述，G1的年轻代回收可以归纳为以下：</p><ul><li>堆空间就是一个被分割为多个区块的内存空间。</li><li>年轻代内存空间由一系列不连续的区块组成。这使得按需调整大小非常容易。</li><li>年轻代垃圾回收过程是一个stop the world过程。所有的应用线程都会被停止。</li><li>年轻代回收过程是一个多线程并发过程。</li><li>存活的对象会被复制到新的Suvivor区块以及Old区块。</li></ul><blockquote><p>G1的老年代收集过程</p></blockquote><p>跟CMS收集器类似，G1收集器被设计为用于老年代对象的低延迟收集器。以下表格介绍了G1在老年代上的收集过程。</p><h3 id="G1垃圾收集的阶段-并发标记周期阶段"><a href="#G1垃圾收集的阶段-并发标记周期阶段" class="headerlink" title="G1垃圾收集的阶段 - 并发标记周期阶段"></a>G1垃圾收集的阶段 - 并发标记周期阶段</h3><p>G1收集器在老年代上执行以下的几个步骤。值得注意的是，下面有些步骤其实是年轻代收集过程的一部分。</p><table><thead><tr><th>阶段</th><th>过程描述</th></tr></thead><tbody><tr><td>(1)初始标记<br>(Stop the World Event)</td><td>stop the world。这个过程发生在 young gc，用于标记那些引用了老年代对象的 Suvivor 区块(根区块 root regions)</td></tr><tr><td>(2)扫描根区块</td><td>扫描那些引用了老年代的 Suvivor 区块（根区块）。这个阶段是和应用线程并行执行。这个阶段必须在下一次 young gc 发生之前完成。</td></tr><tr><td>(3)并发标记</td><td>在全堆范围内寻找存活对象。这个阶段也是和应用线程并行执行。这个阶段可以被年轻代垃圾收集过程所打断</td></tr><tr><td>(4)重新标记<br>(Stop the World Event)</td><td>完成堆中存活对象的标记。这个阶段使用了一个叫 SATB(snapshot-at-the-beginning) 的算法，该算法比 CMS 收集器所用算法快非常多。</td></tr><tr><td>(5)并发清理<br>(Stop the World Event and Concurrent)</td><td>1)核算存活对象和完全空闲区块的记录数据（stop the world);   2)擦除 RSets(stop the world);  3)重置空区块，并且添加进空闲区块列表（并发）。</td></tr><tr><td>(*)复制<br>(Stop the World Event)</td><td>这是会发生多次的 STW 过程，过程中会疏散或者复制存活对象那到新的未使用区块上。复制过程可以发生在年轻代区块中，GC日志中显示为 [GC pause (young)]，或者同时发生在年轻代和老年代区块中，而GC日志中显示为 [GC Pause (mixed)]</td></tr></tbody></table><h3 id="逐步分析G1的老年代收集过程"><a href="#逐步分析G1的老年代收集过程" class="headerlink" title="逐步分析G1的老年代收集过程"></a>逐步分析G1的老年代收集过程</h3><p>经过以上的各阶段的简单介绍后，我们来看看他们在G1收集器的老年代回收过程中是如何相互影响的。</p><h4 id="6-初始标记阶段（Initial-Marking-Phase）"><a href="#6-初始标记阶段（Initial-Marking-Phase）" class="headerlink" title="6.初始标记阶段（Initial Marking Phase）"></a>6.初始标记阶段（Initial Marking Phase）</h4><p>针对存活对象的初始标记在年轻代垃圾收集阶段已经完成。在GC日志中显示为GC pause (young)(inital-mark)。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8%2FInitial%20Marking%20Phase.png" alt="Initial Marking Phase.png"></p><h4 id="7-并发标记阶段（Concurrent-Marking-Phase）"><a href="#7-并发标记阶段（Concurrent-Marking-Phase）" class="headerlink" title="7.并发标记阶段（Concurrent Marking Phase）"></a>7.并发标记阶段（Concurrent Marking Phase）</h4><p>如果发现空区块(下图用”X”标记),他们会在重新标记阶段直接移除。此外，决定存活情况的记录信息也会被计算。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8%2FConcurrent%20Marking%20Phase.png" alt="Concurrent Marking Phase.png"></p><h4 id="8-重新标记阶段（Remark-Phase）"><a href="#8-重新标记阶段（Remark-Phase）" class="headerlink" title="8.重新标记阶段（Remark Phase）"></a>8.重新标记阶段（Remark Phase）</h4><p>空区块会被删除并且回收。所有区块现在都会计算存活情况。<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8%2FRemark%20Phase.png" alt="Remark Phase.png"></p><h4 id="9-复制清理阶段（Copying-Cleanup-Phase）"><a href="#9-复制清理阶段（Copying-Cleanup-Phase）" class="headerlink" title="9.复制清理阶段（Copying&#x2F;Cleanup Phase）"></a>9.复制清理阶段（Copying&#x2F;Cleanup Phase）</h4><p>G1会选择存活对象最少的区块来进行回收，因为这些区块回收速度会最快。这些区块会在一次young GC中被同时回收。GC日志中这个过程显示为[GC pause (mixed)]。因此，年轻代和老年代会在同一时间进行回收。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8%2FCopying%3ACleanup%20Phase.png" alt="Copying:Cleanup Phase.png"></p><h4 id="10-复制清理阶段之后（After-Copying-Cleanup-Phase）"><a href="#10-复制清理阶段之后（After-Copying-Cleanup-Phase）" class="headerlink" title="10.复制清理阶段之后（After Copying&#x2F;Cleanup Phase）"></a>10.复制清理阶段之后（After Copying&#x2F;Cleanup Phase）</h4><p>那些被选中的区块已经被收集并且压缩到了下图的深蓝色和深绿色的区块中。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8%2FAfter%20Copying%3ACleanup%20Phase.png" alt="After Copying:Cleanup Phase.png"></p><h3 id="老年代回收过程总结"><a href="#老年代回收过程总结" class="headerlink" title="老年代回收过程总结"></a>老年代回收过程总结</h3><p>我们可以对G1的老年代收集过程总结几个要点。</p><ul><li>并发标记阶段<ul><li>存活信息会在应用运行的时候并行计算；</li><li>这些存活信息指出了在疏散暂停时候哪些区块是最应该回收的；</li><li>没有类似CMS那样的清除阶段（sweeping phase）。</li></ul></li><li>重新标记阶段<ul><li>使用比CMS所用算法更快的SATB(Snapshot-at-the-Beginning)算法；</li><li>完全为空的区块会被回收；</li></ul></li><li>复制&#x2F;清理阶段<ul><li>年轻代和老年代会被同时回收；</li><li>基于对象存活情况，挑选老年代区块。</li></ul></li></ul><h2 id="命令行参数可选项以及最佳时间"><a href="#命令行参数可选项以及最佳时间" class="headerlink" title="命令行参数可选项以及最佳时间"></a>命令行参数可选项以及最佳时间</h2><p>这个章节里，我们会学习G1的各种命令行选项。</p><h3 id="命令行基本参数"><a href="#命令行基本参数" class="headerlink" title="命令行基本参数"></a>命令行基本参数</h3><p>为了使用G1收集器，需要指定参数：-XX:+UseG1GC</p><p>这是启动Java进程的一个样例：</p><pre><code class="bash">java -Xmx50m -Xms50m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -jar c:\javademos\demo\jfc\Java2D\Java2demo.jar</code></pre><h3 id="命令行关键参数"><a href="#命令行关键参数" class="headerlink" title="命令行关键参数"></a>命令行关键参数</h3><p><strong>-XX:+UseG1GC</strong> - 告诉JVM使用G1垃圾收集器；</p><p><strong>-XX:MaxGCPauseMillis&#x3D;200</strong> - 设置一个最大的GC停顿时间目标。这是一个软目标，JVM会尽最大能力去满足它。因此，停顿时间有时候并不会满足这个目标。默认值是200ms。</p><p><strong>-XX:InitiatingHeapOccupancyPercent&#x3D;45</strong> - 触发并发GC的堆内存占用阈值。G1收集器根据整个堆的占用情况而不是某个分代来触发一次并发回收循环。如果这个值指定为0，则意味着会进行恒定的GC循环。默认值为45（占用45%）。</p><h3 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h3><h4 id="不要设置年轻代的大小"><a href="#不要设置年轻代的大小" class="headerlink" title="不要设置年轻代的大小"></a><strong>不要设置年轻代的大小</strong></h4><p>通过 <em>-Xmn</em> 显式设置年轻代大小，会干扰到G1的默认行为。</p><ul><li>G1不会再遵循回收停顿目标。因此实际上，设置年轻代大小会禁用停顿目标；</li><li>G1再也不能够按需要扩增或者收缩年轻代大小。因为大小已经被固定下来而不能做任何更改。</li></ul><h4 id="响应时间指标"><a href="#响应时间指标" class="headerlink" title="响应时间指标"></a><strong>响应时间指标</strong></h4><p>与其使用平均响应时间（ART)作为一个指标去设置XX:MaxGCPauseMillis&#x3D;N，不如考虑设置一个值，使得90%或更多时间满足这个停顿目标。这意味着90%的用户发起请求后得到应答的时间不会超过这个目标。请记住，这个停顿时间只是一个目标，而不能保证总是能满足它。</p><h4 id="什么是疏散失败-Evacuation-Failure"><a href="#什么是疏散失败-Evacuation-Failure" class="headerlink" title="什么是疏散失败?(Evacuation Failure)"></a><strong>什么是疏散失败?(Evacuation Failure)</strong></h4><p>当JVM对幸存对象进行回收或者在晋升对象到老年代的时候发生堆内存耗尽，将会触发一次晋升失败。此时堆空间不能再扩增，因为它已经处于最大值。当指定参数XX:+PrintGCDetails的时候，这种晋升失败的情况在日志里体现为：<strong>to-space overflow</strong>。而且这个过程会付出昂贵代价！</p><ul><li>GC必须继续下去，所以必须得释放出空间；</li><li>未能成功复制的对象必须安置到适当位置；</li><li>对CSet中的RSets的区块的任何更新都需要重建；（这句太难翻译了，原文是：Any updates to RSets of regions in the CSet have to be regenerated.）</li><li>所有这些步骤都是代价昂贵。</li></ul><h4 id="如何避免疏散失败"><a href="#如何避免疏散失败" class="headerlink" title="如何避免疏散失败"></a><strong>如何避免疏散失败</strong></h4><p>为了避免疏散失败，考虑以下选项。</p><ul><li><p>扩大堆空间</p><ul><li>增大-XX:G1ReservePercent&#x3D;n，默认值是10；</li><li>G1会设定一个虚拟上限，通过让这些保留内存空间闲置着，以防发生更多的”to-space”而需要这些内存。</li></ul></li><li><p>更早启动标记阶段</p></li><li><p>通过-XX:ConcGCThreads&#x3D;n参数，来增大标记线程数量</p></li></ul><h4 id="G1完整的GC开关"><a href="#G1完整的GC开关" class="headerlink" title="G1完整的GC开关"></a>G1完整的GC开关</h4><p>以下是G1 GC开关列表。请牢记上文提到的最佳实践。</p><table><thead><tr><th>GC选项</th><th>描述</th></tr></thead><tbody><tr><td>-XX:+UseG1GC</td><td>指定使用G1垃圾收集器</td></tr><tr><td>-XX:MaxGCPauseMillis&#x3D;n</td><td>设定一个最大的GC停顿时间目标。这是一个软目标，JVM会尽最大努力满足这个目标</td></tr><tr><td>-XX:InitiatingHeapOccupancyPercent&#x3D;n</td><td>触发并发GC的堆内存占用阈值。G1收集器根据整个堆的占用情况而不是某个分代来触发一次并发回收循环。如果这个值指定为0，则意味着会进行恒定的GC循环。默认值为45（占用45%）。</td></tr><tr><td>-XX:NewRatio&#x3D;n</td><td>新生代&#x2F;老年代的大小比率，默认值是2</td></tr><tr><td>-XX:SurvivorRatio&#x3D;n</td><td>Eden区&#x2F;Suvivor区的比率，默认值是8</td></tr><tr><td>-XX:MaxTenuringThreshold&#x3D;n</td><td>最大的存活次数。默认值是15</td></tr><tr><td>-XX:ParallelGCThreads&#x3D;n</td><td>设置并行阶段GC线程数量。不同平台上的默认值各不一样。</td></tr><tr><td>-XX:ConcGCThreads&#x3D;n</td><td>并发阶段的GC线程数量。不同平台上的默认值各不一样.</td></tr><tr><td>-XX:G1ReservePercent&#x3D;n</td><td>设置堆的保留空间阈值以降低发生晋升失败的可能。默认值是10</td></tr><tr><td>-XX:G1HeapRegionSize&#x3D;n</td><td>G1将堆空间划分为相同大小的区块。这个参数设置初始化时候的区块数量。该参数的默认值是根据堆空间来动态确定的。最小值为1Mb，最大值为32Mb</td></tr></tbody></table><h2 id="G1的GC日志"><a href="#G1的GC日志" class="headerlink" title="G1的GC日志"></a>G1的GC日志</h2><p>最后我们来看如何通过日志信息来分析G1收集器的表现。这个章节会介绍可以用来在日志中收集数据以及信息的参数。</p><h3 id="设置日志详情"><a href="#设置日志详情" class="headerlink" title="设置日志详情"></a>设置日志详情</h3><p>你可以设置三个不同级别的日志详情。</p><p>(1）**-verbosegc**（与 <strong>-XX:+PrintGC</strong> 相同）设置详情日志的级别为 <em>fine</em>。</p><p><strong>样例输出</strong></p><pre><code>[GC pause (G1 Humongous Allocation) (young) (initial-mark) 24M- &gt;21M(64M), 0.2349730 secs][GC pause (G1 Evacuation Pause) (mixed) 66M-&gt;21M(236M), 0.1625268 secs] </code></pre><p>(2) <strong>-XX:+PrintGCDetails</strong> 设置详情日志级别为 <em>finer</em>。这个选项展示以下信息：</p><ul><li>各个阶段的平均用时、最小用时和最大用时；</li><li>根扫描、RSet更新、RSet扫描、对象复制、终止(和尝试次数)；</li><li>另外也展示了其他时间，比如选择CSet时间、引用处理时间、引用入队时间和冻结CSet耗时；</li><li>展示Eden、Suvivor以及全堆的占用情况。</li></ul><p><strong>样例输出</strong></p><pre><code>[Ext Root Scanning (ms): Avg: 1.7 Min: 0.0 Max: 3.7 Diff: 3.7][Eden: 818M(818M)-&gt;0B(714M) Survivors: 0B-&gt;104M Heap: 836M(4096M)-&gt;409M(4096M)]</code></pre><p>(3) <strong>-XX:+UnlockExperimentalVMOptions -XX:G1LogLevel&#x3D;finest</strong> 设置详情级别为 *finest**。跟finer级别类似，但包含了个别工作线程的信息。</p><pre><code>[Ext Root Scanning (ms): 2.1 2.4 2.0 0.0           Avg: 1.6 Min: 0.0 Max: 2.4 Diff: 2.3]       [Update RS (ms):  0.4  0.2  0.4  0.0           Avg: 0.2 Min: 0.0 Max: 0.4 Diff: 0.4]           [Processed Buffers : 5 1 10 0           Sum: 16, Avg: 4, Min: 0, Max: 10, Diff: 10]</code></pre><h3 id="指定时间参数"><a href="#指定时间参数" class="headerlink" title="指定时间参数"></a>指定时间参数</h3><p>有一些开关决定打印GC日志中的时间。</p><p>（1）**-XX:+PrintGCTimeStamps** - 当JVM启动后，打印运行时间。</p><p><strong>样例输出</strong></p><pre><code>1.729: [GC pause (young) 46M-&gt;35M(1332M), 0.0310029 secs]</code></pre><p>（2）**-XX:+PrintGCDateStamps** - 每条记录都打印日期前缀。</p><p><strong>样例输出</strong></p><pre><code>2012-05-02T11:16:32.057+0200: [GC pause (young) 46M-&gt;35M(1332M), 0.0317225 secs]</code></pre><h3 id="认识G1日志"><a href="#认识G1日志" class="headerlink" title="认识G1日志"></a>认识G1日志</h3><p>为了认识GC日志，这个章节使用实际的GC日志输出定义一些术语。以下的例子展示了日志的输出，并且附带了术语的解释。</p><p><em>注意:</em>* 了解更多信息请移步<a href="https://blogs.oracle.com/poonam/entry/understanding_g1_gc_logs">Poonam Bajaj’s Blog post on G1 GC logs.</a></p><h3 id="G1日志术语"><a href="#G1日志术语" class="headerlink" title="G1日志术语"></a>G1日志术语</h3><ul><li><p>并行时间(Parallel Time)</p><pre><code>414.557: [GC pause (young), 0.03039600 secs] [Parallel Time: 22.9 ms][GC Worker Start (ms): 7096.0 7096.0 7096.1 7096.1 706.1 7096.1 7096.1 7096.1 7096.2 7096.2 7096.2 7096.2    Avg: 7096.1, Min: 7096.0, Max: 7096.2, Diff: 0.2]</code></pre><p>  Parallel Time - 暂停的主要并行部分的大体运行时间；<br>  Worker Start - workers开始的时间戳；<br>  <strong>注意:</strong> 这些日志都按照线程ID排序，并且每个条目都是一致的。</p></li><li><p>外部根扫描(External Root Scanning)</p><pre><code>[Ext Root Scanning (ms): 3.1 3.4 3.4 3.0 4.2 2.0 3.6 3.2 3.4 7.7 3.7 4.4    Avg: 3.8, Min: 2.0, Max: 7.7, Diff: 5.7]</code></pre><p>  External root scanning - 扫描外部根(例如指向堆空间的系统字典)所耗时间</p></li><li><p>更新RSet(Update Remembered Set)</p><pre><code>[Update RS (ms): 0.1 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 Avg: 0.0, Min: 0.0, Max: 0.1, Diff: 0.1][Processed Buffers : 26 0 0 0 0 0 0 0 0 0 0 0    Sum: 26, Avg: 2, Min: 0, Max: 26, Diff: 26]</code></pre><p>  Update Remembered Set - Any buffers that are completed but have not yet been processed by the concurrent refinement thread before the start of the pause have to be updated. Time depends on density of the cards. The more cards, the longer it will take.</p></li><li><p>扫描RSet(Scanning Remembered Sets)</p><pre><code>[Scan RS (ms): 0.4 0.2 0.1 0.3 0.0 0.0 0.1 0.2 0.0 0.1 0.0 0.0 Avg: 0.1, Min: 0.0, Max: 0.4, Diff: 0.3]F</code></pre><p>  Scanning Remembered Sets - Look for pointers that point into the Collection Set.</p></li><li><p>对象复制(Object Copy)</p><pre><code>[Object Copy (ms): 16.7 16.7 16.7 16.9 16.0 18.1 16.5 16.8 16.7 12.3 16.4 15.7 Avg: 16.3, Min: 12.3, Max:  18.1, Diff: 5.8]</code></pre><p>  Object copy – The time that each individual thread spent copying and evacuating objects.</p></li><li><p>Termination Time</p><pre><code>[Termination (ms): 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.00.0 Avg: 0.0, Min: 0.0, Max: 0.0, Diff: 0.0] [Termination Attempts : 1 1 1 1 1 1 1 1 1 1 1 1 Sum: 12, Avg: 1, Min: 1, Max: 1, Diff: 0]</code></pre><p>  Termination time - When a worker thread is finished with its particular set of objects to copy and scan, it enters the termination protocol. It looks for work to steal and once it’s done with that work it again enters the termination protocol. Termination attempt counts all the attempts to steal work.</p></li><li><p>GC Worker End</p><pre><code>[GC Worker End (ms): 7116.4 7116.3 7116.4 7116.3 7116.4 7116.3 7116.4 7116.4 7116.4 7116.4 7116.3 7116.3    Avg: 7116.4, Min: 7116.3, Max: 7116.4, Diff:   0.1][GC Worker (ms): 20.4 20.3 20.3 20.2 20.3 20.2 20.2 20.2 20.3 20.2 20.1 20.1    Avg: 20.2, Min: 20.1, Max: 20.4, Diff: 0.3]</code></pre><p>  GC worker end time – Timestamp when the individual GC worker stops.</p><p>  GC worker time – Time taken by individual GC worker thread.</p></li><li><p>GC Worker Other</p><pre><code>[GC Worker Other (ms): 2.6 2.6 2.7 2.7 2.7 2.7 2.7 2.8 2.8 2.8 2.8 2.8    Avg: 2.7, Min: 2.6, Max: 2.8, Diff: 0.2]</code></pre><p>  GC worker other – The time (for each GC thread) that can’t be attributed to the worker phases listed previously. Should be quite low. In the past, we have seen excessively high values and they have been attributed to bottlenecks in other parts of the JVM (e.g., increases in the Code Cache occupancy with Tiered).</p></li><li><p>Clear CT</p><pre><code>[Clear CT: 0.6 ms]</code></pre><p>  Time taken to clear the card table of RSet scanning meta-data</p></li><li><p>Other</p><pre><code>[Other: 6.8 ms]</code></pre><p>  Time taken for various other sequential phases of the GC pause.</p></li><li><p>CSet</p><pre><code>[Choose CSet: 0.1 ms]</code></pre><p>  Time taken finalizing the set of regions to collect. Usually very small; slightly longer when having to select old.</p></li><li><p>Ref Proc</p><pre><code>[Ref Proc: 4.4 ms]</code></pre><p>  Time spent processing soft, weak, etc. references deferred from the prior phases of the GC.</p></li><li><p>Ref Enq</p><pre><code>[Ref Enq: 0.1 ms]</code></pre><p>  Time spent placing soft, weak, etc. references on to the pending list.</p></li><li><p>Free CSet</p><pre><code>[Free CSet: 2.0 ms]</code></pre><p>  Time spent freeing the set of regions that have just been collected, including their remembered sets.</p></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在本文中，你已经浏览学习了Java JVM里的G1垃圾收集器。首先你学习为何堆和垃圾收集器是Java JVM的重要组成部分。然后回顾了CMS和G1垃圾收集器是如何工作的。接着学习了G1的命令行开关以及使用它们的最佳实践。最后学习了GC日志中的打印对象以及数据。</p><p>在这个教程中，你学习了：</p><ul><li>Java JVM的组成部分；</li><li>G1收集器的概述；</li><li>回顾CMS收集器；</li><li>回顾G1收集器；</li><li>命令行开关和最佳实践；</li><li>G1的日志。</li></ul><h3 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h3><p>更多相关信息请查看以下网页链接：</p><ul><li><a href="http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html">Java HotSpot VM Options</a></li><li><a href="http://www.oracle.com/technetwork/java/javase/tech/g1-intro-jsp-135488.html">The Garbage First(G1) Garbage Collector</a></li><li><a href="https://blogs.oracle.com/poonam/entry/understanding_g1_gc_logs">Poonam Bajaj G1 GC Blog Post</a></li><li><a href="http://education.oracle.com/pls/web_prod-plq-dad/db_pages.getpage?page_id=609&p_org_id=1001&lang=US&get_params=dc:D67232GC10,p_preview:N">Java SE 7: Develop Rich Client Applications</a></li><li><a href="http://www.amazon.com/Java-Performance-Charlie-Hunt/dp/0137142528/ref=sr_1_1">Java Performance - Charlie Hunt and Binu John</a></li><li><a href="http://www.oracle.com/oll">Oracle Learning Library</a></li></ul><h3 id="鸣谢"><a href="#鸣谢" class="headerlink" title="鸣谢"></a>鸣谢</h3><ul><li>Curriculum Developer: Michael J Williams</li><li>QA: Krishnanjani Chitta</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
            <tag> 垃圾回收器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 虚拟机原理 (三) 垃圾收集</title>
      <link href="/2021/01/09/Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86-3-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/"/>
      <url>/2021/01/09/Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86-3-%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<p>Java 虚拟机技术是每个 Java 开发工程师都应该深入掌握的。本系列文章将深入介绍 JVM 相关技术，主要包括内存划分、对象创建回收与分配以及垃圾收集三大部分。本系列文章将力求全面概要地汇总核心知识点，并使知识点串联成面，以方便学习、工作以及备忘复习。本文将介绍第三部分——垃圾收集。</p><span id="more"></span><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%2F%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E9%A6%96%E9%A1%B5%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.jpg" alt="垃圾收集思维导图"></p><h1 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h1><ul><li>标记清除算法<ul><li>需要标记的对象非常多，效率一般不高</li><li>内存容易导致空间碎片化问题</li></ul></li><li>标记整理算法<ul><li>在标记清除算法基础上，增加内存整理功能，避免碎片化的问题</li><li>同样存在标记量大而效率不高的问题</li></ul></li><li>标记复制算法<ul><li>一般需要预留 Survivor 区域，导致空间利用率不高</li><li>回收效率非常高</li></ul></li><li>分代收集算法<ul><li>常见的垃圾收集器都采用此法</li></ul></li></ul><h1 id="常见垃圾收集器"><a href="#常见垃圾收集器" class="headerlink" title="常见垃圾收集器"></a>常见垃圾收集器</h1><h2 id="经典垃圾收集器"><a href="#经典垃圾收集器" class="headerlink" title="经典垃圾收集器"></a>经典垃圾收集器</h2><ul><li><p>新生代收集器</p><ul><li>Serial New 收集器（-XX:+UseSerialGC）<blockquote><p>新生代单线程垃圾收集器。</p></blockquote></li><li>Parallel 收集器（-XX:+UseParallelGC）：<blockquote><p>也称为 Parallel Scavenge收集器，可以理解为 Serial New 收集器的多线程版本。该垃圾收集器可与 Serial Old 以及 Parallel Old 两款收集器搭配使用。</p></blockquote></li><li>ParNew 收集器（-XX:+UseParNewGC）<blockquote><p>该垃圾收集器专门开发来与 CMS 收集器搭配使用，当然也可以与 Serial Old 垃圾收集器使用。</p></blockquote></li></ul></li><li><p>老年代收集器</p><ul><li>Serial Old 收集器（-XX:+UseSerialOldGC）</li><li>Parallel Old 收集器（-XX:+UseParallelOldGC）<blockquote><p>老年代并行垃圾收集器，仅与 Parallel 收集器搭配使用。</p></blockquote></li><li>CMS 收集器（-XX:+UseConcMarkSweepGC）</li></ul></li><li><p>跨代收集器</p><ul><li>G1 收集器（-XX:+UseG1GC）</li></ul></li></ul><blockquote><p>注意，在 jdk1.8.0_161 中测试发现 -XX:+UseSerialOldGC 参数已经不可用。目前各个垃圾收集器之间的关系图如下：<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%2F%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.png" alt="垃圾收集器之间的关系.png"><br>其中标红线表示 jdk1.8.0_161 之后推荐使用的搭配关系，此外 CMS 在并发失败的时候还会退化为 Serial Old。<br>从 JDK 源码也可以看出端倪:<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%2Fcheck_gc_args" alt="check_gc_args"></p></blockquote><h3 id="CMS-垃圾收集器"><a href="#CMS-垃圾收集器" class="headerlink" title="CMS 垃圾收集器"></a>CMS 垃圾收集器</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p> CMS (Concurrent Mark Sweep)是老年代垃圾收集器，内部使用标记清除算法。其一般与 ParNew 搭配使用。CMS 的回收模式一般分为两种background 和 foreground 两种模式。background模式下，一般划分为以下几个阶段：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%2FCMS%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%9B%9E%E6%94%B6%E9%98%B6%E6%AE%B5.png" alt="CMS垃圾收集器回收阶段.png"></p><ul><li><strong>初始标记</strong>：快速标记 GC Roots 直接引用的对象，该阶段为 Stop The World 过程；</li><li><strong>并发标记</strong>：从 GC Roots 直接引用对象出发遍历其他存活对象，该过程与用户线程并发运行，因此可能会有已被标记的对象状态发生变化。该过程持续时间会比较长，但不会 STW；</li><li><strong>重新标记</strong>：修正并发标记阶段状态发生变动的对象，该阶段停顿时间会比初始标记稍长，但远比并发标记要短暂。另外，CMS 主要采用了三色标记的增量更新算法实现重新标记；</li><li><strong>并发清理</strong>：清理未标记的对象，该阶段与用户线程并发运行。同时根据三色标记原理，该阶段新增对象都会被标记为黑色而不必清理。</li></ul><p>另外一种模式是 foreground ，该模式下 CMS 将会退化为与 Serial Old 相同的收集算法，也就是采用单线程串行 GC 模式，STW 时间超长，有时会长达十几秒。这种模式下才能准确称为 Full GC。</p><p>CMS 存在几个缺点：</p><ul><li>对 CPU 资源敏感，会与应用程序争抢 CPU 资源；</li><li>并发标记和并发清理阶段会产生浮动垃圾，需要等待下一次 GC 过程才能回收；</li><li>标记清除算法会产生大量空间碎片（但可通过 -XX:+UseCMSCompactAtFullCollection 参数让 JVM 清理后进行内存整理）；</li><li>在并发标记和并发清理阶段，GC 线程与用户线程并发执行，此时如果再次触发 Major GC，会引起 “concurrent mode failure”，此时会进入 STW 状态，并退化为使用 Serial Old 垃圾收集器来回收。</li></ul><h4 id="常用调优参数："><a href="#常用调优参数：" class="headerlink" title="常用调优参数："></a>常用调优参数：</h4><table><thead><tr><th>参数</th><th>参数含义</th><th>默认值</th></tr></thead><tbody><tr><td>-XX:+UseConcMarkSweepGC</td><td>启用 CMS 收集器</td><td>默认搭配 ParNew 新生代收集器</td></tr><tr><td>-XX:ConcGCThreads</td><td>并发的 GC 线程数量</td><td>默认值（CPU核心数+3）&#x2F; 4</td></tr><tr><td>-XX:+UseCMSCompactAtFullCollection</td><td>Full GC 后做压缩整理以减少内存碎片</td><td></td></tr><tr><td>-XX:CMSFullGCsBeforeCompaction</td><td>指定多少次 Full GC 后压缩整理一次</td><td>默认值是0，表示每次 Full GC 都会压缩一次</td></tr><tr><td>-XX:CMSInitiatingOccupancyFraction</td><td>当老年代使用达到该比例会触发 Full GC</td><td>默认值92（百分比）</td></tr><tr><td>-XX:+UseCMSInitiatingOccupancyOnly</td><td>表示仅使用设定的回收阈值(这里指CMSInitiatingOccupancyFraction)，如果不指定，JVM仅在第一次使用设定阈值，后续则自动调整，所以一般设置了回收阈值都会同时设置该值。</td><td></td></tr><tr><td>-XX:+CMSScavengeBeforeRemark</td><td>在 Full GC 前执行一次 Minor GC，目的是减少老年代对年轻代的引用，从而降低标记阶段的开销</td><td></td></tr><tr><td>-XX:+CMSParallelInitialMarkEnabled</td><td>表示在初始标记的时候多线程执行从而缩短 STW</td><td></td></tr><tr><td>-XX:+CMSParallelRemarkEnabled</td><td>表示在重新标记的时候多线程执行从而缩短 STW</td><td>默认开启</td></tr></tbody></table><h4 id="GC-日志案例："><a href="#GC-日志案例：" class="headerlink" title="GC 日志案例："></a>GC 日志案例：</h4><blockquote><p>运行参数： -Xms50m -Xmx50m -XX:+UseConcMarkSweepGC -XX:MetaspaceSize&#x3D;64m -XX:MaxMetaspaceSize&#x3D;128M -XX:+PrintGCDetails -XX:CMSInitiatingOccupancyFraction&#x3D;92 -XX:+UseCMSInitiatingOccupancyOnly</p></blockquote><pre><code class="bash">## 初始标记[GC (CMS Initial Mark) [1 CMS-initial-mark: 30614K(34176K)] 34916K(49536K), 0.0015545 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] ## 并发标记[CMS-concurrent-mark-start][CMS-concurrent-mark: 0.014/0.014 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] [CMS-concurrent-preclean-start][CMS-concurrent-preclean: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [CMS-concurrent-abortable-preclean-start][CMS-concurrent-abortable-preclean: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] ## 重新标记（最终标记）[GC (CMS Final Remark) [YG occupancy: 4302 K (15360 K)][Rescan (parallel) , 0.0008078 secs][weak refs processing, 0.0004334 secs][class unloading, 0.0038316 secs][scrub symbol table, 0.0038272 secs][scrub string table, 0.0003411 secs][1 CMS-remark: 30614K(34176K)] 34916K(49536K), 0.0093542 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] ## 并发清理[CMS-concurrent-sweep-start][CMS-concurrent-sweep: 0.003/0.003 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] ## 并发重置[CMS-concurrent-reset-start][CMS-concurrent-reset: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] </code></pre><p>主要看点：</p><ul><li>初始标记耗时非常短（0.0015545 secs），触发阈值约是90%（30614&#x2F;34176≈90%），这值比参数指定值92%略小，但在预期之内；</li><li>并发标记阶段不会 STW，用时相对较长（0.014 secs）；</li><li>重新标记阶段默认就是多线程（Rescan (parallel)），也就是说 CMSParallelRemarkEnabled 默认开启；</li></ul><h4 id="常见调优思路"><a href="#常见调优思路" class="headerlink" title="常见调优思路"></a>常见调优思路</h4><p><a href="https://tech.meituan.com/2020/11/12/java-9-cms-gc.html">Java中9种常见的CMS GC问题分析与解决</a></p><h3 id="G1-垃圾收集器"><a href="#G1-垃圾收集器" class="headerlink" title="G1 垃圾收集器"></a>G1 垃圾收集器</h3><h4 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h4><p>G1 垃圾收集器与 CMS 收集器非常相似，但存在本质的区别。读者可以先看下一篇<a href="https://blog.duval.top/2021/01/10/Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86-4-G1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%E5%85%A5%E9%97%A8/">《Java 虚拟机原理 (四) G1垃圾收集器入门》</a>进行了解，此处不再重复。</p><p>下边直接来看 G1 的垃圾回收阶段图：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%2FG1%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E9%98%B6%E6%AE%B5%E5%9B%BE.png" alt="G1垃圾收集阶段图.png"></p><p>具体各个阶段总结如下：</p><table><thead><tr><th>回收阶段</th><th>是否 STW</th><th>过程</th></tr></thead><tbody><tr><td>年轻代收集 (young gc)</td><td>是（收集过程中复制移动动作是一个 STW 过程）</td><td>1.使用复制算法，从 eden 区将存活对象转移到 survivor区；<br>2.如果对象超过了老化阈值，则会被晋升到老年代区块中。</td></tr><tr><td>初始标记（initial-mark)</td><td>是</td><td>1.当老年代占堆比重达到 IHOP 阈值（缺省45%），则会触发并发标记周期，并进入初始标记阶段；<br>2.初始标记过程是伴随着一次年轻代收集同时完成的；<br>3.该过程主要是标记那些引用了老年代对象的 Survivor 区块（也就是根区块）</td></tr><tr><td>并发根区块扫描 (concurrent-root-scan)</td><td>否</td><td>1.扫描那些引用了老年代的 Suvivor 区块（根区块）并标记他们所引用的对象。<br>2.这个阶段是和应用线程并行执行。这个阶段必须在下一次 young gc 发生之前完成。</td></tr><tr><td>并发标记 (concurrent-mark)</td><td>否</td><td>1.在全堆范围内寻找存活对象；<br>2.该过程与应用线程并行执行；<br>3.这个阶段可以被年轻代垃圾收集过程所打断（也就是中间可以穿插多个 young gc）</td></tr><tr><td>重新标记 (remark)</td><td>是</td><td>1.最终完成堆中所有存活对象的标记；<br>2.这个阶段使用了一个叫SATB(snapshot-at-the-beginning)的算法，该算法比CMS收集器所用算法快非常多。</td></tr><tr><td>并发清理 (cleanup)</td><td>是（重置空区块阶段(3)为并发操作）</td><td>1.清算存活对象以及空区块 (STW)；<br>2.擦除 RSets (STW)；<br>3.重置空区块，并添加进空闲区块列表；<br>4.该阶段还会决定是否进入空间回收周期。</td></tr><tr><td>空间回收周期（space reclamation</td><td>是</td><td>1.该过程会疏散或者复制存活对象那到新的未使用区块上；<br>2.这过程可以包含多次 young gc，可以发生在年轻代区块中，GC日志中显示为[GC pause (young)]，或者同时发生在年轻代和老年代区块中，而GC日志中显示为[GC Pause (mixed)]；<br>3.当G1判断不再值得回收老年代区块以获取更多空间的时候，便会结束该阶段，并进入下一个年轻代收集循环。</td></tr></tbody></table><blockquote><p>注意！当 G1 在回收存活对象或者是晋升对象到老年代的时候发生堆空间不足，将会触发晋升失败。此时，G1将进入 STW，并使用单线程来进行 Full GC。如果调优到位的话，你的应用应该避免Full GC发生。</p></blockquote><p>综上，G1 垃圾收集模式分为三种：</p><ul><li><strong>Young GC</strong>：当 G1 评估当前年轻代的回收时间接近 -XX:MaxGCPauseMillis 指定值的时候，会触发 Young GC；</li><li><strong>Mixed GC</strong>：当 老年代占有率达到 -XX:InitiatingHeapOccupancyPercent 指定值的时候，会触发并发周期。而并发清理阶段阶段会判断是否需要进入空间回收周期。在空间回收周期内，会根据期望的GC停顿时间以及区块的回收价值等来决定是否进行以及进行多少次 Mixed GC；</li><li><strong>Full GC</strong>：STW，单线程收集过程。</li></ul><h4 id="常用调优参数：-1"><a href="#常用调优参数：-1" class="headerlink" title="常用调优参数："></a>常用调优参数：</h4><table><thead><tr><th>参数</th><th>参数含义</th><th>默认值</th></tr></thead><tbody><tr><td>-XX:+UseG1GC</td><td>指定使用 G1 垃圾收集器</td><td></td></tr><tr><td>-XX:MaxGCPauseMillis&#x3D;200</td><td>设定一个最大的GC停顿时间目标。这是一个软目标，JVM会尽最大努力满足这个目标。但不宜设置过小，以免因为每次回收垃圾过少而导致频繁 GC。</td><td>200 (ms)</td></tr><tr><td>-XX:GCPauseTimeInterval&#x3D;&lt;ergo&gt;</td><td>GC 停顿间隔时间</td><td>G1 在默认情况下不设置该值，而允许G1在一些极端的情况下连续执行垃圾回收</td></tr><tr><td>-XX:ParallelGCThreads&#x3D;&lt;ergo&gt;</td><td>并行阶段最大的线程数</td><td>根据CPU核心数N进行计算，如果N&lt;8，那么ParallelGCThreads&#x3D;N；如果N&gt;&#x3D;8，那么ParallelGCThreads&#x3D;N*5&#x2F;8</td></tr><tr><td>-XX:ConcGCThreads&#x3D;&lt;ergo&gt;</td><td>并发阶段最大的线程数</td><td>默认值是-XX:ParallelGCThreads的值除以4</td></tr><tr><td>-XX:+G1UseAdaptiveIHOP <br> -XX:InitiatingHeapOccupancyPercent&#x3D;45</td><td>配置启用IHOP，以及配置触发比例</td><td>默认启用，触发比例为45%。注意，-XX:+G1UseAdaptiveIHOP这个选项会在JDK9里默认启用，即-XX:InitiatingHeapOccupancyPercent和XX:+GIUseAdaptivelHOP在JDK9之后只需要启用一个就可以了。JDK8环境下运行该选项会输出:“Unrecognized VM option ‘G1UseAdaptivelHOP’”</td></tr><tr><td>-XX:G1HeapRegionSize&#x3D;&lt;ergo&gt;</td><td>设置区块大小</td><td>整个堆最多划分为2048个Region，Region的大小一定是在1～32M之间，并且是2的N次方。 所以，如果堆的尺寸小于2G，那么Region数量就会少于2048。如果设置的堆大于64G，JVM会适当增加region的数量，但是region大小一定不会超过32M。</td></tr><tr><td>-XX:G1NewSizePercent&#x3D;5<br>-XX:G1MaxNewSizePercent&#x3D;60</td><td>配置年轻代占比的最小值和最大值</td><td>最小值默认为5%，最大值默认为60%</td></tr><tr><td>-XX:G1HeapWastePercent&#x3D;5</td><td>允许浪费的堆内存比例。如果可回收百分比低于这个百分比，那么G1就不会触发Mixed GC。</td><td>默认值5%</td></tr><tr><td>-XX:G1MixedGCCountTarget&#x3D;8</td><td>设置空间清理阶段的回收次数</td><td>默认不超过8次</td></tr><tr><td>-XX:G1MixedGCLiveThresholdPercent&#x3D;85</td><td>如果老年代区块内部存活对象超过该比例，那么在空间清理阶段不会将该区块加入 CSet，也就是不会对其进行回收</td><td>默认值85%</td></tr><tr><td>-XX:G1ReservePercent&#x3D;10</td><td>设置堆的保留空间阈值以降低发生晋升失败的可能。</td><td>默认值是10</td></tr><tr><td>-XX:G1OldCSetRegionThresholdPercent&#x3D;10</td><td>设置Mixed GC期间要回收的老年代Region数量上限，即一次Mixed GC中最多可以被选入CSet中的老年代Region数量。</td><td>默认值10%</td></tr></tbody></table><h4 id="GC-日志案例：-1"><a href="#GC-日志案例：-1" class="headerlink" title="GC 日志案例："></a>GC 日志案例：</h4><ul><li><p>案例一</p><blockquote><p>CommandLine flags: -XX:G1NewSizePercent&#x3D;20 -XX:+HeapDumpOnOutOfMemoryError -XX:InitialHeapSize&#x3D;3221225472 -XX:MaxGCPauseMillis&#x3D;500 -XX:MaxHeapSize&#x3D;5872025600 -XX:-OmitStackTraceInFastThrow -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UnlockExperimentalVMOptions -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC </p></blockquote><pre><code class="bash">## Young GC（以下同，略去详细内容）2021-01-08T04:12:09.331+0800: 1172604.919: [GC pause (G1 Evacuation Pause) (young), 0.0184242 secs]  [Parallel Time: 15.1 ms, GC Workers: 4]      [GC Worker Start (ms): Min: 1172604919.7, Avg: 1172604919.8, Max: 1172604919.8, Diff: 0.1]      [Ext Root Scanning (ms): Min: 1.4, Avg: 1.7, Max: 2.6, Diff: 1.2, Sum: 6.9]      [Update RS (ms): Min: 6.8, Avg: 7.4, Max: 7.8, Diff: 1.0, Sum: 29.8]        [Processed Buffers: Min: 11, Avg: 18.2, Max: 27, Diff: 16, Sum: 73]      [Scan RS (ms): Min: 0.4, Avg: 0.6, Max: 0.6, Diff: 0.2, Sum: 2.2]      [Code Root Scanning (ms): Min: 0.0, Avg: 0.1, Max: 0.1, Diff: 0.1, Sum: 0.3]      [Object Copy (ms): Min: 4.9, Avg: 5.0, Max: 5.1, Diff: 0.2, Sum: 19.9]      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]        [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 4]      [GC Worker Other (ms): Min: 0.1, Avg: 0.1, Max: 0.1, Diff: 0.1, Sum: 0.4]      [GC Worker Total (ms): Min: 14.8, Avg: 14.9, Max: 15.0, Diff: 0.2, Sum: 59.5]      [GC Worker End (ms): Min: 1172604934.6, Avg: 1172604934.6, Max: 1172604934.7, Diff: 0.1]  [Code Root Fixup: 0.0 ms]  [Code Root Purge: 0.0 ms]  [Clear CT: 0.5 ms]  [Other: 2.8 ms]      [Choose CSet: 0.0 ms]      [Ref Proc: 0.3 ms]      [Ref Enq: 0.0 ms]      [Redirty Cards: 0.1 ms]      [Humongous Register: 0.2 ms]      [Humongous Reclaim: 0.0 ms]      [Free CSet: 1.9 ms]  [Eden: 2498.0M(2498.0M)-&gt;0.0B(2496.0M) Survivors: 6144.0K-&gt;6144.0K Heap: 5011.5M(5576.0M)-&gt;2513.8M(5576.0M)][Times: user=0.06 sys=0.00, real=0.02 secs] ## 初始标记 initial-mark2021-01-08T04:12:18.958+0800: 1172614.546: [GC pause (G1 Evacuation Pause) (young) (initial-mark), 0.0199455 secs]  ### ......  [Eden: 2496.0M(2496.0M)-&gt;0.0B(2492.0M) Survivors: 6144.0K-&gt;8192.0K Heap: 5009.8M(5576.0M)-&gt;2515.0M(5576.0M)][Times: user=0.05 sys=0.02, real=0.02 secs] ## 并发根节点扫描2021-01-08T04:12:18.979+0800: 1172614.567: [GC concurrent-root-region-scan-start]2021-01-08T04:12:19.004+0800: 1172614.592: [GC concurrent-root-region-scan-end, 0.0256504 secs]## 并发标记2021-01-08T04:12:19.004+0800: 1172614.592: [GC concurrent-mark-start]2021-01-08T04:12:19.214+0800: 1172614.802: [GC concurrent-mark-end, 0.2101424 secs]## 重新标记2021-01-08T04:12:19.215+0800: 1172614.803: [GC remark 2021-01-08T04:12:19.215+0800: 1172614.803: [Finalize Marking, 0.0003026 secs] 2021-01-08T04:12:19.215+0800: 1172614.803: [GC ref-proc, 0.7285039 secs] 2021-01-08T04:12:19.944+0800: 1172615.532: [Unloading, 0.0301928 secs], 0.7619789 secs][Times: user=0.95 sys=0.02, real=0.77 secs] ## 清理阶段2021-01-08T04:12:19.978+0800: 1172615.566: [GC cleanup 2575M-&gt;2567M(5576M), 0.0076275 secs][Times: user=0.00 sys=0.00, real=0.01 secs] 2021-01-08T04:12:19.986+0800: 1172615.574: [GC concurrent-cleanup-start]2021-01-08T04:12:19.986+0800: 1172615.574: [GC concurrent-cleanup-end, 0.0000396 secs]## 空间收集阶段的 young gc2021-01-08T04:12:28.168+0800: 1172623.756: [GC pause (G1 Evacuation Pause) (young), 0.0249811 secs]   ### ......  [Eden: 2492.0M(2492.0M)-&gt;0.0B(1110.0M) Survivors: 8192.0K-&gt;4096.0K Heap: 4999.0M(5576.0M)-&gt;2504.2M(5576.0M)][Times: user=0.06 sys=0.03, real=0.02 secs] ## 空间收集阶段的 young gc（mixed)2021-01-08T04:12:31.149+0800: 1172626.737: [GC pause (G1 Evacuation Pause) (mixed), 0.0437074 secs]  ### ......  [Eden: 1110.0M(1110.0M)-&gt;0.0B(1108.0M) Survivors: 4096.0K-&gt;6144.0K Heap: 3614.2M(5576.0M)-&gt;2206.5M(5576.0M)][Times: user=0.10 sys=0.04, real=0.04 secs] ## 空间收集阶段的 young gc（mixed)2021-01-08T04:12:34.734+0800: 1172630.322: [GC pause (G1 Evacuation Pause) (mixed), 0.0397893 secs]  ### ......  [Eden: 1108.0M(1108.0M)-&gt;0.0B(1108.0M) Survivors: 6144.0K-&gt;6144.0K Heap: 3314.5M(5576.0M)-&gt;1916.7M(5576.0M)][Times: user=0.10 sys=0.04, real=0.04 secs] ## 空间收集阶段的 young gc（mixed)2021-01-08T04:12:39.836+0800: 1172635.424: [GC pause (G1 Evacuation Pause) (mixed), 0.0539989 secs]  ### ......  [Eden: 1108.0M(1108.0M)-&gt;0.0B(1110.0M) Survivors: 6144.0K-&gt;4096.0K Heap: 3024.7M(5576.0M)-&gt;1536.4M(5576.0M)][Times: user=0.13 sys=0.05, real=0.05 secs] </code></pre><ul><li>案例二</li></ul><pre><code class="bash">## 大对象收集[GC pause (G1 Humongous Allocation) (young), 0.0022191 secs] [Parallel Time: 1.3 ms, GC Workers: 4]    [GC Worker Start (ms): Min: 909912.8, Avg: 909913.1, Max: 909913.9, Diff: 1.1]    [Ext Root Scanning (ms): Min: 0.0, Avg: 0.3, Max: 0.4, Diff: 0.4, Sum: 1.1]    [Update RS (ms): Min: 0.0, Avg: 0.1, Max: 0.3, Diff: 0.3, Sum: 0.4]       [Processed Buffers: Min: 0, Avg: 2.2, Max: 3, Diff: 3, Sum: 9]    [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]    [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]    [Object Copy (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.1]    [Termination (ms): Min: 0.0, Avg: 0.5, Max: 0.7, Diff: 0.7, Sum: 1.8]       [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 4]    [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1]    [GC Worker Total (ms): Min: 0.0, Avg: 0.9, Max: 1.2, Diff: 1.2, Sum: 3.5]    [GC Worker End (ms): Min: 909914.0, Avg: 909914.0, Max: 909914.1, Diff: 0.1] [Code Root Fixup: 0.0 ms] [Code Root Purge: 0.0 ms] [Clear CT: 0.0 ms] [Other: 0.9 ms]    [Choose CSet: 0.0 ms]    [Ref Proc: 0.8 ms]    [Ref Enq: 0.0 ms]    [Redirty Cards: 0.1 ms]    [Humongous Register: 0.0 ms]    [Humongous Reclaim: 0.0 ms]    [Free CSet: 0.0 ms] [Eden: 0.0B(2048.0K)-&gt;0.0B(2048.0K) Survivors: 0.0B-&gt;0.0B Heap: 38.1M(50.0M)-&gt;38.1M(50.0M)][Times: user=0.00 sys=0.01, real=0.00 secs] ## Full GC[Full GC (Allocation Failure)  38M-&gt;37M(50M), 0.0419625 secs]  [Eden: 0.0B(2048.0K)-&gt;0.0B(2048.0K) Survivors: 0.0B-&gt;0.0B Heap: 38.1M(50.0M)-&gt;37.9M(50.0M)], [Metaspace: 30407K-&gt;30407K(1077248K)][Times: user=0.05 sys=0.00, real=0.04 secs] [Full GC (Allocation Failure)  37M-&gt;37M(50M), 0.0346627 secs]  [Eden: 0.0B(2048.0K)-&gt;0.0B(2048.0K) Survivors: 0.0B-&gt;0.0B Heap: 37.9M(50.0M)-&gt;37.9M(50.0M)], [Metaspace: 30407K-&gt;30407K(1077248K)][Times: user=0.05 sys=0.00, real=0.04 secs] </code></pre></li></ul><h2 id="低延迟垃圾收集器"><a href="#低延迟垃圾收集器" class="headerlink" title="低延迟垃圾收集器"></a>低延迟垃圾收集器</h2><ul><li>ZGC 收集器：JDK11 中推出的一款低延迟垃圾回收器，适用于大内存低延迟服务的内存管理和回收，SPECjbb 2015 基准测试，在 128G 的大堆下，最大停顿时间才 1.68 ms，停顿时间远胜于 G1 和 CMS。</li><li>Shenandoah 收集器：由 Red Hat 的一个团队负责开发，与 G1 类似，基于 Region 设计的垃圾收集器，但不需要 Remember Set 或者 Card Table 来记录跨 Region 引用，停顿时间和堆的大小没有任何关系。停顿时间与 ZGC 接近。</li></ul><h1 id="常用垃圾收集器公共参数"><a href="#常用垃圾收集器公共参数" class="headerlink" title="常用垃圾收集器公共参数"></a>常用垃圾收集器公共参数</h1><ul><li><p>以下两个命令结合起来可以大致推敲 JVM 默认参数：</p><pre><code>  java -XX:+PrintFlagsInitial $&#123;pid&#125;  jinfo $&#123;pid&#125;</code></pre></li><li><p>以下列举常用的一些公共参数：</p><table><thead><tr><th>参数</th><th>参数含义</th><th>默认值</th></tr></thead><tbody><tr><td>-Xms -Xmx -Xmn</td><td>指定堆启动内存、堆最大内存、年轻代内存。比如 -Xmx5g 表示堆最大内存为5g。</td><td></td></tr><tr><td>-XX:ErrorFile&#x3D;file</td><td>指定 Fatal Error日志文件位置，比如：.&#x2F;java_error_%p.log</td><td></td></tr><tr><td>-XX:+HeapDumpOnOutOfMemoryError</td><td>指示 JVM 发生 OutOfMemory 的时候输出 dump 文件</td><td></td></tr><tr><td>-XX:-OmitStackTraceInFastThrow</td><td>该参数禁用 OmitStackTraceInFastThrow。OmitStackTraceInFastThrow 默认开启，指示 hotspot 使用fast throw来优化这个抛出异常的地方，直接抛出一个事先分配好的、类型匹配的对象，这个对象的message和stack trace都被清空。所以开启OmitStackTraceInFastThrow不利于排查问题。</td><td></td></tr><tr><td>-XX:+PrintGC</td><td>指示输出简要GC日志</td><td></td></tr><tr><td>-XX:+PrintGCDetails</td><td>指示输出详细GC日志</td><td></td></tr><tr><td>-XX:+PrintGCApplicationStoppedTime</td><td>指示打印STW时间</td><td></td></tr><tr><td>-XX:+PrintGCDateStamps</td><td>指示输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）</td><td></td></tr><tr><td>-XX:+PrintGCTimeStamps</td><td>该参数指示输出GC的时间戳（以JVM启动到当期的总时长的时间戳形式）</td><td></td></tr><tr><td>-XX:+UseCompressedClassPointers</td><td>该参数指示压缩kclass指针大小</td><td></td></tr><tr><td>-XX:+UseCompressedOops</td><td>该参数指示进行指针压缩（包含kclass指针和对象指针）</td><td></td></tr><tr><td>-Xloggc:${GC_LOG_PATH}</td><td>该参数指示输出GC日志到文件</td><td></td></tr><tr><td>-XX:SurvivorRatio&#x3D;8</td><td>该参数设置的是Eden区与每一个Survivor区的比值，可以反推出占新生代的比值，Eden为8, 两个Survivor为1, Eden占新生代的4&#x2F;5, 每个Survivor占1&#x2F;10，两个占1&#x2F;5</td><td>默认8</td></tr><tr><td>-XX:MetaspaceSize&#x3D;64m <br> -XX:MaxMetaspaceSize&#x3D;128M</td><td>该参数指定元数据空间初始扩容阈值为64m，最大扩容空间为128M</td><td>默认值无穷大</td></tr></tbody></table></li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><h2 id="G1-资料"><a href="#G1-资料" class="headerlink" title="G1 资料"></a>G1 资料</h2><ul><li><a href="https://www.cnblogs.com/GrimMjx/p/12234564.html#_label2">《搞懂G1垃圾收集器》</a></li><li><a href="https://www.oracle.com/technetwork/tutorials/tutorials-1876574.html">《Getting Started with the G1 Garbage Collector》</a></li><li><a href="https://www.infoq.com/articles/G1-One-Garbage-Collector-To-Rule-Them-All/">《G1: One Garbage Collector To Rule Them All》</a></li><li><a href="https://www.oracle.com/technical-resources/articles/java/g1gc.html">《Garbage First Garbage Collector Tuning》</a></li></ul><h2 id="其他资料"><a href="#其他资料" class="headerlink" title="其他资料"></a>其他资料</h2><ul><li><a href="https://tech.meituan.com/2020/11/12/java-9-cms-gc.html">Java中9种常见的CMS GC问题分析与解决</a>:美团技术团队出品，深度分析了常见的多种 GC 优化情景。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
            <tag> Java </tag>
            
            <tag> 垃圾收集器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 虚拟机原理 (二) 对象创建与回收</title>
      <link href="/2021/01/08/Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86-2-%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA%E5%92%8C%E5%9B%9E%E6%94%B6/"/>
      <url>/2021/01/08/Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86-2-%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA%E5%92%8C%E5%9B%9E%E6%94%B6/</url>
      
        <content type="html"><![CDATA[<p>Java 虚拟机技术是每个 Java 开发工程师都应该深入掌握的。本系列文章将深入介绍 JVM 相关技术，主要包括内存划分、对象创建回收与分配以及垃圾收集三大部分。本系列文章将力求全面概要地汇总核心知识点，并使知识点串联成面，以方便学习、工作以及备忘复习。本文将介绍第二部分——对象创建与回收。</p><span id="more"></span><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%9B%9E%E6%94%B6%2F%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA%E5%9B%9E%E6%94%B6%E4%BB%A5%E5%8F%8A%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.png" alt="对象创建与回收思维导图"></p><h2 id="对象创建"><a href="#对象创建" class="headerlink" title="对象创建"></a>对象创建</h2><p>对象在 JVM 的创建过程可见下图：<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%9B%9E%E6%94%B6%2FJVM%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA%E8%BF%87%E7%A8%8B.png" alt="JVM对象创建过程.png"></p><h3 id="类加载检查"><a href="#类加载检查" class="headerlink" title="类加载检查"></a>类加载检查</h3><p>虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个<br>符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。</p><h3 id="类加载"><a href="#类加载" class="headerlink" title="类加载"></a>类加载</h3><p>这部分之前已经探讨过，参见<a href="https://blog.duval.top/2020/12/28/%E4%B8%80%E6%96%87%E5%BD%BB%E5%BA%95%E6%8E%8C%E6%8F%A1-Java-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/">《一文彻底掌握 Java 类加载机制》</a>。</p><p>简单来说，就是类对象的加载、连接（验证-&gt;准备-&gt;解析）和初始化（&lt;clinit&gt;方法)等过程。</p><h3 id="分配内存"><a href="#分配内存" class="headerlink" title="分配内存"></a>分配内存</h3><h4 id="分配方法"><a href="#分配方法" class="headerlink" title="分配方法"></a>分配方法</h4><p>类加载完毕后，类的新对象所需要的内存大小已经确定。这时候可以为新对象在堆中分配空间。分配空间的算法在不同的垃圾收集器中实现不一样。常见有以下两种解决方案：</p><ul><li>指针碰撞：内存空间是规整，使用和未使用的空间由指针相隔，则从指针位置开始尝试申请一块空闲空间。Serial、ParNew 采用此法；</li><li>空闲列表：内存空间是零碎的，JVM 需要维护一个空闲内存列表，分配时从列表里选取一块内存用于分配对象，并更新空闲列表。CMS 采用此法；</li></ul><h4 id="并发方法"><a href="#并发方法" class="headerlink" title="并发方法"></a>并发方法</h4><p>并发情况下分配内存，存在线程安全问题，常见解决方案：</p><ul><li>CAS：JVM 使用 CAS 和失败重试来保证操作原子性，从而对分配内存的过程进行同步处理，以实现并发安全；</li><li>TLAB（Thread Local Allocation Buffer）：即线程本地分配缓存区。每个线程预先分配一小块内存空间，然后每个线程的对象分配在各自的 TLAB 空间进行，互不干扰。通过虚拟机参数 -XX:UseTLAB 可以开启该功能。</li></ul><h4 id="其他技术要点"><a href="#其他技术要点" class="headerlink" title="其他技术要点"></a>其他技术要点</h4><h5 id="对象栈上分配"><a href="#对象栈上分配" class="headerlink" title="对象栈上分配"></a>对象栈上分配</h5><ul><li><p><strong>逃逸分析</strong> (-XX:+DoEscapeAnalysis，JDK7后默认开启)</p><p>  JVM 通过对象逃逸分析确定对象是否会被外部访问，如果不会逃逸则该对象将在栈上分配。栈上分配的内存空间会随着出栈销毁，避免对象分配在堆中，从而减轻回收压力。</p><p>  注意默认情况下，数组对象长度超过64时不会通过逃逸分析优化，会自动在堆上分配。这个大小可以通过启动参数-XX:EliminateAllocationArraySizeLimit&#x3D;n来进行控制，n是数组的大小。</p></li><li><p><strong>标量分析</strong> (-XX:+EliminateAllocations, JDK7后默认开启)</p><p>  通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，JVM不会创建该对象，而是将该 对象成员变量分解若干个被这个方法使用的成员变量所代替，这些代替的成员变量在栈帧或寄存器上分配空间，这样就 不会因为没有一大块连续空间导致对象内存不够分配。</p></li></ul><h5 id="对象在新生代分配"><a href="#对象在新生代分配" class="headerlink" title="对象在新生代分配"></a>对象在新生代分配</h5><p>大多数情况下，对象都在新生代中分配。当新生代中的 Eden 区以及其中一个 Survivor 区没有足够空间的时候，会触发一次 Minor GC，并将剩余存活对象移动到另一个空的 Survivor 区。</p><p>Eden与Survivor区默认8:1:1。可以通过参数 -XX:SurvivorRatio&#x3D;n 改变这个比例，该参数设置的是Eden区与每一个Survivor区的比值，例如当n&#x3D;8可以反推出占新生代的比值，Eden为8, 两个Survivor为1, Eden占新生代的4&#x2F;5, 每个Survivor占1&#x2F;10，两个占1&#x2F;5。</p><p>JVM还有个参数-XX:+UseAdaptiveSizePolicy(默认开启)，会导致这个8:1:1比例自动变化，如果不想这个比例有变 化可以设置参数-XX:-UseAdaptiveSizePolicy。</p><h5 id="大对象直接进入老年代"><a href="#大对象直接进入老年代" class="headerlink" title="大对象直接进入老年代"></a>大对象直接进入老年代</h5><p>大对象需要大量连续内存空间（比如：字符串、数组等）。一般情况下大对象会在新生代分配。另外存在两种情况会直接分配到老年代：</p><ul><li>在 Serial 和 ParNew 这两个收集器下，可以通过参数  -XX:PretenureSizeThreshold&#x3D;n 设置大对象的大小（n 是字节数），此时大对象会直接分配到老年代；</li><li>在 G1 收集器下，超过 Region 大小的一半的对象，会直接分配到老年代。</li></ul><blockquote><p>因为大对象占用较大空间，在新生代里复制十几次才被晋升的话，效率太低。</p></blockquote><h5 id="老对象进入老年代"><a href="#老对象进入老年代" class="headerlink" title="老对象进入老年代"></a>老对象进入老年代</h5><p>如果一个对象在新生代多次回收依然存活，则会被晋升到老年代。通过参数 -XX:MaxTenuringThreshold 设置年龄阈值。（一般默认值是15，CMS是6）。</p><blockquote><p>通过 -XX:+PrintFlagsFinal 可以打印启动后参数值</p></blockquote><h5 id="对象动态年龄判断"><a href="#对象动态年龄判断" class="headerlink" title="对象动态年龄判断"></a>对象动态年龄判断</h5><p>在一次 minor GC之后 JVM 将当前保存对象的 Survivor 区对象从年龄小到大排序，并累加，如果当前对象占用内存总和超过了 Survivor 区的50%，则剩下的较老的对象会直接晋升老年代。通过参数 -XX:TargetSurvivorRatio 可以改变该比例，默认值是50%。</p><h5 id="老年代空间担保"><a href="#老年代空间担保" class="headerlink" title="老年代空间担保"></a>老年代空间担保</h5><p>简单来说，就是 Minor GC 前先看看老年代是否有足够剩余空间，如果没有则先触发 Full GC。具体流程看图：<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%9B%9E%E6%94%B6%2F%E8%80%81%E5%B9%B4%E4%BB%A3%E7%A9%BA%E9%97%B4%E6%8B%85%E4%BF%9D%E6%9C%BA%E5%88%B6.png" alt="老年代空间担保机制.png"></p><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>分配内存结束后，对象会被初始化为零值；如果使用 TLAB，则提前至 TLAB 分配时进行。这个阶段确保了对象新建后不用对其字段赋值，便可以使用其字段默认零值的原因，如下：</p><pre><code class="java">public class App &#123;    private int value;    private boolean flag;    private App app;    public App() &#123;        System.out.println(&quot;value=&quot; + value);        System.out.println(&quot;flag=&quot; + flag);        System.out.println(&quot;app=&quot; + app);    &#125;    public static void main(String[] args) &#123;        new App();    &#125;&#125;</code></pre><p>输出结果：</p><pre><code>value=0flag=falseapp=null</code></pre><h3 id="设置对象头"><a href="#设置对象头" class="headerlink" title="设置对象头"></a>设置对象头</h3><p>对象空间划分为对象头和实例数据两部分，其中对象头又包含以下几个部分：</p><ul><li><p><strong>Mark Word 标记字段</strong></p><p>Mark Word 在32位 JVM 占32bit，64位系统占64bit。Mark Word在不同的锁状态下存储的内容不同，在32位JVM中是这么存的：<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA%E4%B8%8E%E5%9B%9E%E6%94%B6%2Fmarkword.png" alt="markword.png"></p></li><li><p><strong>Kclass 类型指针</strong></p><p>类的元数据指针，而元数据是保存在方法区（或元空间）。在64位 JVM 中，开启指针压缩占用32bit，不开启的话占用64bit；在32位 JVM 中，占用32bit。</p></li><li><p><strong>数组长度</strong>（只有数组对象才有）</p><p>只有数组才会有该字段，占用32bit。</p></li><li><p><strong>填充字节</strong> </p><p>JVM 要求对象空间长度是 8 字节的倍数。如果不满足倍数关系，需要填充</p></li></ul><h4 id="指针压缩"><a href="#指针压缩" class="headerlink" title="指针压缩"></a>指针压缩</h4><p>从 JDK1.6 update 14开始，JVM 在64位系统开始支持指针压缩，主要包含两个参数：</p><ul><li>-XX:+UseCompressedOops 开启压缩所有指针（默认开启，禁用可用-XX:-UseCompressedOops）；</li><li>-XX:+UseCompressedClassPointers 开启压缩对象头里的类型指针Klass Pointer（默认开启，禁用可用-XX:-UseCompressedClassPointers）。</li></ul><p>使用 <a href="https://github.com/duval1024/java-all-in-one/blob/master/jdk-source-learn/src/main/java/org/demo/jvm/MarkWordTest.java">MarkWordTest</a> 可以验证压缩效果，仓库可能还没公开，先贴下代码：</p><pre><code class="java">public class MarkWordTest &#123;    public static void main(String[] args) &#123;        ClassLayout layout = ClassLayout.parseInstance(new Object());        System.out.println(layout.toPrintable());        System.out.println();        ClassLayout layout2 = ClassLayout.parseInstance(new int[10]);        System.out.println(layout2.toPrintable());        System.out.println();        ClassLayout layout3 = ClassLayout.parseInstance(new Person());        System.out.println(layout3.toPrintable());    &#125;    static class Person &#123;        private byte enable;        private int age;        String name;    &#125;&#125;</code></pre><p>禁用压缩指针效果：</p><pre><code class="text">java.lang.Object object internals: OFFSET  SIZE   TYPE DESCRIPTION                               VALUE      0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)      8     4        (object header)                           00 dc 46 16 (00000000 11011100 01000110 00010110) (373742592)     12     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)Instance size: 16 bytesSpace losses: 0 bytes internal + 0 bytes external = 0 bytes total[I object internals: OFFSET  SIZE   TYPE DESCRIPTION                               VALUE      0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)      8     4        (object header)                           68 cb 46 16 (01101000 11001011 01000110 00010110) (373738344)     12     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)     16     4        (object header)                           0a 00 00 00 (00001010 00000000 00000000 00000000) (10)     20     4        (alignment/padding gap)                       24    40    int [I.&lt;elements&gt;                             N/AInstance size: 64 bytesSpace losses: 4 bytes internal + 0 bytes external = 4 bytes totalorg.demo.jvm.MarkWordTest$Person object internals: OFFSET  SIZE               TYPE DESCRIPTION                               VALUE      0     4                    (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)      4     4                    (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)      8     4                    (object header)                           c8 a4 22 18 (11001000 10100100 00100010 00011000) (404923592)     12     4                    (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)     16     4                int Person.age                                0     20     1               byte Person.enable                             0     21     3                    (alignment/padding gap)                       24     8   java.lang.String Person.name                               nullInstance size: 32 bytesSpace losses: 3 bytes internal + 0 bytes external = 3 bytes total</code></pre><p>启动指针压缩效果：</p><pre><code class="text">java.lang.Object object internals: OFFSET  SIZE   TYPE DESCRIPTION                               VALUE      0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)      8     4        (object header)                           e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243)     12     4        (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total[I object internals: OFFSET  SIZE   TYPE DESCRIPTION                               VALUE      0     4        (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)      4     4        (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)      8     4        (object header)                           6d 01 00 f8 (01101101 00000001 00000000 11111000) (-134217363)     12     4        (object header)                           0a 00 00 00 (00001010 00000000 00000000 00000000) (10)     16    40    int [I.&lt;elements&gt;                             N/AInstance size: 56 bytesSpace losses: 0 bytes internal + 0 bytes external = 0 bytes totalorg.demo.jvm.MarkWordTest$Person object internals: OFFSET  SIZE               TYPE DESCRIPTION                               VALUE      0     4                    (object header)                           01 00 00 00 (00000001 00000000 00000000 00000000) (1)      4     4                    (object header)                           00 00 00 00 (00000000 00000000 00000000 00000000) (0)      8     4                    (object header)                           4e f2 00 f8 (01001110 11110010 00000000 11111000) (-134155698)     12     4                int Person.age                                0     16     1               byte Person.enable                             0     17     3                    (alignment/padding gap)                       20     4   java.lang.String Person.name                               nullInstance size: 24 bytesSpace losses: 3 bytes internal + 0 bytes external = 3 bytes total</code></pre><h4 id="为何需要指针压缩？"><a href="#为何需要指针压缩？" class="headerlink" title="为何需要指针压缩？"></a>为何需要指针压缩？</h4><ul><li>64位 JVM 中使用指针压缩，可以大大减少内存占用，降低内存压力；</li><li>32位 JVM 支持最大的内存是4G（2^32）；</li><li>64位 JVM 中，如果堆内存小于4G，不需要开启指针压缩，JVM 会直接去掉高32位地址；而当堆空间超过32G的时候，指针压缩会失效，强制改为使用64位地址空间。这和指针压缩的实现原理有关。简单来说，指针压缩是从byte的角度寻址，而不是从bit的角度，因为堆里的对象都是8字节对齐的，堆内使用字节角度来寻址更快更优，当然在寄存器层面依然是按位寻址。</li></ul><p>两种寻址方式的图解如下：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%2F%E6%8C%89%E4%BD%8D%E5%AF%BB%E5%9D%80%E4%B8%8E%E6%8C%89%E5%AD%97%E5%AF%BB%E5%9D%80.jpg" alt="按位寻址与按字寻址.jpg"></p><h3 id="执行方法"><a href="#执行方法" class="headerlink" title="执行&lt;init&gt;方法"></a>执行&lt;init&gt;方法</h3><p>&lt;init&gt;方法是由 JVM 生成的方法，会执行一系列的初始化，按顺序包括：</p><ul><li>父类变量初始化</li><li>父类语句块</li><li>父类构造函数</li><li>子类变量初始化</li><li>子类语句块</li><li>子类构造函数</li></ul><p>这里提一下类加载过程中的&lt;clinit&gt;方法，其内部的初始化步骤按顺序包括：</p><ul><li>父类静态变量初始化</li><li>父类静态语句块</li><li>子类静态变量初始化</li><li>子类静态语句块</li></ul><p>读者需要注意区分 &lt;clinit&gt; 和 &lt;init&gt;，前者是在类加载阶段执行，而后者是在对象初始化之后执行。也就是说 &lt;clinit&gt; 一定先于 &lt;init&gt; 执行。</p><h2 id="对象回收"><a href="#对象回收" class="headerlink" title="对象回收"></a>对象回收</h2><h3 id="对象存活判断算法"><a href="#对象存活判断算法" class="headerlink" title="对象存活判断算法"></a>对象存活判断算法</h3><p>常见的垃圾回收器都是通过标记那些存活对象，而没有得到标记的对象将成为垃圾对象被回收。常见的判断对象存活算法有二：</p><ul><li><strong>引用计数法</strong>：简单高效，但是很难解决循环依赖问题。</li><li><strong>可达性分析算法</strong>：大多数垃圾收集器都采用此法。可达性算法的GC Roots根节点一般是线程栈本地变量、静态变量、本地方法栈变量等等。</li></ul><h3 id="常见引用类型"><a href="#常见引用类型" class="headerlink" title="常见引用类型"></a>常见引用类型</h3><ul><li><strong>强引用</strong>：最常见的引用方式<pre><code class="java">    Person person = new Person();</code></pre></li><li><strong>软引用</strong>：使用 SoftReference 包裹的对象，正常情况下不会回收，但如果 GC 后依然无法释放空间存放新对象的时候，会把软引用对象回收掉。<pre><code class="java">    SoftReference&lt;Person&gt; persion = new SoftReference&lt;&gt;(new Person());</code></pre></li><li><strong>弱引用</strong>：使用 WeakReference 包裹的对象，只要发生 GC 会直接被回收掉。<pre><code class="java">   WeakReference&lt;Person&gt; persion = new WeakReference&lt;&gt;(new Person());</code></pre></li><li><strong>虚引用</strong>：最弱的一种引用关系。</li></ul><h3 id="Finalize-方法"><a href="#Finalize-方法" class="headerlink" title="Finalize 方法"></a>Finalize 方法</h3><p>每个对象再回收前都会执行且仅执行一次其 Finalize 方法。一般情况下，不要尝试重载该方法。</p><h3 id="回收方法区"><a href="#回收方法区" class="headerlink" title="回收方法区"></a>回收方法区</h3><p>无用类判断条件：</p><ul><li>该类的所有实例都已经被回收；</li><li>加载该类的 ClassLoader 已经被回收；</li><li>该类的 Class 对象已经没有任何引用。</li></ul><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://juejin.cn/post/6844903957836333063">《Java 对象创建过程。init 方法和 clinit方法》</a></li><li><a href="http://youngforzy.top/2017/10/26/JVM%E4%B9%8B%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA%E8%BF%87%E7%A8%8B/">《JVM之对象创建过程》</a></li><li><a href="https://blog.duval.top/2020/12/28/%E4%B8%80%E6%96%87%E5%BD%BB%E5%BA%95%E6%8E%8C%E6%8F%A1-Java-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/">《一文彻底掌握 Java 类加载机制》</a></li><li><a href="https://ifeve.com/jvm%E4%BC%98%E5%8C%96%E4%B9%8B%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90%E5%8F%8A%E9%94%81%E6%B6%88%E9%99%A4/">《JVM优化之逃逸分析及锁消除》</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 虚拟机原理 (一) 内存划分</title>
      <link href="/2021/01/07/Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86-1-%E5%86%85%E5%AD%98%E5%88%92%E5%88%86/"/>
      <url>/2021/01/07/Java-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86-1-%E5%86%85%E5%AD%98%E5%88%92%E5%88%86/</url>
      
        <content type="html"><![CDATA[<p>Java 虚拟机技术是每个 Java 开发工程师都应该深入掌握的。本系列文章将深入介绍 JVM 相关技术，主要包括内存划分、对象创建回收与分配以及垃圾收集三大部分。本系列文章将力求全面概要地汇总核心知识点，并使知识点串联成面，以方便学习、工作以及备忘复习。本文将介绍第一部分:内存划分。</p><span id="more"></span><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%86%85%E5%AD%98%E5%88%92%E5%88%86%2FJVM%20%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE.png" alt="JVM 内存模型思维导图"></p><h2 id="JDK-体系架构"><a href="#JDK-体系架构" class="headerlink" title="JDK 体系架构"></a>JDK 体系架构</h2><p>先从宏观上来看 JVM 所处的位置，且看官方文档的<a href="https://docs.oracle.com/javase/8/docs/">体系架构图</a>：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%86%85%E5%AD%98%E5%88%92%E5%88%86%2FJDK%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="JDK体系架构图.png"></p><ul><li>JVM（Java Virtual Machine）：处于整个体系最底层，直接与不同的操作系统打交道，因此针对不同的系统有相应的 JVM 实现。Java 程序正是借助 JVM 实现了“一处编写处处运行“的跨平台能力；</li><li>JRE（Java SE Runtime Environment）：Java 运行时环境，是在 JVM 基础上增加 Java 基础类库。Java 程序可以运行在 JRE 之上；</li><li>JDK（Java SE Development Kit）：Java 开发工具包，是在 JRE 基础上增加了开发 Java 程序所需要的各种工具包。</li></ul><p>因此本系列文章主要探讨最底层的 JVM 底层原理。</p><h2 id="JVM-内存模型"><a href="#JVM-内存模型" class="headerlink" title="JVM 内存模型"></a>JVM 内存模型</h2><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%86%85%E5%AD%98%E5%88%92%E5%88%86%2FJVM%20%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%9B%BE.jpg" alt="JVM 内存模型图.jpg"></p><p>上图展示的是以下样例代码的内存模型：</p><pre><code class="java">public class App &#123;    private int plus() &#123;        int a = 1;        int b = 1;        int c = a + b;        return c;    &#125;    public static void main(String[] args) &#123;        App obj = new App();        System.out.println(obj.plus());    &#125;&#125;</code></pre><p>JVM 运行时数据区域包括以下五部分：</p><ul><li>程序计数器：每个线程都会有独立的程序计数器，用于记录当前程序运行到的位置，以便线程切换时能够恢复到当前运行位置；</li><li>Java 虚拟机栈：即是图中线程内部的 Java 线程栈。每个线程也都拥有自己的线程栈。线程栈遵循先进后出（FILO）原则，内部包含多个栈帧。每一个栈帧由局部变量表、操作数栈、动态链接以及方法出口等构成；</li><li>本地方法栈：与虚拟机栈类似，但保存的是 native 方法调用栈；</li><li>堆：运行时数据区域中最大的一部分，是大部分对象保存的地方。JVM 常常使用分代收集算法回收该区域；</li><li>方法区：JDK8 里变更为元空间（metaspace），直接保存在直接内存中（注意直接内存不属于 JVM 运行时数据区域）。方法区主要保存类信息、运行时常量池、静态变量、即时编译器编译后的代码等数据。</li></ul><p>此外，直接内存也是非常重要一部分内存空间。 JVM 元数据空间以及 Java NIO 等都是用到直接内存。</p><h2 id="JVM-参数"><a href="#JVM-参数" class="headerlink" title="JVM 参数"></a>JVM 参数</h2><p>JVM 提供了若干参数来控制上述各个区域的大小，如下图所示：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FJava%20%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8E%9F%E7%90%86%E4%B9%8B%E5%86%85%E5%AD%98%E5%88%92%E5%88%86%2FJVM%20%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E8%B0%83%E4%BC%98%E5%8F%82%E6%95%B0.jpg" alt="JVM 内存模型与调优参数.jpg"></p><p>配置样例如：</p><pre><code class="bash">java -Xmx6g -Xms6g -Xmn3g -Xss512K -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:SurvivorRatio=8 -XX:MetaspaceSize=64m ‐XX:MaxMetaspaceSize=128M -jar myapp.jar</code></pre><p>需要注意，元数据空间在缺省参数的情况下，默认初始大小为21M，如果发生空间不足，会触发 Full GC 进行扩容，且最大扩容空间可为所有的机器内存。所以一定要配置元数据空间参数，且 MetaspaceSize 和 MaxMetaspaceSize 最好相等，从而从根源上杜绝 Full GC 扩容。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://juejin.cn/post/6844903592374042637">JVM内存模型</a>：该文将 Java 内存模型介绍得非常具体详细。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一文彻底掌握 Java 类加载机制</title>
      <link href="/2020/12/28/%E4%B8%80%E6%96%87%E5%BD%BB%E5%BA%95%E6%8E%8C%E6%8F%A1-Java-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/12/28/%E4%B8%80%E6%96%87%E5%BD%BB%E5%BA%95%E6%8E%8C%E6%8F%A1-Java-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>本来想归纳总结下 Java 类加载机制，但发现网上相关文章非常完备充分，此处仅摘录相关资料已备忘复习。</p><span id="more"></span><h2 id="思维导图"><a href="#思维导图" class="headerlink" title="思维导图"></a>思维导图</h2><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E4%B8%80%E6%96%87%E5%BD%BB%E5%BA%95%E6%8E%8C%E6%8F%A1%20Java%20%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2FJava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6.png" alt="Java类加载机制.png"></p><h2 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h2><ul><li>《深入理解Java虚拟机》 周志明 : 全网最佳资料，其他资料大多是二次生产自该书第7章</li><li><a href="http://fanyilun.me/2018/12/29/%E7%90%86%E8%A7%A3Java%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/">理解Java类加载机制</a></li><li><a href="https://blog.csdn.net/sky__fall/article/details/109698544">能不能自己写一个类叫java.lang.System&#x2F;String？网上答案都是错的–ClassLoader详解</a> ：这文章介绍了 -Xbootclasspath 参数，值得一看。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 类加载机制 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一文彻底掌握Java IO类库</title>
      <link href="/2020/12/23/%E4%B8%80%E6%96%87%E5%BD%BB%E5%BA%95%E6%8E%8C%E6%8F%A1Java-IO%E7%B1%BB%E5%BA%93/"/>
      <url>/2020/12/23/%E4%B8%80%E6%96%87%E5%BD%BB%E5%BA%95%E6%8E%8C%E6%8F%A1Java-IO%E7%B1%BB%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<p>Java开发过程中经常会用到 Java IO 类库，本文将深入源码，带你彻底掌握 Java IO 类库。</p><span id="more"></span><h2 id="Java-IO类图框架"><a href="#Java-IO类图框架" class="headerlink" title="Java IO类图框架"></a>Java IO类图框架</h2><p>Java IO 类库可以大体划分为字节流和字符流两大类，再根据输入和输出两种情况，可以再分为四小类。所以<a href="https://bubcoaxnbl.feishu.cn/mindnotes/bmncnZAhJYFx5oWnuECGAXR2Fhd">大致框架图</a>如下所示：<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E4%B8%80%E6%96%87%E5%BD%BB%E5%BA%95%E6%8E%8C%E6%8F%A1Java%20IO%E7%B1%BB%E5%BA%93%2FJava%20IO%20%E7%B1%BB%E5%9B%BE.png" alt="Java IO 类图.png"></p><p>如上图，Java 类图并不繁多，而且分类和命名都非常清晰。其中需要重点掌握的类已经加粗展示在图里。</p><p>下边我们逐类逐个展开分析整个类库。</p><h2 id="字节流"><a href="#字节流" class="headerlink" title="字节流"></a>字节流</h2><p>顾名思义，字节流相关类是处理字节类型数据的，而且都是以『Stream』为后缀的类。根据输入输出类型，可以划分为 InputStream 或 OutputStream 的两大类的实现类。</p><h3 id="InputStream"><a href="#InputStream" class="headerlink" title="InputStream"></a>InputStream</h3><p>先看看内部方法：</p><pre><code class="java">public abstract class InputStream implements Closeable &#123;    public abstract int read() throws IOException;    public int read(byte b[]) throws IOException &#123;/***/&#125;    public int read(byte b[], int off, int len) throws IOException &#123;/***/&#125;    public long skip(long n) throws IOException &#123;/***/&#125;    public int available() throws IOException &#123;/***/&#125;    public void close() throws IOException &#123;/***/&#125;    public synchronized void mark(int readlimit) &#123;/***/&#125;    public synchronized void reset() throws IOException &#123;/***/&#125;    public boolean markSupported() &#123;/***/&#125;</code></pre><p>InputStream 实现了 Closeable 接口，并且内部只有一个抽象方法 read， 所有实现类都强制要求实现该方法。其他方法提供了非常扼要的默认实现，实现类可以酌情覆盖实现。</p><h4 id="FileInputStream"><a href="#FileInputStream" class="headerlink" title="FileInputStream"></a>FileInputStream</h4><p>在<a href="https://blog.duval.top/2020/12/16/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E6%96%87%E4%BB%B6%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%B5%81%E5%92%8C%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6/">《深入理解Java文件输入输出流和文件描述符》</a>我们已经深入探讨过该类。</p><p>简单来说，FileInputStream 内部通过文件描述符 FileDescriptor 和系统文件关联起来，并通过 native 方法调用系统 API 读写文件。</p><h4 id="FilterInputStream"><a href="#FilterInputStream" class="headerlink" title="FilterInputStream"></a>FilterInputStream</h4><p>FilterInputStream 采用装饰器模式，内部包装了一个 InputStream 对象，并且继承了 InputStream 并覆写全部方法，但方法内容都是单纯地调用内部包装的 InputStream 对象。如下：</p><pre><code class="java">publicclass FilterInputStream extends InputStream &#123;    protected volatile InputStream in;    protected FilterInputStream(InputStream in) &#123;        this.in = in;    &#125;    public int read() throws IOException &#123;        return in.read();    &#125;    public int read(byte b[]) throws IOException &#123;        return read(b, 0, b.length);    &#125;    public int read(byte b[], int off, int len) throws IOException &#123;        return in.read(b, off, len);    &#125;    public long skip(long n) throws IOException &#123;        return in.skip(n);    &#125;    public int available() throws IOException &#123;        return in.available();    &#125;    public void close() throws IOException &#123;        in.close();    &#125;    public synchronized void mark(int readlimit) &#123;        in.mark(readlimit);    &#125;    public synchronized void reset() throws IOException &#123;        in.reset();    &#125;    public boolean markSupported() &#123;        return in.markSupported();    &#125;&#125;</code></pre><p>所以正如其名，FilterInputStream 就像是内部 InputStream 对象的一个过滤器一般，所有方法调用都需要经过一层包装方法的『过滤』才能到达内部对象。FilterInputStream 并没有逻辑实现，具体实现需要子类覆写相关方法实现。</p><p>比较有意思的实现有以下几个：</p><ul><li><strong>BufferedInputStream</strong><blockquote><p>BufferedInputStream 内部使用一个 buf 字节数组进行缓冲，覆写了 FilterInputStream 的全部方法实现一个带缓冲区的字节流类。在进行磁盘或网络IO时，原始的InputStream对数据读取的过程都是一个字节一个字节操作的，而BufferedInputStream在其内部提供了一个buffer，在读数据时，会一次读取一大块数据到buffer中，这样比单字节的操作效率要高的多，特别是进程磁盘IO和对大量数据进行读写的时候,能提升IO性能。</p></blockquote></li><li><strong>PushbackInputStream</strong><blockquote><p>PushbackInputStream 内部同样使用一个 buf 字节数组对已读数据进行缓存，然后可以通过 unread 方法将已读的数据重新放回 buf 数组，从而实现了一个支持 push back 的字节流类。</p></blockquote></li><li><strong>DataInputStream</strong><blockquote><p>DataInputStream 提供了许多可以读取 Java 基本类型的方法。</p></blockquote></li></ul><h4 id="ByteArrayInputStream"><a href="#ByteArrayInputStream" class="headerlink" title="ByteArrayInputStream"></a>ByteArrayInputStream</h4><p>ByteArrayInputStream 支持从 byte 数组读取数据，通过构造函数可以指定该 byte 数组：</p><pre><code class="java">    protected byte buf[];    protected int pos;    protected int mark = 0;    protected int count;    public ByteArrayInputStream(byte buf[]) &#123;        this.buf = buf;        this.pos = 0;        this.count = buf.length;    &#125;    public ByteArrayInputStream(byte buf[], int offset, int length) &#123;        this.buf = buf;        this.pos = offset;        this.count = Math.min(offset + length, buf.length);        this.mark = offset;    &#125;</code></pre><h4 id="ObjectInputStream"><a href="#ObjectInputStream" class="headerlink" title="ObjectInputStream"></a>ObjectInputStream</h4><p>ObjectInputStream 与 DataInputStream 类似也支持 Java 基本类型的读取，此外还支持反序列化读取对象。它常常与 ObjectOutputStream 搭配使用。因此，ObjectOutputStream 实现将基本类型或者对象序列化并输出到 IO 字节流或者设备上，而 ObjectInputStream 从 IO 字节流或者设备上反序列化读取基本类型或者对象。</p><p>比如，从文件中读取一个 person 对象。</p><pre><code class="java">ObjectInputStream input = new ObjectInputStream(new FileInputStream(&quot;data.txt&quot;));Person person = (MyClass) input.readObject(); input.close();</code></pre><p>这里要求 Person 一定要实现 java.io.Serializable 接口。</p><h4 id="PipedInputStream"><a href="#PipedInputStream" class="headerlink" title="PipedInputStream"></a>PipedInputStream</h4><p>PipedInputStream 通常和 PipedOutputStream 搭配使用，实现了一个承载字节流的管道类。PipedOutputStream 的输出会自动调用 PipedInputStream 的 receive 方法作为输入。PipedInputStream 提供了以下几个特殊方法：</p><pre><code class="java">// 连接 PipedOutputStream 对象，形成管道public void connect(PipedOutputStream src) throws IOException;// 接收一个字节protected synchronized void receive(int b) throws IOException;// 接收一个字节数组synchronized void receive(byte b[], int off, int len)  throws IOException;</code></pre><p>注意到其 read 方法和 receive 都是同步方法，read 方法在没有数据的时候会发生阻塞，而 receive 方法在缓冲数组没有剩余空间的时候也会发生阻塞：</p><pre><code class="java">public synchronized int read()  throws IOException &#123;        if (!connected) &#123;            throw new IOException(&quot;Pipe not connected&quot;);        &#125; else if (closedByReader) &#123;            throw new IOException(&quot;Pipe closed&quot;);        &#125; else if (writeSide != null &amp;&amp; !writeSide.isAlive()                   &amp;&amp; !closedByWriter &amp;&amp; (in &lt; 0)) &#123;            throw new IOException(&quot;Write end dead&quot;);        &#125;        readSide = Thread.currentThread();        int trials = 2;        while (in &lt; 0) &#123;            // in小于0表示缓冲数组为空，处于无数据状态            if (closedByWriter) &#123;                /* closed by writer, return EOF */                return -1;            &#125;            if ((writeSide != null) &amp;&amp; (!writeSide.isAlive()) &amp;&amp; (--trials &lt; 0)) &#123;                throw new IOException(&quot;Pipe broken&quot;);            &#125;            /* might be a writer waiting */            notifyAll();            try &#123;                // 阻塞等待                wait(1000);            &#125; catch (InterruptedException ex) &#123;                throw new java.io.InterruptedIOException();            &#125;        &#125;        int ret = buffer[out++] &amp; 0xFF;        if (out &gt;= buffer.length) &#123;            out = 0;        &#125;        if (in == out) &#123;            /* now empty */            in = -1;        &#125;        return ret;    &#125;protected synchronized void receive(int b) throws IOException &#123;        checkStateForReceive();        writeSide = Thread.currentThread();        if (in == out)            // 当in等于out，意味着缓冲数组已满，阻塞等待空间释放            awaitSpace();        if (in &lt; 0) &#123;            in = 0;            out = 0;        &#125;        buffer[in++] = (byte)(b &amp; 0xFF);        if (in &gt;= buffer.length) &#123;            in = 0;        &#125;    &#125;</code></pre><h4 id="SequenceInputStream"><a href="#SequenceInputStream" class="headerlink" title="SequenceInputStream"></a>SequenceInputStream</h4><p>SequenceInputStream 支持将多个 InputStream 组合起来，并按照顺序进行读取。</p><h3 id="OutputStream"><a href="#OutputStream" class="headerlink" title="OutputStream"></a>OutputStream</h3><p>OutputStream 与 InputStream 相对应，实现上存在很多相似之处。先看看内部方法：</p><pre><code class="java">public abstract class OutputStream implements Closeable, Flushable &#123;    public abstract void write(int b) throws IOException;    public void write(byte b[]) throws IOException &#123;/***/&#125;    public void write(byte b[], int off, int len) throws IOException &#123;/***/&#125;    public void flush() throws IOException &#123;/***/&#125;    public void close() throws IOException &#123;/***/&#125;&#125;</code></pre><p>OutputStream 实现了 Closeable 接口和 Flushable 方法，同样有一个抽象的 write 方法需要实现。其他方法提供框架性代码，也需要实现类覆写相关方法，提供更多的自定义功能。</p><h4 id="FileOutputStream"><a href="#FileOutputStream" class="headerlink" title="FileOutputStream"></a>FileOutputStream</h4><p>实现上与 FileInputStream 类似，提供对文件写入字节流的功能。</p><h4 id="FilterOutputStream"><a href="#FilterOutputStream" class="headerlink" title="FilterOutputStream"></a>FilterOutputStream</h4><p>与 FilterInputStream 类似，对 OutputStream 对象进行包装，并继承了 OutputStream 并覆写全部方法，方法内容都是简单地调用内部的 OutputStream 对象。</p><p>同样的也有几个子类实现：</p><ul><li><strong>BufferedOutputStream</strong>：带缓冲区的字节流输出类，与 BufferedInputStream 对应；</li><li><strong>DataOutputStream</strong>：提供写 Java 基本类型相关方法的字节流类，与 DataInputStream 对应；</li><li><strong>PrintStream</strong>：与 DataOutputStream 有些类似，不过它提供了更加丰富的写出方法，并且支持换行输出。</li></ul><h4 id="ByteArrayOutputStream"><a href="#ByteArrayOutputStream" class="headerlink" title="ByteArrayOutputStream"></a>ByteArrayOutputStream</h4><p>与 ByteArrayInputStream 相反，ByteArrayOutputStream 实现输出到内部的缓存字节数组 buf 中。特有的方法有：</p><pre><code class="java">/** 将该 Stream 输出为 byte 数组**/public synchronized byte toByteArray()[] &#123;    return Arrays.copyOf(buf, count);&#125;/** 将该 Stream 输出到另一个 Stream 上**/public synchronized void writeTo(OutputStream out) throws IOException &#123;    out.write(buf, 0, count);&#125;</code></pre><h4 id="ObjectOutputStream"><a href="#ObjectOutputStream" class="headerlink" title="ObjectOutputStream"></a>ObjectOutputStream</h4><p>与 ObjectInputStream 对应，ObjectOutputStream 实现将 Java 基本类型数据或者 Java 对象序列化后写入输出字节流中。</p><h4 id="PipedOutputStream"><a href="#PipedOutputStream" class="headerlink" title="PipedOutputStream"></a>PipedOutputStream</h4><p>与 PipedInputStream 搭配使用，PipedOutputStream 会输出字节流到管道另一端的 PipedInputStream。</p><h2 id="字符流"><a href="#字符流" class="headerlink" title="字符流"></a>字符流</h2><p>字节流处理的是 byte 数组，而字符流处理的是 char 数组。而且字符流相关的类都以 Reader 或者 Writer 为后缀。</p><h3 id="Reader"><a href="#Reader" class="headerlink" title="Reader"></a>Reader</h3><p>先看看内部方法：</p><pre><code class="java">public abstract class Reader implements Readable, Closeable &#123;    public int read(java.nio.CharBuffer target) throws IOException;    public int read() throws IOException;    public int read(char cbuf[]) throws IOException;    abstract public int read(char cbuf[], int off, int len) throws IOException;    public long skip(long n) throws IOException;    public boolean ready() throws IOException;    public boolean markSupported();    public void mark(int readAheadLimit) throws IOException;    public void reset() throws IOException;    abstract public void close() throws IOException;&#125;</code></pre><p>内部方法与 InputStream 非常相似，同样实现类需要实现 read 方法。</p><h4 id="BufferedReader"><a href="#BufferedReader" class="headerlink" title="BufferedReader"></a>BufferedReader</h4><p>带缓冲区的 Reader 实现。</p><h4 id="CharArrayReader"><a href="#CharArrayReader" class="headerlink" title="CharArrayReader"></a>CharArrayReader</h4><p>从字符数组读取数据的 Reader 实现。</p><h4 id="InputStreamReader"><a href="#InputStreamReader" class="headerlink" title="InputStreamReader"></a>InputStreamReader</h4><p>InputStreamReader 是一个包装类，内部对象是 StreamDecoder。StreamDecoder 支持从 InputStream 中读取字符。</p><pre><code class="java">public class InputStreamReader extends Reader &#123;    private final StreamDecoder sd;    /**     * Creates an InputStreamReader that uses the default charset.     *     * @param  in   An InputStream     */    public InputStreamReader(InputStream in) &#123;        super(in);        try &#123;            sd = StreamDecoder.forInputStreamReader(in, this, (String)null); // ## check lock object        &#125; catch (UnsupportedEncodingException e) &#123;            // The default encoding should always be available            throw new Error(e);        &#125;    &#125;    // ...&#125;</code></pre><ul><li><p><strong>FileReader</strong>：InputStreamReader 的实现，入参是一个 FileInputStream 对象</p><pre><code class="java">  public FileReader(String fileName) throws FileNotFoundException &#123;      super(new FileInputStream(fileName));  &#125;</code></pre></li></ul><h4 id="FilterReader"><a href="#FilterReader" class="headerlink" title="FilterReader"></a>FilterReader</h4><p>FilterReader 与上文的 FilterInputStream 类似，也是一个包装类。它内部包含一个 Reader 对象，并且继承自 Reader 并覆写所有方法，而方法内容都是简单调用内部 Reader 对象。</p><ul><li><strong>PushbackReader</strong>：FilterReader 的实现类，内部使用一个 buf 字符数组对已读数据进行缓存，然后可以通过 unread 方法将已读的数据重新放回 buf 数组，从而实现了一个支持 push back 的字符流类。</li></ul><h4 id="PipedReader"><a href="#PipedReader" class="headerlink" title="PipedReader"></a>PipedReader</h4><p>与 PipedInputStream 类似</p><h4 id="StringReader"><a href="#StringReader" class="headerlink" title="StringReader"></a>StringReader</h4><p>与 CharArrayReader 类似</p><h3 id="Writer"><a href="#Writer" class="headerlink" title="Writer"></a>Writer</h3><h4 id="BufferedWriter"><a href="#BufferedWriter" class="headerlink" title="BufferedWriter"></a>BufferedWriter</h4><p>带缓冲区的 Writer 实现。</p><h4 id="CharArrayWriter"><a href="#CharArrayWriter" class="headerlink" title="CharArrayWriter"></a>CharArrayWriter</h4><p>与 CharArrayReader 相反，CharArrayWriter 将数据写入内部字符数组中。其特有方法有：</p><pre><code class="java">public char toCharArray()[] &#123;    synchronized (lock) &#123;        return Arrays.copyOf(buf, count);    &#125;&#125;public void writeTo(Writer out) throws IOException &#123;    synchronized (lock) &#123;        out.write(buf, 0, count);    &#125;&#125;</code></pre><h4 id="OutputStreamWriter"><a href="#OutputStreamWriter" class="headerlink" title="OutputStreamWriter"></a>OutputStreamWriter</h4><p>与 InputStreamReader 相对，OutputStreamWriter 也是一个包装类，内部对象是 StreamEncoder。StreamEncoder 支持将字符输出到 OutputStream 中。</p><ul><li><p><strong>FileWriter</strong>OutputStreamWriter 的实现，入参是一个 FileOutputStream 对象</p><pre><code class="java">  public FileWriter(String fileName) throws IOException &#123;      super(new FileOutputStream(fileName));  &#125;</code></pre></li></ul><h4 id="FilterWriter"><a href="#FilterWriter" class="headerlink" title="FilterWriter"></a>FilterWriter</h4><p>FilterWriter 的是一个包装类，内部包含一个 Writer 对象，同时也继承了 Writer，并覆写了部分方法。这个类在 JDK 里没有找到相关实现子类。</p><h4 id="PipedWriter"><a href="#PipedWriter" class="headerlink" title="PipedWriter"></a>PipedWriter</h4><p>与 PipedReader PipedWriter 会输出字符流到管道另一端的 PipedWriter。</p><h4 id="PrintWriter"><a href="#PrintWriter" class="headerlink" title="PrintWriter"></a>PrintWriter</h4><p>类似 PrintStream，提供了丰富的写出方法，并且支持换行输出。这里发现其并没有实现 FilterWriter，这点与 PrintStream 的继承结构并不吻合。个人觉得这点不是很好，但是也无伤大雅。</p><h4 id="StringWriter"><a href="#StringWriter" class="headerlink" title="StringWriter"></a>StringWriter</h4><p>将字符流输出到内部的 StringBuffer 上，同时可以通过 toString 方法获取内部的字符串缓存：</p><pre><code class="java">public String toString() &#123;    return buf.toString();&#125;</code></pre><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="RandomAccessFile"><a href="#RandomAccessFile" class="headerlink" title="RandomAccessFile"></a>RandomAccessFile</h3><p>FileInputStream（文件字符流）或 FileReader（文件字节流）来读文件都只能够实现从文件开始顺序读取到文件结束。</p><p>而 RandomAccessFile 可以实现随机读写，用来只读取文件中的一部分：</p><pre><code class="java">public class RandAccessDemo &#123;    public static String randomAccessFileRead() throws IOException &#123;        // 创建一个RandomAccessFile对象        RandomAccessFile file = new RandomAccessFile( &quot;data.txt&quot;, &quot;rw&quot;);        // 通过seek方法来移动读写位置的指针        file.seek(10);        // 获取当前指针        long pointerBegin = file.getFilePointer();        // 从当前指针开始读        byte[] contents = new byte[1024];        file.read( contents);        long pointerEnd = file.getFilePointer();        System. out.println( &quot;pointerBegin:&quot; + pointerBegin + &quot;\n&quot; + &quot;pointerEnd:&quot; + pointerEnd + &quot;\n&quot; + new String(contents));        String dataStr = new String(contents);        file.close();        return dataStr;    &#125;    public static void randomAccessFileWrite(String dataStr) throws IOException &#123;        // 创建一个RandomAccessFile对象        RandomAccessFile file = new RandomAccessFile(&quot;data.txt&quot;, &quot;rw&quot;);        // 通过seek方法来移动读写位置的指针        file.seek(10);        // 获取当前指针        long pointerBegin = file.getFilePointer();        // 从当前指针位置开始写        file.write(dataStr.getBytes());        long pointerEnd = file.getFilePointer();        System.out.println(&quot;pointerBegin:&quot; + pointerBegin + &quot;\n&quot; + &quot;pointerEnd:&quot; + pointerEnd + &quot;\n&quot;);        file.close();    &#125;&#125;</code></pre><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.cnblogs.com/java-chen-hao/p/11083740.html#_label2_5">高级Java工程师必备 —– 深入分析 Java IO （三）</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> IO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解Java文件输入输出流和文件描述符</title>
      <link href="/2020/12/16/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E6%96%87%E4%BB%B6%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%B5%81%E5%92%8C%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6/"/>
      <url>/2020/12/16/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E6%96%87%E4%BB%B6%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%B5%81%E5%92%8C%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6/</url>
      
        <content type="html"><![CDATA[<p>本文将深入理解文件描述符，并从 JDK 源码上分析文件描述符在文件输入输出流中的运用。</p><span id="more"></span><blockquote><p>特别声明，为避免重复造轮子，部分内容和图片摘自文末参考资料。本文仅限用于交流学习，严禁用于商业用途。</p></blockquote><h2 id="文件描述符是什么？"><a href="#文件描述符是什么？" class="headerlink" title="文件描述符是什么？"></a>文件描述符是什么？</h2><p>[1] 在Linux系统中一切皆可以看成是文件，文件又可分为：普通文件、目录文件、链接文件和设备文件。文件描述符（file descriptor）是内核为了高效管理已被打开的文件所创建的索引，其是一个非负整数（通常是小整数），用于指代被打开的文件，所有执行I&#x2F;O操作的系统调用都通过文件描述符。程序刚刚启动的时候，0是标准输入，1是标准输出，2是标准错误。如果此时去打开一个新的文件，它的文件描述符会是3。POSIX标准要求每次打开文件时（含socket）必须使用当前进程中最小可用的文件描述符号码，因此，在网络通信过程中稍不注意就有可能造成串话。标准文件描述符图如下：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E6%96%87%E4%BB%B6%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%B5%81%E5%92%8C%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6%2Fstd-in-out-err.png" alt="std-in-out-err.png"></p><h2 id="Linux-进程中的文件描述符"><a href="#Linux-进程中的文件描述符" class="headerlink" title="Linux 进程中的文件描述符"></a>Linux 进程中的文件描述符</h2><p>[2] 从 Linux 进程的数据结构也可以看出端倪：</p><pre><code class="c++">struct task_struct &#123;    // 进程状态    long              state;    // 虚拟内存结构体    struct mm_struct  *mm;    // 进程号    pid_t             pid;    // 指向父进程的指针    struct task_struct __rcu  *parent;    // 子进程列表    struct list_head        children;    // 存放文件系统信息的指针    struct fs_struct        *fs;    // 一个数组，包含该进程打开的文件指针    struct files_struct     *files;&#125;;</code></pre><p>files 指针指向一个数组，这个数组里装着所有该进程打开的文件的指针。每个进程被创建时，files的前三位被填入默认值，分别指向标准输入流、标准输出流、标准错误流。我们常说的「文件描述符」就是指这个文件指针数组的索引，所以程序的文件描述符默认情况下 0 是输入，1 是输出，2 是错误。如下图所示：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E6%96%87%E4%BB%B6%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%B5%81%E5%92%8C%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6%2F%E8%BF%9B%E7%A8%8B%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6.jpg" alt="进程文件描述符.jpg"></p><p>所以，在 linux 中的重定向、管道等操作，其实只是修改了进程的 files 数组前三位的指向。</p><h2 id="FileDescriptor"><a href="#FileDescriptor" class="headerlink" title="FileDescriptor"></a>FileDescriptor</h2><p>FileDescriptor 是文件描述符在 JVM 中的抽象。来看看内部结构：</p><pre><code class="java">public final class FileDescriptor &#123;    // 文件描述符（就是上文所说的 files 数组下标）    private int fd;    // 该文件描述符所关联的实例（通常是输入输出流实例，比如 FileInputStream ）    private Closeable parent;    private List&lt;Closeable&gt; otherParents;    private boolean closed;    // 标准输入    public static final FileDescriptor in = new FileDescriptor(0);    // 标准输出    public static final FileDescriptor out = new FileDescriptor(1);    // 标准错误    public static final FileDescriptor err = new FileDescriptor(2);    public boolean valid() &#123;        return fd != -1;    &#125;    /* This routine initializes JNI field offsets for the class */    private static native void initIDs();    static &#123;        initIDs();    &#125;&#125;</code></pre><p>FileDescriptor 非常清晰，我们可以直接总结以下几点：</p><ul><li>FileDescriptor 与文件描述符一一对应，使用 fd 字段保存文件描述符；</li><li>单个 FileDescriptor 可以和多个 Closeable 关联（通常是输入输出流实例，比如 FileInputStream ）；</li><li>FileDescriptor 内部有三个公开静态常量 in、out 和 err 分别代表标准输入、标准输出和标准错误，这仨通常用在 java.lang.System 中；</li><li>文件描述符 fd 通常为非负数；</li></ul><h3 id="initIDs"><a href="#initIDs" class="headerlink" title="initIDs"></a>initIDs</h3><p>initIDs 方法用于初始化 fd 字段的 ID （我觉得可以理解为 fd 字段的指针）。这是一个 native 方法，可以在 JDK 源码里找到相应的 JNI 实现。以 Window 下的实现为例（因为 Window 的相对容易找到 &#x3D; &#x3D;)：</p><pre><code class="C++">/* field id for jint &#39;fd&#39; in java.io.FileDescriptor */jfieldID IO_fd_fdID;/* field id for jlong &#39;handle&#39; in java.io.FileDescriptor */jfieldID IO_handle_fdID;/************************************************************** * static methods to store field IDs in initializers */JNIEXPORT void JNICALLJava_java_io_FileDescriptor_initIDs(JNIEnv *env, jclass fdClass) &#123;    CHECK_NULL(IO_fd_fdID = (*env)-&gt;GetFieldID(env, fdClass, &quot;fd&quot;, &quot;I&quot;));    CHECK_NULL(IO_handle_fdID = (*env)-&gt;GetFieldID(env, fdClass, &quot;handle&quot;, &quot;J&quot;));&#125;</code></pre><p>可见 fd 的字段ID被保存到了全局字段中，后续其他代码可以根据其字段ID来修改 fd 的值。字段ID在这里我理解为一个指针。这里还处理了 handle 字段，可能是版本问题，我没有在 JDK 里看到这个字段。</p><h2 id="文件输入输出流"><a href="#文件输入输出流" class="headerlink" title="文件输入输出流"></a>文件输入输出流</h2><p>Java IO 里的文件输入输出流类有二：FileInputStream 和 FileOutputStream。两者的类图继承结构非常清晰：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E6%96%87%E4%BB%B6%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%B5%81%E5%92%8C%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6%2F%E6%96%87%E4%BB%B6%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%B5%81%E7%B1%BB%E5%9B%BE.png" alt="文件输入输出流类图.png"></p><p>因为两者实现原理差不多，下边以 FileInputStream 展开探讨。</p><h3 id="FileInputStream"><a href="#FileInputStream" class="headerlink" title="FileInputStream"></a>FileInputStream</h3><p>先来看看 FileInputStream 的源码。</p><p>内部字段很少很简洁，详见注释：</p><pre><code class="java">publicclass FileInputStream extends InputStream    /* 文件描述符对象**/    private final FileDescriptor fd;    /** 文件路径 **/    private final String path;    /** 可以操作读写文件的通道 **/    private FileChannel channel = null;    /** 关闭时用于并发控制的锁对象 **/    private final Object closeLock = new Object();    private volatile boolean closed = false;&#125;</code></pre><p>还有一个与 FileDescriptor 类似的 initIDs 方法，也是用来设置内部的 fd 字段ID：</p><pre><code class="java">private static native void initIDs();private native void close0() throws IOException;static &#123;    initIDs();&#125;</code></pre><p>构造方法也挺简单的，关键是看看其中这个构造函数：</p><pre><code class="java">public FileInputStream(File file) throws FileNotFoundException &#123;    String name = (file != null ? file.getPath() : null);    SecurityManager security = System.getSecurityManager();    if (security != null) &#123;        security.checkRead(name);    &#125;    if (name == null) &#123;        throw new NullPointerException();    &#125;    if (file.isInvalid()) &#123;        throw new FileNotFoundException(&quot;Invalid file path&quot;);    &#125;    // 新建一个文件描述符对象    fd = new FileDescriptor();    // 将当前 FileInputStream 和该文件描述符关联起来    fd.attach(this);    path = name;    // 打开该文件    open(name);&#125;</code></pre><p>构造函数中新建了一个文件描述符对象 fd，要记得这个对象的内部还有一个 long 类型的 fd 字段，默认初始化为 0L。而 fd 字段的初始化逻辑是在 open 方法。最终调用的是 native 方法：</p><pre><code class="java">/**    * Opens the specified file for reading.    * @param name the name of the file    */private native void open0(String name) throws FileNotFoundException;</code></pre><blockquote><p>题外话，这里提一下怎么通过 这个 native 方法找到对应的 C++ 实现：</p><ul><li>下载相应版本的 JDK 源码；</li><li>找到 jdk&#x2F;src&#x2F;share&#x2F;classes&#x2F;java&#x2F;io&#x2F;FileInputStream.java；</li><li>执行 javah java.io.FileInputStream 便可以生成 Header文件 java_io_FileInputStream.h ：</li></ul><pre><code class="C++">/* * Class:     java_io_FileInputStream * Method:    open0 * Signature: (Ljava/lang/String;)V */JNIEXPORT void JNICALL Java_java_io_FileInputStream_open0 (JNIEnv *, jobject, jstring);</code></pre><ul><li>使用 C++ 方法名 Java_java_io_FileInputStream_open0 进行搜索便很快能找到对应的 C++ 方法实现；</li></ul></blockquote><p>我们查看 JDK 源码（jdk&#x2F;src&#x2F;share&#x2F;native&#x2F;java&#x2F;io&#x2F;FileInputStream.c），有以下代码：</p><pre><code class="C++">jfieldID fis_fd; /* id for jobject &#39;fd&#39; in java.io.FileInputStream *//************************************************************** * static methods to store field ID&#39;s in initializers */JNIEXPORT void JNICALLJava_java_io_FileInputStream_initIDs(JNIEnv *env, jclass fdClass) &#123;    fis_fd = (*env)-&gt;GetFieldID(env, fdClass, &quot;fd&quot;, &quot;Ljava/io/FileDescriptor;&quot;);&#125;/************************************************************** * Input stream */JNIEXPORT void JNICALLJava_java_io_FileInputStream_open0(JNIEnv *env, jobject this, jstring path) &#123;    fileOpen(env, this, path, fis_fd, O_RDONLY);&#125;</code></pre><p>这里可以看到 initIDs 方法实现，其逻辑是将名为“fd”的 FileDescriptor 类型对象的字段ID保存到全局变量 fid中；</p><p>而 open0 方法调用了 fileOpen。在不同的操作系统上有不同的实现，以 Window 为例：</p><pre><code class="C++">voidfileOpen(JNIEnv *env, jobject this, jstring path, jfieldID fid, int flags)&#123;    FD h = winFileHandleOpen(env, path, flags);    if (h &gt;= 0) &#123;        SET_FD(this, h, fid);    &#125;&#125;</code></pre><p>这里对展开 winFileHandleOpen 方法不感兴趣，大体意思就是调用 Window 的系统方法打开了文件，并返回了文件描述符 h。</p><p>然后调用 SET_FD 方法将文件描述符 h 设置到 fid 中。fid 就是 initIDs 所缓存的字段ID（理解为 fd 字段的指针）。</p><p>至此，FileInputStream 和文件描述符关联了起来。后续在 FileInputStream 上的读写，JVM 都可以通过其内部的 fd 字段非常方便地找到需要读写的文件！所以，FileInputStream 还支持指定文件描述符的构造形式：</p><pre><code class="java">FileOutputStream fdOut = new FileOutputStream(FileDescriptor.out);</code></pre><p>这其实就是 System.out 的实现。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我们学习了 Linux 系统的文件操作符概念，理解了”一切皆是文件“的设计理念。此外，还深入学习了文件输入输出流类的源码实现，探讨它们是怎么利用文件描述符和操作系统进行交互。希望大家有所收获！</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><p>特别声明，本文部分段落摘自以下资料。</p></blockquote><ul><li>[1] <a href="https://blog.csdn.net/cywosp/article/details/38965239">《每天进步一点点——Linux中的文件描述符与打开文件之间的关系》</a> </li><li>[2] <a href="https://zhuanlan.zhihu.com/p/105086274">《Linux 进程、线程、文件描述符的底层原理》</a></li></ul><blockquote><p>其他参考资料</p></blockquote><ul><li><a href="https://blog.csdn.net/lili13897741554/article/details/82115105">Java IO流之文件描述符FileDescriptor</a></li><li><a href="https://segmentfault.com/a/1190000009724931">文件描述符（File Descriptor）简介</a>：这文章讲到文件描述符限制的相关命令，非常实用！</li><li><a href="https://gorden5566.com/post/1027.html">如何查找 jdk 中的 native 实现</a>：查看 JDK 源码必备技能</li><li><a href="https://www.cnblogs.com/java-chen-hao/p/11083740.html">高级Java工程师必备 —– 深入分析 Java IO （三）</a>：介绍Java IO 类库的好文</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 文件描述符 </tag>
            
            <tag> 输入输出流 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生产问题(2) ExceptionInInitializerError导致线程池中的线程异常被吞</title>
      <link href="/2020/12/15/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98-2-ExceptionInInitializerError%E5%AF%BC%E8%87%B4%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%BC%82%E5%B8%B8%E8%A2%AB%E5%90%9E/"/>
      <url>/2020/12/15/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98-2-ExceptionInInitializerError%E5%AF%BC%E8%87%B4%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%BC%82%E5%B8%B8%E8%A2%AB%E5%90%9E/</url>
      
        <content type="html"><![CDATA[<p>最近在生产环境遇到一个比较极端的线程池吞异常问题，研究了下背后的原理，发现是静态块初始化异常抛出 ExceptionInInitializerError 导致的。这情景平时少见，在这里记录下已备忘。</p><span id="more"></span><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>吞异常代码核心思想提炼后的样例是这样的：</p><pre><code class="java">@Slf4jpublic class ExceptionSingleton &#123;    private ExceptionSingleton() &#123;        // 单例实例化过程中抛出运行时异常        throw new RuntimeException(&quot;ExceptionSingleton constructor exception.&quot;);    &#125;    private static class SingletonHolder &#123;        // 懒汉式单例        private volatile static ExceptionSingleton INSTANCE = new ExceptionSingleton();    &#125;    public static ExceptionSingleton getInstance() &#123;        return SingletonHolder.INSTANCE;    &#125;    static class Processor implements Runnable &#123;        @Override        public void run() &#123;            try &#123;                ExceptionSingleton.getInstance();            &#125; catch (Exception e) &#123;                // 此处尝试捕获单例构造过程中抛出的RuntimeException，但其实无效                log.error(&quot;can not catch this exception here&quot;, e);            &#125;        &#125;    &#125;    public static void main(String[] args) throws InterruptedException, TimeoutException, ExecutionException &#123;        ExecutorService executorService = Executors.newSingleThreadExecutor();        executorService.submit(new Processor(););        Thread.currentThread().join();    &#125;&#125;</code></pre><p>这段代码的期望思路是在线程池线程中捕获单例实例化所抛出的 RuntimeException，并打印日志。实际执行结果并没有打印任何日志，提交到线程池的 Processor 仿佛是凭空消失了一般。</p><p>要深究背后的原因，我们先来探讨几个知识点：</p><h2 id="ExceptionInInitializerError"><a href="#ExceptionInInitializerError" class="headerlink" title="ExceptionInInitializerError"></a>ExceptionInInitializerError</h2><ul><li><p>从类注释可以看出来，ExceptionInInitializerError 在静态类变量或者静态块初始化的时候会被抛出：</p><pre><code class="java">/*** Signals that an unexpected exception has occurred in a static initializer.* An &lt;code&gt;ExceptionInInitializerError&lt;/code&gt; is thrown to indicate that an* exception occurred during evaluation of a static initializer or the* initializer for a static variable.** &lt;p&gt;As of release 1.4, this exception has been retrofitted to conform to* the general purpose exception-chaining mechanism.  The &quot;saved throwable* object&quot; that may be provided at construction time and accessed via* the &#123;@link #getException()&#125; method is now known as the &lt;i&gt;cause&lt;/i&gt;,* and may be accessed via the &#123;@link Throwable#getCause()&#125; method, as well* as the aforementioned &quot;legacy method.&quot;** @author  Frank Yellin* @since   JDK1.1*/public class ExceptionInInitializerError extends LinkageError &#123;    /**    * This field holds the exception if the    * ExceptionInInitializerError(Throwable thrown) constructor was    * used to instantiate the object    *    * @serial    *    */    private Throwable exception;    // ...&#125;</code></pre></li><li><p>还需要注意在静态类变量或者静态块初始化中所抛出的所有异常，都需要使用 ExceptionInInitializerError 进行包装。特别注意的是：<strong>如果是抛出的是 RuntimeException，则JDK会自动使用 ExceptionInInitializerError 进行包装。</strong></p></li></ul><p>所以，最开始样例的单例抛出的 RuntimeException，其实被JDK包装成了 ExceptionInInitializerError。那么 Processor 内部的 try catch 块捕获的是 Exception 而不是 Throwable，那当然就不会打印异常日志 。不要忘记 Exception、Error 和 Throwable 三者的关系：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E6%8A%93%E8%99%AB%E7%AC%94%E8%AE%B0%3AExceptionInInitializerError%E5%AF%BC%E8%87%B4%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%AD%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%BC%82%E5%B8%B8%E8%A2%AB%E5%90%9E%2Fthrowable-exception-error.png" alt="throwable-exception-error.png"></p><h2 id="FutureTask"><a href="#FutureTask" class="headerlink" title="FutureTask"></a>FutureTask</h2><p>虽然 Processor 没有捕获 ExceptionInInitializerError，但为啥线程池内部也没打印相关错误日志呢？</p><p>这得深入看看线程池的代码。我们看到样例使用的提交方法是 submit：</p><pre><code class="java">public Future&lt;?&gt; submit(Runnable task) &#123;    if (task == null) throw new NullPointerException();    RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null);    execute(ftask);    return ftask;&#125;</code></pre><p>submit 方法很简洁，一开始通过 newTaskFor 方法新建了一个 FutureTask,FutureTask 的第一个入参是用户提交的业务逻辑 runnable：</p><pre><code class="java">protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123;    return new FutureTask&lt;T&gt;(runnable, value);&#125;</code></pre><p>runnable 会被缓存到内部字段 callable ：</p><pre><code class="java">public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; &#123;    /** The underlying callable; nulled out after running */    private Callable&lt;V&gt; callable;    public FutureTask(Callable&lt;V&gt; callable) &#123;        if (callable == null)            throw new NullPointerException();        this.callable = callable;        this.state = NEW;       // ensure visibility of callable    &#125;    // ...&#125;</code></pre><p>然后这个 ftask 会被提交到线程池队列中。紧接着，在线程池中会被取出ftask，并执行：</p><pre><code class="java">final void runWorker(Worker w) &#123;    Thread wt = Thread.currentThread();    Runnable task = w.firstTask;    w.firstTask = null;    w.unlock(); // allow interrupts    boolean completedAbruptly = true;    try &#123;        while (task != null || (task = getTask()) != null) &#123;            w.lock();            // If pool is stopping, ensure thread is interrupted;            // if not, ensure thread is not interrupted.  This            // requires a recheck in second case to deal with            // shutdownNow race while clearing interrupt            if ((runStateAtLeast(ctl.get(), STOP) ||                    (Thread.interrupted() &amp;&amp;                    runStateAtLeast(ctl.get(), STOP))) &amp;&amp;                !wt.isInterrupted())                wt.interrupt();            try &#123;                beforeExecute(wt, task);                Throwable thrown = null;                try &#123;                    // 执行task                    task.run();                &#125; catch (RuntimeException x) &#123;                    thrown = x; throw x;                &#125; catch (Error x) &#123;                    thrown = x; throw x;                &#125; catch (Throwable x) &#123;                    thrown = x; throw new Error(x);                &#125; finally &#123;                    // 调用afterExecute来做一些最后处理（比如可以打印执行异常）                    afterExecute(task, thrown);                &#125;            &#125; finally &#123;                task = null;                w.completedTasks++;                w.unlock();            &#125;        &#125;        completedAbruptly = false;    &#125; finally &#123;        processWorkerExit(w, completedAbruptly);    &#125;&#125;</code></pre><p>task.run() 实际执行的是 FutureTask#run() 方法：</p><pre><code class="java"> public void run() &#123;    if (state != NEW ||        !UNSAFE.compareAndSwapObject(this, runnerOffset,                                        null, Thread.currentThread()))        return;    try &#123;        Callable&lt;V&gt; c = callable;        if (c != null &amp;&amp; state == NEW) &#123;            V result;            boolean ran;            try &#123;                result = c.call();                ran = true;            &#125; catch (Throwable ex) &#123;                // 这里捕获了所有的异常和错误                result = null;                ran = false;                setException(ex);            &#125;            if (ran)                set(result);        &#125;    &#125; finally &#123;        // runner must be non-null until state is settled to        // prevent concurrent calls to run()        runner = null;        // state must be re-read after nulling runner to prevent        // leaked interrupts        int s = state;        if (s &gt;= INTERRUPTING)            handlePossibleCancellationInterrupt(s);    &#125;&#125;</code></pre><p>callable 就是用户自定义的业务逻辑，如果在 callable 中抛出任何异常或者错误，都会在 try-catch 块中被捕获，并且通过 setException(ex) 方法，缓存到了字段 outcome 上：</p><pre><code class="java">/** The result to return or exception to throw from get() */private Object outcome; // non-volatile, protected by state reads/writesprotected void setException(Throwable t) &#123;    if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123;        outcome = t;        UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state        finishCompletion();    &#125;&#125;</code></pre><p>因此，通过 submit 提交到线程池的 task 所抛出的异常，其实是被缓存到了 FutureTask 当中。</p><h2 id="修复方法"><a href="#修复方法" class="headerlink" title="修复方法"></a>修复方法</h2><p>通过以上的探讨，这个吞异常的问题可以有多个解决方法。</p><h3 id="捕获Throwable而不是Exception"><a href="#捕获Throwable而不是Exception" class="headerlink" title="捕获Throwable而不是Exception"></a>捕获Throwable而不是Exception</h3><p>既然静态代码发生异常抛出的是 ExceptionInInitializerError ，它和 Exception 都是Throwable 的子类。因此，我们可以通过捕获 Throwable 来修复吞异常的问题:</p><pre><code class="java">static class Processor implements Runnable &#123;        @Override        public void run() &#123;            try &#123;                ExceptionSingleton.getInstance();            &#125; catch (Throwable e) &#123;                log.error(&quot;catch throwable here&quot;, e);            &#125;        &#125;&#125;</code></pre><h3 id="使用execute提交任务到线程池而不是submit"><a href="#使用execute提交任务到线程池而不是submit" class="headerlink" title="使用execute提交任务到线程池而不是submit"></a>使用execute提交任务到线程池而不是submit</h3><p>通过 submit 方法提交的 task 会被自动包装为 FutureTask 而导致异常被缓存而不是直接抛出。但 execute 方法提交就不会进行包装，所以，改为 execute 方法也能修复问题：</p><pre><code class="java">executorService.execute(new Processor());</code></pre><p>更进一步，我们从上边的 runWorker 方法可以注意到还可以重载 ThreadPoolExecutor 的 afterExecute 方法来打印异常信息，比如：</p><pre><code class="java">class MyThreadExecutor extends ThreadPoolExecutor &#123;    // ...    @Override    protected void afterExecute(Runnable r, Throwable t) &#123;        super.afterExecute(r, t);        // log throwable    &#125;&#125;</code></pre><h3 id="消费-Future"><a href="#消费-Future" class="headerlink" title="消费 Future"></a>消费 Future</h3><p>这个问题样例在使用 submit 其实不够严谨。因为 summit 返回了一个 Future 实例，熟悉异步编程的话，应该知道我们应该消费掉这个 Future。所以可以这样子修复：</p><pre><code class="java">Future task = executorService.submit(new Processor());task.get(500, TimeUnit.MILLISECONDS);</code></pre><p>调用 FutureTask 的 get 方法，方法内部会检查到错误异常，并向外抛出。</p><pre><code class="java">Exception in thread &quot;main&quot; java.util.concurrent.ExecutionException: java.lang.ExceptionInInitializerError    at java.util.concurrent.FutureTask.report(FutureTask.java:122)    at java.util.concurrent.FutureTask.get(FutureTask.java:206)    at org.demo.singleton.ExceptionSingleton.main(ExceptionSingleton.java:50)Caused by: java.lang.ExceptionInInitializerError    at org.demo.singleton.ExceptionSingleton.getInstance(ExceptionSingleton.java:24)    at org.demo.singleton.ExceptionSingleton$Processor.run(ExceptionSingleton.java:32)    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)    at java.util.concurrent.FutureTask.run(FutureTask.java:266)    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)    at java.lang.Thread.run(Thread.java:748)Caused by: java.lang.RuntimeException: ExceptionSingleton constructor exception.    at org.demo.singleton.ExceptionSingleton.&lt;init&gt;(ExceptionSingleton.java:16)    at org.demo.singleton.ExceptionSingleton.&lt;init&gt;(ExceptionSingleton.java:12)    at org.demo.singleton.ExceptionSingleton$SingletonHolder.&lt;clinit&gt;(ExceptionSingleton.java:20)    ... 7 more</code></pre><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://www.baeldung.com/java-exceptionininitializererror">When Does Java Throw the ExceptionInInitializerError?</a>：介绍什么时候抛出ExceptionInInitializerError错误的好文章</li></ul>]]></content>
      
      
      <categories>
          
          <category> 总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生产问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《代码整洁之道》</title>
      <link href="/2020/11/14/%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93/"/>
      <url>/2020/11/14/%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93/</url>
      
        <content type="html"><![CDATA[<p>如何写出整洁代码是一名优秀程序员的必修课。</p><p>整洁的代码有助于项目提高迭代质量，减轻历史包袱；同时也能让别人更易看懂代码，促进团队协作分工。</p><p>《代码整洁之道》一书里边有不少观点值得采纳。本文摘录书本主要内容，以备后忘。详细建议阅读原著。</p><span id="more"></span><h2 id="有意义的命名"><a href="#有意义的命名" class="headerlink" title="有意义的命名"></a>有意义的命名</h2><ul><li>命名应当名副其实，能准确体现对象的含义；</li><li>避免误导性命名。比如：不要使用”l”、”1” 以及其他专有名称；</li><li>命名应该做有意义的区分。比如：ProductInfo 、ProductData和Product没区别，moneyAmount和money没区别；</li><li>使用可以读出来的命名。比如：使用generationTimestamp，而不是genymdhms；</li><li>使用可以搜索的命名。比如：”e” 或者魔法数在代码中难以搜索；</li><li>避免使用编码（包括匈牙利标记法、成员前缀或接口实现标记等等）。比如：IShapeFactory无论是作为子类或者其实现，其首字母的标记”I”都是累赘的，应该使用ShapeFactory；</li><li>类名或者对象名应该是名词，如：Customer、WikiPage、Account、AddressParser。避免使用含义不确切的名词：Manager、Processor、Data、Info等，更不应使用动词；</li><li>方法名应该是动词或者动词短语；</li><li>添加有意义的语境。比如：firstName、secondName、street、houseNumber等零散字段，可以增加前缀”addr-“作为语境，明确暗示它们构成一个地址；更好的办法是封装为Address类；</li><li>不要添加无用的语境。比如开发一个名为GSD的系统，不应该给所有的类都加上GSD前缀；</li></ul><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><ul><li>函数第一规则：短小</li><li>函数的缩进层次要控制的两层之内；</li><li>函数应该做一件事，做好这件事，只做一件事；</li><li>使用抽象工厂类隐藏switch语句；</li><li>使用描述性命名，长而具有描述性的命名，要比短而令人费解的命名要好；</li><li>函数参数越少越好，当参数数量需要两个、三个或三个以上的时候，就说明其中一些参数可能应该封装为类；</li><li>标志参数丑陋不堪，不应该向函数传入布尔值，而是拆分为两个方法。比如：setStatus(Boolean start) 应该拆分为 start() 和 stop();</li><li>分隔询问和指令。比如if (set(“username”, “unclebob”)… 应该拆分为：<pre><code class="java">    if (attributeExists(&quot;username&quot;) &#123;        setAttribute(&quot;username&quot;, &quot;unclebob&quot;);`        ...    &#125;</code></pre></li><li>使用异常替代返回错误码；</li><li>try&#x2F;catch代码块会搞乱代码结构，应该将try和catch代码块的主体部分抽离出来形成独立函数。比如:<pre><code class="java">    try &#123;        deletePageAndAllReferences(page);    &#125; catch (Exception e) &#123;        logError(e);    &#125;</code></pre></li><li>避免重复的代码；</li></ul><h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><ul><li><p>恰当的注释是用来弥补我们用代码表达意图时所遭遇的失败。如果发现自己需要写注释，先复盘下是否可以通过代码表达而不是注释；</p></li><li><p>注释不能美化糟糕的代码。与其花时间编写解释糟糕代码的注释，还不如花时间清理下糟糕的代码；</p></li><li><p>通过良好的代码来阐述逻辑。比如：</p><ul><li>良好代码：</li></ul><pre><code class="java">    if (employee.isEligibleForFullBenefits())</code></pre><ul><li>而不要采用糟糕注释：</li></ul><pre><code class="java">    // check to see if the employee is eligible for full benefits    if ((employee.flags &amp; HOURLY_FLAG) &amp;&amp; employee.age &gt; 65))</code></pre></li><li><p>好注释</p><ul><li>法律信息</li><li>提供信息的注释</li><li>对意图的解释</li><li>阐释</li><li>警示</li><li>TODO注释</li><li>放大</li><li>公共API的Javadoc</li></ul></li><li><p>坏注释</p><ul><li>喃喃自语</li><li>多余的注释</li><li>误导性注释</li><li>循规式注释</li><li>日志式注释</li><li>废话式注释</li><li>注释掉的代码</li><li>HTML注释</li><li>非公共API的Javadoc</li></ul></li></ul><h2 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h2><ul><li>单个文件控制在恰当的长度（比如200~500行）；</li><li>源文件应该像报纸一样。名称应该简单且一目了然。名称本身应该足够告诉我们是否在正确的模块中。源文件最顶部应该给出高层次概念和算法。细节应该往下渐次展开，直至找到源文件中最底层的函数和细节。</li><li>源文件内部在垂直方向上，不同概念之间应该有间隔。比如：import块、import static块、变量定义、方法区等等，它们之间应该有空行间隔；</li><li>紧密相关的代码应该相互靠近。比如：<ul><li>不必在变量之间插入无用的注释；</li><li>变量声明应该尽可能靠近其实用的位置；</li><li>循环中的控制变量应该尽量在循环语句中声明；</li><li>被调用的函数应该在调用函数的下方；</li><li>概念相关的代码应该放在一起；</li></ul></li><li>每行代码长度控制在120个字符以内；</li><li>代码行中恰当使用空格。比如：逗号后加一个空格；</li><li>统一的缩进风格；</li></ul><h2 id="对象和数据结构"><a href="#对象和数据结构" class="headerlink" title="对象和数据结构"></a>对象和数据结构</h2><ul><li>数据抽象以避免曝露数据细节，以抽象形态表述数据；</li><li>过程式代码便于在不改动既有数据机构的前提下添加新函数。面向对象代码便于在不改动既有函数的前提下添加新类；</li><li>反之亦然，过程式代码难以添加新数据结构，因为必须修改所有函数。面向对象代码难以添加新函数，因为必须修改所有类；</li></ul><h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><ul><li>使用异常而非返回码；</li><li>不要在方法中返回null值，而是抛出异常或返回特例对象；</li><li>不要向方法传递null值；</li></ul><h2 id="边界"><a href="#边界" class="headerlink" title="边界"></a>边界</h2><h2 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h2><ul><li>不要遵循TDD三定律（所谓的编写生产代码前先编写单元测试）；</li><li>保持测试代码的整洁，抽象隐藏测试准备细节，突出测试逻辑；</li><li>单元测试中优先考虑简介，再考虑执行效率；</li><li>每个测试有且只有一个断言；</li></ul><h2 id="类"><a href="#类" class="headerlink" title="类"></a>类</h2><ul><li>类应该保持短小；</li><li>类应该遵守单一权责原则（SRP）；</li><li>类内部应该保持高内聚（保持每个方法都操作内部的一个或者多个变量）；</li></ul><h2 id="系统"><a href="#系统" class="headerlink" title="系统"></a>系统</h2><ul><li><p>系统的构造和使用分开的办法：</p><ul><li>分离构造过程，创建系统所需的对象，并传递给应用程序，应用程序只管使用；</li><li>在应用程序中使用抽象工厂方法来隐藏构建细节；</li><li>使用依赖注入来分离构造和使用；</li></ul></li><li><p>Java AOP三种机制：</p><ul><li>Java代理，常用的字节码操作库有：CGLIB、ASM、Javassist；</li><li>纯Java AOP框架；</li><li>AspectJ；</li></ul></li></ul><h2 id="迭进"><a href="#迭进" class="headerlink" title="迭进"></a>迭进</h2><ul><li>运行所有测试；</li><li>不可重复；</li><li>调整代码，确保具有良好的表达力；</li><li>尽可能少的类和方法；</li></ul><h2 id="并发编程"><a href="#并发编程" class="headerlink" title="并发编程"></a>并发编程</h2><ul><li>对象是过程的抽象，线程是调度的抽象；</li><li>并发防御性原则<ul><li>单一权责原则；</li><li>限制数据作用域；</li><li>使用数据副本；</li><li>线程应尽可能独立；</li></ul></li><li>了解Java并发安全库；</li><li>了解并发执行模型；</li><li>保持同步区域微小；</li></ul><h2 id="味道与启发"><a href="#味道与启发" class="headerlink" title="味道与启发"></a>味道与启发</h2><h3 id="注释-1"><a href="#注释-1" class="headerlink" title="注释"></a>注释</h3><ul><li>不恰当的信息</li><li>废弃的注释</li><li>冗余的注释</li><li>糟糕的注释</li><li>注释掉的代码</li></ul><h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><ul><li>需要多步才能实现的构建</li><li>需要多步才能做到的测试</li></ul><h3 id="函数-1"><a href="#函数-1" class="headerlink" title="函数"></a>函数</h3><ul><li>过多的参数</li><li>输出参数</li><li>标志参数（布尔值参数）</li><li>不被调用的死函数</li></ul><h3 id="一般性问题"><a href="#一般性问题" class="headerlink" title="一般性问题"></a>一般性问题</h3><ul><li>一个源文件存在多种语言</li><li>明显的行为未被实现</li><li>不正确的边界行为</li><li>忽视安全（防御性编程）</li><li>重复代码</li><li>在错误的抽象层级上的代码</li><li>基类依赖于派生类</li><li>信息过多（类中方法过多、函数变量过多等等）</li><li>不执行的代码</li><li>垂直距离过大（变量、函数应该在靠近使用的地方定义）</li><li>前后不一致（不同地方的相似概念应该用相似一致的命名，如方法名processVerificationRequest和processDeletionRequest）</li><li>混淆视听的代码（如：没有实现的默认构造函数、没用的变量、无调用的函数、无信息量的注释）</li><li>人为耦合。（不相互依赖的东西不应该耦合）</li><li>特性依恋。（类的方法只应对所属类中的变量和函数感兴趣，不应该垂青其他类中的变量和函数）</li><li>选择算子参数。选择算子可能是boolean、枚举、整数等形式，通常可以拆分为多个小函数</li><li>晦涩的意图，包括联排表达式、匈牙利语标记法、魔术数等</li><li>位置错误的权责</li><li>不恰当的静态方法。如果的确需要静态方法，那么请确保没机会打算让它有多态行为</li><li>使用解释性变量</li><li>函数名称应该表达其行为</li><li>理解算法</li><li>把逻辑依赖改为物理依赖。（比如某些写死的静态变量，改为从实体的get方法获取）</li><li>用多态替代If&#x2F;Else或Switch&#x2F;Case</li><li>团队成员应遵循标准约定</li><li>用命名常量替代魔术数</li><li>封装布尔条件</li><li>避免否定性布尔条件</li><li>函数只做一件事</li><li>掩蔽时序耦合</li><li>封装边界条件（比如level+1、level-1）</li><li>函数应该只在一个抽象层级</li><li>在较高层级放置可配置数据</li></ul><h2 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h2><ul><li>通过使用通配符避免过长的导入清单（import）</li><li>不要继承常量</li><li>优先使用枚举而不是常量</li></ul><h2 id="名称"><a href="#名称" class="headerlink" title="名称"></a>名称</h2><ul><li>采用描述性名称</li><li>名称应该与抽象层级相符</li><li>尽可能使用标准命名法</li><li>无歧义的名称</li><li>作用范围较大的名称选用长名称（范围小的可以用短名称，比如循环变量i）</li><li>避免编码式命名（比如匈牙利语标记法等）</li><li>名称应该说明副作用（比如createOrReturnOos优于getOos）</li></ul><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><ul><li>测试不足</li><li>使用覆盖率工具包</li><li>别略过小测试</li><li>被忽略的测试就是对不确定事物的疑问</li><li>测试边界条件</li><li>全面测试相近的缺陷</li><li>测试失败的模式有启发性</li><li>测试覆盖率的模式有启发性</li><li>测试应该快速</li></ul>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
            <tag> 代码整洁之道 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>再读Spring源码之三 常用扩展点</title>
      <link href="/2020/10/26/%E5%86%8D%E8%AF%BBSpring%E6%BA%90%E7%A0%81%E4%B9%8B%E4%B8%89-%E5%B8%B8%E7%94%A8%E6%89%A9%E5%B1%95%E7%82%B9/"/>
      <url>/2020/10/26/%E5%86%8D%E8%AF%BBSpring%E6%BA%90%E7%A0%81%E4%B9%8B%E4%B8%89-%E5%B8%B8%E7%94%A8%E6%89%A9%E5%B1%95%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<p>本来打算逐个详解Spring的扩展点，但网上关于扩展点的有关资料其实已经非常多，没必要重复造轮子。于是，我决定用这篇文章扼要总结备忘下Spring的各个扩展点的原理和使用场景。</p><span id="more"></span><h2 id="BeanFactory内部扩展点"><a href="#BeanFactory内部扩展点" class="headerlink" title="BeanFactory内部扩展点"></a>BeanFactory内部扩展点</h2><p>BeanFactory初始化扩展点顺序：</p><ul><li><strong>BeanNameAware</strong>‘s setBeanName</li><li><strong>BeanClassLoaderAware</strong>‘s setBeanClassLoader</li><li><strong>BeanFactoryAware</strong>‘s setBeanFactory</li><li><strong>EnvironmentAware</strong>‘s setEnvironment</li><li><strong>EmbeddedValueResolverAware</strong>‘s setEmbeddedValueResolver</li><li><strong>ResourceLoaderAware</strong>‘s setResourceLoader (only applicable when running in an application context)</li><li><strong>ApplicationEventPublisherAware</strong>‘s setApplicationEventPublisher (only applicable when running in an application context)</li><li><strong>MessageSourceAware</strong>‘s setMessageSource (only applicable when running in an application context)</li><li><strong>ApplicationContextAware</strong>‘s setApplicationContext (only applicable when running in an application context)</li><li><strong>ServletContextAware</strong>‘s setServletContext (only applicable when running in a web application context)</li><li><strong>BeanPostProcessors</strong>‘s postProcessBeforeInitialization methods </li><li><strong>InitializingBean</strong>‘s afterPropertiesSet</li><li>a custom init-method definition</li><li><strong>BeanPostProcessors</strong>‘s postProcessAfterInitialization methods</li></ul><p>BeanFactory关闭扩展点顺序：</p><ul><li><strong>DestructionAwareBeanPostProcessors</strong> postProcessBeforeDestruction methods</li><li><strong>DisposableBean</strong>‘s destroy</li><li>a custom destroy-method definition</li></ul><h2 id="BeanFactoryPostProcessor"><a href="#BeanFactoryPostProcessor" class="headerlink" title="BeanFactoryPostProcessor"></a>BeanFactoryPostProcessor</h2><h3 id="接口定义"><a href="#接口定义" class="headerlink" title="接口定义"></a>接口定义</h3><pre><code class="java">/** * Factory hook that allows for custom modification of an application context&#39;s * bean definitions, adapting the bean property values of the context&#39;s underlying * bean factory. * * &lt;p&gt;Useful for custom config files targeted at system administrators that * override bean properties configured in the application context. See * &#123;@link PropertyResourceConfigurer&#125; and its concrete implementations for * out-of-the-box solutions that address such configuration needs. * * &lt;p&gt;A &#123;@code BeanFactoryPostProcessor&#125; may interact with and modify bean * definitions, but never bean instances. Doing so may cause premature bean * instantiation, violating the container and causing unintended side-effects. * If bean instance interaction is required, consider implementing * &#123;@link BeanPostProcessor&#125; instead. * * &lt;h3&gt;Registration&lt;/h3&gt; * &lt;p&gt;An &#123;@code ApplicationContext&#125; auto-detects &#123;@code BeanFactoryPostProcessor&#125; * beans in its bean definitions and applies them before any other beans get created. * A &#123;@code BeanFactoryPostProcessor&#125; may also be registered programmatically * with a &#123;@code ConfigurableApplicationContext&#125;. * * &lt;h3&gt;Ordering&lt;/h3&gt; * &lt;p&gt;&#123;@code BeanFactoryPostProcessor&#125; beans that are autodetected in an * &#123;@code ApplicationContext&#125; will be ordered according to * &#123;@link org.springframework.core.PriorityOrdered&#125; and * &#123;@link org.springframework.core.Ordered&#125; semantics. In contrast, * &#123;@code BeanFactoryPostProcessor&#125; beans that are registered programmatically * with a &#123;@code ConfigurableApplicationContext&#125; will be applied in the order of * registration; any ordering semantics expressed through implementing the * &#123;@code PriorityOrdered&#125; or &#123;@code Ordered&#125; interface will be ignored for * programmatically registered post-processors. Furthermore, the * &#123;@link org.springframework.core.annotation.Order @Order&#125; annotation is not * taken into account for &#123;@code BeanFactoryPostProcessor&#125; beans. * * @author Juergen Hoeller * @author Sam Brannen * @since 06.07.2003 * @see BeanPostProcessor * @see PropertyResourceConfigurer */@FunctionalInterfacepublic interface BeanFactoryPostProcessor &#123;    /**     * Modify the application context&#39;s internal bean factory after its standard     * initialization. All bean definitions will have been loaded, but no beans     * will have been instantiated yet. This allows for overriding or adding     * properties even to eager-initializing beans.     * @param beanFactory the bean factory used by the application context     * @throws org.springframework.beans.BeansException in case of errors     */    void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;&#125;</code></pre><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>BeanFactoryPostProcessor用于在Bean定义信息加载完成之后、Bean实例化之前进行，对Bean的定义信息进行修改。</p><p>常见例子：PropertySourcesPlaceholderConfigurer，用于配置文件的占位符替换。</p><h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><p>Spring容器启动过程中会自动加载实现了BeanFactoryPostProcessor接口的Bean。</p><p>并且在refresh()中进行调用：</p><pre><code class="java">// 见org.springframework.context.support.AbstractApplicationContext@Overridepublic void refresh() throws BeansException, IllegalStateException &#123;    synchronized (this.startupShutdownMonitor) &#123;        // Prepare this context for refreshing.        prepareRefresh();        // Tell the subclass to refresh the internal bean factory.        ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();        // Prepare the bean factory for use in this context.        prepareBeanFactory(beanFactory);        try &#123;            // Allows post-processing of the bean factory in context subclasses.            postProcessBeanFactory(beanFactory);            // Invoke factory processors registered as beans in the context.            invokeBeanFactoryPostProcessors(beanFactory);        // ...</code></pre><p>具体调用逻辑见org.springframework.context.support.PostProcessorRegistrationDelegate#invokeBeanFactoryPostProcessors方法，此处不再赘言。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>BeanFactoryPostProcessor是在bean实例化前被触发的，因此绝对不能在BeanFactoryPostProcessor提前实例化bean，否则会破坏容器造成预估不到的副作用。如果需要修改Bean的实例化逻辑，应该使用BeanPostProcessor。</p><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://www.cnblogs.com/youzhibing/p/10559337.html">Spring拓展接口之BeanFactoryPostProcessor，占位符与敏感信息解密原理</a></li><li><a href="https://www.jianshu.com/p/3d099ea43b0e">使用BeanFactoryPostProcessor——这种姿势不要用</a></li></ul><h2 id="BeanDefinitionRegistryPostProcessor"><a href="#BeanDefinitionRegistryPostProcessor" class="headerlink" title="BeanDefinitionRegistryPostProcessor"></a>BeanDefinitionRegistryPostProcessor</h2><h3 id="接口定义-1"><a href="#接口定义-1" class="headerlink" title="接口定义"></a>接口定义</h3><pre><code class="java">/** * Extension to the standard &#123;@link BeanFactoryPostProcessor&#125; SPI, allowing for * the registration of further bean definitions &lt;i&gt;before&lt;/i&gt; regular * BeanFactoryPostProcessor detection kicks in. In particular, * BeanDefinitionRegistryPostProcessor may register further bean definitions * which in turn define BeanFactoryPostProcessor instances. * * @author Juergen Hoeller * @since 3.0.1 * @see org.springframework.context.annotation.ConfigurationClassPostProcessor */public interface BeanDefinitionRegistryPostProcessor extends BeanFactoryPostProcessor &#123;    /**     * Modify the application context&#39;s internal bean definition registry after its     * standard initialization. All regular bean definitions will have been loaded,     * but no beans will have been instantiated yet. This allows for adding further     * bean definitions before the next post-processing phase kicks in.     * @param registry the bean definition registry used by the application context     * @throws org.springframework.beans.BeansException in case of errors     */    void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException;&#125;</code></pre><h3 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h3><p>BeanFactoryPostProcessor的子类，用于注册自定义的BeanDefinition。该拓展点在BeanFactoryPostProcessor之前执行。</p><h3 id="实现原理-1"><a href="#实现原理-1" class="headerlink" title="实现原理"></a>实现原理</h3><p>实现过程和 <em>BeanFactoryPostProcessor</em> 高度相关。<br>请见 <em>org.springframework.context.support.PostProcessorRegistrationDelegate#invokeBeanFactoryPostProcessors</em> 方法</p><h2 id="BeanPostProcessor"><a href="#BeanPostProcessor" class="headerlink" title="BeanPostProcessor"></a>BeanPostProcessor</h2><h3 id="接口定义-2"><a href="#接口定义-2" class="headerlink" title="接口定义"></a>接口定义</h3><pre><code class="java">/** * Factory hook that allows for custom modification of new bean instances &amp;mdash; * for example, checking for marker interfaces or wrapping beans with proxies. * * &lt;p&gt;Typically, post-processors that populate beans via marker interfaces * or the like will implement &#123;@link #postProcessBeforeInitialization&#125;, * while post-processors that wrap beans with proxies will normally * implement &#123;@link #postProcessAfterInitialization&#125;. * * &lt;h3&gt;Registration&lt;/h3&gt; * &lt;p&gt;An &#123;@code ApplicationContext&#125; can autodetect &#123;@code BeanPostProcessor&#125; beans * in its bean definitions and apply those post-processors to any beans subsequently * created. A plain &#123;@code BeanFactory&#125; allows for programmatic registration of * post-processors, applying them to all beans created through the bean factory. * * &lt;h3&gt;Ordering&lt;/h3&gt; * &lt;p&gt;&#123;@code BeanPostProcessor&#125; beans that are autodetected in an * &#123;@code ApplicationContext&#125; will be ordered according to * &#123;@link org.springframework.core.PriorityOrdered&#125; and * &#123;@link org.springframework.core.Ordered&#125; semantics. In contrast, * &#123;@code BeanPostProcessor&#125; beans that are registered programmatically with a * &#123;@code BeanFactory&#125; will be applied in the order of registration; any ordering * semantics expressed through implementing the * &#123;@code PriorityOrdered&#125; or &#123;@code Ordered&#125; interface will be ignored for * programmatically registered post-processors. Furthermore, the * &#123;@link org.springframework.core.annotation.Order @Order&#125; annotation is not * taken into account for &#123;@code BeanPostProcessor&#125; beans. * * @author Juergen Hoeller * @author Sam Brannen * @since 10.10.2003 * @see InstantiationAwareBeanPostProcessor * @see DestructionAwareBeanPostProcessor * @see ConfigurableBeanFactory#addBeanPostProcessor * @see BeanFactoryPostProcessor */public interface BeanPostProcessor &#123;    /**     * Apply this &#123;@code BeanPostProcessor&#125; to the given new bean instance &lt;i&gt;before&lt;/i&gt; any bean     * initialization callbacks (like InitializingBean&#39;s &#123;@code afterPropertiesSet&#125;     * or a custom init-method). The bean will already be populated with property values.     * The returned bean instance may be a wrapper around the original.     * &lt;p&gt;The default implementation returns the given &#123;@code bean&#125; as-is.     * @param bean the new bean instance     * @param beanName the name of the bean     * @return the bean instance to use, either the original or a wrapped one;     * if &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked     * @throws org.springframework.beans.BeansException in case of errors     * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet     */    @Nullable    default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123;        return bean;    &#125;    /**     * Apply this &#123;@code BeanPostProcessor&#125; to the given new bean instance &lt;i&gt;after&lt;/i&gt; any bean     * initialization callbacks (like InitializingBean&#39;s &#123;@code afterPropertiesSet&#125;     * or a custom init-method). The bean will already be populated with property values.     * The returned bean instance may be a wrapper around the original.     * &lt;p&gt;In case of a FactoryBean, this callback will be invoked for both the FactoryBean     * instance and the objects created by the FactoryBean (as of Spring 2.0). The     * post-processor can decide whether to apply to either the FactoryBean or created     * objects or both through corresponding &#123;@code bean instanceof FactoryBean&#125; checks.     * &lt;p&gt;This callback will also be invoked after a short-circuiting triggered by a     * &#123;@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation&#125; method,     * in contrast to all other &#123;@code BeanPostProcessor&#125; callbacks.     * &lt;p&gt;The default implementation returns the given &#123;@code bean&#125; as-is.     * @param bean the new bean instance     * @param beanName the name of the bean     * @return the bean instance to use, either the original or a wrapped one;     * if &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked     * @throws org.springframework.beans.BeansException in case of errors     * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet     * @see org.springframework.beans.factory.FactoryBean     */    @Nullable    default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123;        return bean;    &#125;&#125;</code></pre><h3 id="应用场景-2"><a href="#应用场景-2" class="headerlink" title="应用场景"></a>应用场景</h3><p> <em>BeanPostProcessor</em> 允许自定义修改spring bean factory创建的新bean实例。如果你想在Spring容器完成实例化、配置和初始化bean之后实现一些定制逻辑，我们可以插入一个或多个 <em>BeanPostProcessor</em> 实现。</p><p> <em>BeanPostProcessor</em> 通常检查回调接口，或者使用代理包装bean。例如一些Spring AOP基础结构类（例如 <em>AbstractAdvisingBeanPostProcessor</em> ）实现了bean后处理器，提供代理包装逻辑。</p><p>常见例子： <em>AutowiredAnnotationBeanPostProcessor</em>，@Autowire注解的实现</p><h3 id="实现原理-2"><a href="#实现原理-2" class="headerlink" title="实现原理"></a>实现原理</h3><p>Bean在实例化前后分别会调用该拓展点的两个方法。</p><p>例如，在类 <em>org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory</em> 中有如下逻辑：</p><pre><code class="java">protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) &#123;    if (System.getSecurityManager() != null) &#123;        AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123;            invokeAwareMethods(beanName, bean);            return null;        &#125;, getAccessControlContext());    &#125;    else &#123;        invokeAwareMethods(beanName, bean);    &#125;    Object wrappedBean = bean;    if (mbd == null || !mbd.isSynthetic()) &#123;        // 实例化前调用 postProcessBeforeInitialization        wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);    &#125;    try &#123;        invokeInitMethods(beanName, wrappedBean, mbd);    &#125;    catch (Throwable ex) &#123;        throw new BeanCreationException(                (mbd != null ? mbd.getResourceDescription() : null),                beanName, &quot;Invocation of init method failed&quot;, ex);    &#125;    if (mbd == null || !mbd.isSynthetic()) &#123;        // 实例化后调用 applyBeanPostProcessorsAfterInitialization        wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);    &#125;    return wrappedBean;&#125;@Overridepublic Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName)        throws BeansException &#123;    Object result = existingBean;    for (BeanPostProcessor processor : getBeanPostProcessors()) &#123;        Object current = processor.postProcessBeforeInitialization(result, beanName);        if (current == null) &#123;            return result;        &#125;        result = current;    &#125;    return result;&#125;@Overridepublic Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName)        throws BeansException &#123;    Object result = existingBean;    for (BeanPostProcessor processor : getBeanPostProcessors()) &#123;        Object current = processor.postProcessAfterInitialization(result, beanName);        if (current == null) &#123;            return result;        &#125;        result = current;    &#125;    return result;&#125;</code></pre><h3 id="注意事项-1"><a href="#注意事项-1" class="headerlink" title="注意事项"></a>注意事项</h3><p>无</p><h3 id="参考资料-1"><a href="#参考资料-1" class="headerlink" title="参考资料"></a>参考资料</h3><ul><li><a href="https://juejin.im/post/6844903976886861831">Spring系列六：Spring BeanPostProcessor</a></li></ul><h2 id="Aware"><a href="#Aware" class="headerlink" title="Aware"></a>Aware</h2><h3 id="接口定义-3"><a href="#接口定义-3" class="headerlink" title="接口定义"></a>接口定义</h3><p>只是一个标记接口，没有其他内部方法。具体实现都在子类中。</p><pre><code class="java">/** * A marker superinterface indicating that a bean is eligible to be notified by the * Spring container of a particular framework object through a callback-style method. * The actual method signature is determined by individual subinterfaces but should * typically consist of just one void-returning method that accepts a single argument. * * &lt;p&gt;Note that merely implementing &#123;@link Aware&#125; provides no default functionality. * Rather, processing must be done explicitly, for example in a * &#123;@link org.springframework.beans.factory.config.BeanPostProcessor&#125;. * Refer to &#123;@link org.springframework.context.support.ApplicationContextAwareProcessor&#125; * for an example of processing specific &#123;@code *Aware&#125; interface callbacks. * * @author Chris Beams * @author Juergen Hoeller * @since 3.1 */public interface Aware &#123;&#125;</code></pre><h3 id="应用场景-3"><a href="#应用场景-3" class="headerlink" title="应用场景"></a>应用场景</h3><p>Aware 接口是一个标记接口，所有实现该接口的类都会被Spring容器筛选出来，并得到某种通知。所有实现该接口的子接口都提供固定的接收通知的方法。常见的实现包括：</p><ul><li>ApplicationContextAware</li><li>EnvironmentAware</li><li>EmbeddedValueResolverAware</li><li>ResourceLoaderAware</li><li>ApplicationEventPublisherAware</li><li>MessageSourceAware</li></ul><h3 id="实现原理-3"><a href="#实现原理-3" class="headerlink" title="实现原理"></a>实现原理</h3><p>Aware相关接口实现Bean是借助一个 <em>ApplicationContextAwareProcessor</em> 来触发的。<em>ApplicationContextAwareProcessor</em> 实现了 <em>BeanPostProcessor</em> 扩展点:</p><pre><code class="java">class ApplicationContextAwareProcessor implements BeanPostProcessor &#123;    private final ConfigurableApplicationContext applicationContext;    private final StringValueResolver embeddedValueResolver;    /**     * Create a new ApplicationContextAwareProcessor for the given context.     */    public ApplicationContextAwareProcessor(ConfigurableApplicationContext applicationContext) &#123;        this.applicationContext = applicationContext;        this.embeddedValueResolver = new EmbeddedValueResolver(applicationContext.getBeanFactory());    &#125;    @Override    @Nullable    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123;        // 只处理Aware子类，此处提前判断并短路不符合条件的bean。        // 个人觉得这个布尔条件略丑，为啥不用 bean instanceOf Aware ?        if (!(bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware ||                bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware ||                bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware))&#123;            return bean;        &#125;        AccessControlContext acc = null;        if (System.getSecurityManager() != null) &#123;            acc = this.applicationContext.getBeanFactory().getAccessControlContext();        &#125;        if (acc != null) &#123;            AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123;                invokeAwareInterfaces(bean);                return null;            &#125;, acc);        &#125;        else &#123;            invokeAwareInterfaces(bean);        &#125;        return bean;    &#125;    private void invokeAwareInterfaces(Object bean) &#123;        // 判断bean类型，并且调用其实现的子接口方法        if (bean instanceof EnvironmentAware) &#123;            ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment());        &#125;        if (bean instanceof EmbeddedValueResolverAware) &#123;            ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver);        &#125;        if (bean instanceof ResourceLoaderAware) &#123;            ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext);        &#125;        if (bean instanceof ApplicationEventPublisherAware) &#123;            ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext);        &#125;        if (bean instanceof MessageSourceAware) &#123;            ((MessageSourceAware) bean).setMessageSource(this.applicationContext);        &#125;        if (bean instanceof ApplicationContextAware) &#123;            ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext);        &#125;    &#125;&#125;</code></pre><h2 id="ApplicationListener"><a href="#ApplicationListener" class="headerlink" title="ApplicationListener"></a>ApplicationListener</h2><h3 id="接口定义-4"><a href="#接口定义-4" class="headerlink" title="接口定义"></a>接口定义</h3><pre><code class="java">/** * Interface to be implemented by application event listeners. * * &lt;p&gt;Based on the standard &#123;@code java.util.EventListener&#125; interface * for the Observer design pattern. * * &lt;p&gt;As of Spring 3.0, an &#123;@code ApplicationListener&#125; can generically declare * the event type that it is interested in. When registered with a Spring * &#123;@code ApplicationContext&#125;, events will be filtered accordingly, with the * listener getting invoked for matching event objects only. * * @author Rod Johnson * @author Juergen Hoeller * @param &lt;E&gt; the specific &#123;@code ApplicationEvent&#125; subclass to listen to * @see org.springframework.context.ApplicationEvent * @see org.springframework.context.event.ApplicationEventMulticaster * @see org.springframework.context.event.EventListener */@FunctionalInterfacepublic interface ApplicationListener&lt;E extends ApplicationEvent&gt; extends EventListener &#123;    /**     * Handle an application event.     * @param event the event to respond to     */    void onApplicationEvent(E event);&#125;</code></pre><h3 id="应用场景-4"><a href="#应用场景-4" class="headerlink" title="应用场景"></a>应用场景</h3><p><em>ApplicationListener</em> 主要用来监听应用程序上下文的事件，不同的实现子类注册自己感兴趣的事件。</p><h3 id="实现原理-4"><a href="#实现原理-4" class="headerlink" title="实现原理"></a>实现原理</h3><p>使用样例：</p><pre><code class="java">@Slf4j@Componentpublic class MyApplicationStartedListener implements ApplicationListener&lt;ApplicationStartedEvent&gt; &#123;    @Override    public void onApplicationEvent(ApplicationStartedEvent event) &#123;        log.info(&quot;application started. event=&#123;&#125;&quot;, event);    &#125;&#125;</code></pre><h2 id="InitializingBean"><a href="#InitializingBean" class="headerlink" title="InitializingBean"></a>InitializingBean</h2><h3 id="接口定义-5"><a href="#接口定义-5" class="headerlink" title="接口定义"></a>接口定义</h3><pre><code class="java">/** * Interface to be implemented by beans that need to react once all their properties * have been set by a &#123;@link BeanFactory&#125;: e.g. to perform custom initialization, * or merely to check that all mandatory properties have been set. * * &lt;p&gt;An alternative to implementing &#123;@code InitializingBean&#125; is specifying a custom * init method, for example in an XML bean definition. For a list of all bean * lifecycle methods, see the &#123;@link BeanFactory BeanFactory javadocs&#125;. * * @author Rod Johnson * @author Juergen Hoeller * @see DisposableBean * @see org.springframework.beans.factory.config.BeanDefinition#getPropertyValues() * @see org.springframework.beans.factory.support.AbstractBeanDefinition#getInitMethodName() */public interface InitializingBean &#123;    /**     * Invoked by the containing &#123;@code BeanFactory&#125; after it has set all bean properties     * and satisfied &#123;@link BeanFactoryAware&#125;, &#123;@code ApplicationContextAware&#125; etc.     * &lt;p&gt;This method allows the bean instance to perform validation of its overall     * configuration and final initialization when all bean properties have been set.     * @throws Exception in the event of misconfiguration (such as failure to set an     * essential property) or if initialization fails for any other reason     */    void afterPropertiesSet() throws Exception;&#125;</code></pre><h3 id="应用场景-5"><a href="#应用场景-5" class="headerlink" title="应用场景"></a>应用场景</h3><p><em>InitializingBean</em> 用在Bean的属性注入完毕后，执行用户自定义的初始化逻辑。</p><h3 id="实现原理-5"><a href="#实现原理-5" class="headerlink" title="实现原理"></a>实现原理</h3><p>调用逻辑可见 <em>org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory</em></p><pre><code class="java">/**    * Initialize the given bean instance, applying factory callbacks    * as well as init methods and bean post processors.    * &lt;p&gt;Called from &#123;@link #createBean&#125; for traditionally defined beans,    * and from &#123;@link #initializeBean&#125; for existing bean instances.    * @param beanName the bean name in the factory (for debugging purposes)    * @param bean the new bean instance we may need to initialize    * @param mbd the bean definition that the bean was created with    * (can also be &#123;@code null&#125;, if given an existing bean instance)    * @return the initialized bean instance (potentially wrapped)    * @see BeanNameAware    * @see BeanClassLoaderAware    * @see BeanFactoryAware    * @see #applyBeanPostProcessorsBeforeInitialization    * @see #invokeInitMethods    * @see #applyBeanPostProcessorsAfterInitialization    */protected Object initializeBean(String beanName, Object bean, @Nullable RootBeanDefinition mbd) &#123;    if (System.getSecurityManager() != null) &#123;        AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123;            invokeAwareMethods(beanName, bean);            return null;        &#125;, getAccessControlContext());    &#125;    else &#123;        invokeAwareMethods(beanName, bean);    &#125;    Object wrappedBean = bean;    if (mbd == null || !mbd.isSynthetic()) &#123;        wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);    &#125;    try &#123;        // 调用用户自定义初始化方法        invokeInitMethods(beanName, wrappedBean, mbd);    &#125;    catch (Throwable ex) &#123;        throw new BeanCreationException(                (mbd != null ? mbd.getResourceDescription() : null),                beanName, &quot;Invocation of init method failed&quot;, ex);    &#125;    if (mbd == null || !mbd.isSynthetic()) &#123;        wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);    &#125;    return wrappedBean;&#125;/**    * Give a bean a chance to react now all its properties are set,    * and a chance to know about its owning bean factory (this object).    * This means checking whether the bean implements InitializingBean or defines    * a custom init method, and invoking the necessary callback(s) if it does.    * @param beanName the bean name in the factory (for debugging purposes)    * @param bean the new bean instance we may need to initialize    * @param mbd the merged bean definition that the bean was created with    * (can also be &#123;@code null&#125;, if given an existing bean instance)    * @throws Throwable if thrown by init methods or by the invocation process    * @see #invokeCustomInitMethod    */protected void invokeInitMethods(String beanName, Object bean, @Nullable RootBeanDefinition mbd)        throws Throwable &#123;    // 执行InitializingBean扩展点，调用用户自定义逻辑    boolean isInitializingBean = (bean instanceof InitializingBean);    if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod(&quot;afterPropertiesSet&quot;))) &#123;        if (logger.isTraceEnabled()) &#123;            logger.trace(&quot;Invoking afterPropertiesSet() on bean with name &#39;&quot; + beanName + &quot;&#39;&quot;);        &#125;        if (System.getSecurityManager() != null) &#123;            try &#123;                AccessController.doPrivileged((PrivilegedExceptionAction&lt;Object&gt;) () -&gt; &#123;                    ((InitializingBean) bean).afterPropertiesSet();                    return null;                &#125;, getAccessControlContext());            &#125;            catch (PrivilegedActionException pae) &#123;                throw pae.getException();            &#125;        &#125;        else &#123;            ((InitializingBean) bean).afterPropertiesSet();        &#125;    &#125;    // 执行用户自定义的初始化方法 init-method    if (mbd != null &amp;&amp; bean.getClass() != NullBean.class) &#123;        String initMethodName = mbd.getInitMethodName();        if (StringUtils.hasLength(initMethodName) &amp;&amp;                !(isInitializingBean &amp;&amp; &quot;afterPropertiesSet&quot;.equals(initMethodName)) &amp;&amp;                !mbd.isExternallyManagedInitMethod(initMethodName)) &#123;            invokeCustomInitMethod(beanName, bean, mbd);        &#125;    &#125;&#125;</code></pre><h2 id="FactoryBean"><a href="#FactoryBean" class="headerlink" title="FactoryBean"></a>FactoryBean</h2><p>之前单独写过一篇，请见<a href="https://blog.duval.top/2020/10/07/%E5%86%8D%E8%AF%BBSpring%E6%BA%90%E7%A0%81%E4%B9%8B%E4%BA%8C-FactoryBean/">《再读Spring源码之二 FactoryBean》</a></p>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 源码分析 </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>再读Spring源码之二 FactoryBean</title>
      <link href="/2020/10/07/%E5%86%8D%E8%AF%BBSpring%E6%BA%90%E7%A0%81%E4%B9%8B%E4%BA%8C-FactoryBean/"/>
      <url>/2020/10/07/%E5%86%8D%E8%AF%BBSpring%E6%BA%90%E7%A0%81%E4%B9%8B%E4%BA%8C-FactoryBean/</url>
      
        <content type="html"><![CDATA[<p>本文是《再读Spring源码》系列第二篇，一起来探讨下Spring框架常见扩展点FactoryBean，了解它的使用场景和实现原理。</p><span id="more"></span><h2 id="FactoryBean简介"><a href="#FactoryBean简介" class="headerlink" title="FactoryBean简介"></a>FactoryBean简介</h2><p>正如名字所言，FactoryBean本质上一个是工厂类，用于构造用户所需的Bean。通过FactoryBean可以隐藏到构造某些Bean的复杂参数以及构建逻辑，暴露更加简化的接口。</p><p>FactoryBean的接口方法非常简单：</p><pre><code class="java">public interface FactoryBean&lt;T&gt; &#123;  // 获取对象  T getObject() throws Exception;  // 获取对象类型  Class&lt;T&gt; getObjectType();  // 判断是否为单例  boolean isSingleton();&#125;</code></pre><h2 id="FactoryBean使用方法"><a href="#FactoryBean使用方法" class="headerlink" title="FactoryBean使用方法"></a>FactoryBean使用方法</h2><p>如下样例，我们可以通过StudentFactoryBean来构建Student实例：</p><pre><code class="java">public class Student extends Person &#123;    public Student(DateTime birthday, String name) &#123;        super(birthday, name);    &#125;&#125;@Componentpublic class StudentFactoryBean implements FactoryBean&lt;Student&gt; &#123;    private String name;    private Integer age;    @Override    public Student getObject() throws Exception &#123;        DateTime birthday = new DateTime().minusYears(age);        return new Student(birthday, name);    &#125;    @Override    public Class&lt;?&gt; getObjectType() &#123;        return Student.class;    &#125;&#125;</code></pre><p>这里只是演示下用法，所以StudentFactoryBean的构建逻辑很简单。实际应用中，FactoryBean一般包含大量复杂业务逻辑。</p><h3 id="在XML配置中使用FactoryBean"><a href="#在XML配置中使用FactoryBean" class="headerlink" title="在XML配置中使用FactoryBean"></a>在XML配置中使用FactoryBean</h3><p>在老版本的spring框架里，常常通过xml配置注入bean。FactoryBean的常见用法是这样的：</p><pre><code class="xml">&lt;bean class = &quot;a.b.c.StudentFactoryBean&quot; id = &quot;bob&quot;&gt;    &lt;property name = &quot;name&quot; value =&quot;Bob&quot;/&gt;    &lt;property name = &quot;age&quot; value =&quot;20&quot;/&gt;&lt;/bean&gt;&lt;bean class = &quot;a.b.c.Teacher&quot; id = &quot;Tom&quot;&gt;    &lt;property name = &quot;student&quot; ref = &quot;bob&quot;/&gt;&lt;/bean&gt;</code></pre><p>这里bob实例的类型虽然为StudentFactoryBean，但在实例化的时候，Spring会调用StudentFactoryBean#getObject进行实例化，并返回Student对象。因此bob实例的最终类型是Student。</p><h3 id="在注解中使用FactoryBean"><a href="#在注解中使用FactoryBean" class="headerlink" title="在注解中使用FactoryBean"></a>在注解中使用FactoryBean</h3><p>在较新版本的Spring中，一般使用注解代替xml配置注入。Factory在注解注入方式的使用上稍有不同。一般如下：</p><pre><code class="java">@Beanpublic Student getStudent() throws Exception &#123;    return new StudentFactoryBean().setAge(20).setName(&quot;Bob&quot;).getObject();&#125;</code></pre><p>需要显式地调用getObject方法返回bean对象，并通过 <em>@Bean</em> 注解将类型为Student的bean注册到spring容器中。</p><h2 id="FactoryBean在spring中的实现原理"><a href="#FactoryBean在spring中的实现原理" class="headerlink" title="FactoryBean在spring中的实现原理"></a>FactoryBean在spring中的实现原理</h2><p>FactoryBean会在spring容器启动过程中进行加载，可以跟踪以下代码：</p><pre><code class="java">-&gt; SpringApplicationBuilder#run(String... args)--&gt; SpringApplicationBuilder#refreshContext(ConfigurableApplicationContext context)---&gt; SpringApplicationBuilder#refresh(ApplicationContext applicationContext)----&gt; SpringApplicationBuilder#refresh(ConfigurableApplicationContext applicationContext)-----&gt; AbstractApplicationContext#refresh()------&gt; AbstractApplicationContext#finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory)-------&gt; DefaultListableBeanFactory#preInstantiateSingletons()</code></pre><p>到最后我们会发现FactoryBean的初始化逻辑：</p><pre><code class="java">public void preInstantiateSingletons() throws BeansException &#123;// ...    // Trigger initialization of all non-lazy singleton beans...    for (String beanName : beanNames) &#123;        RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName);        if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123;            // 处理FactoryBean            if (isFactoryBean(beanName)) &#123;                // 实例化该工厂bean（注意工厂bean的名字以&amp;开头）                Object bean = getBean(FACTORY_BEAN_PREFIX + beanName);                if (bean instanceof FactoryBean) &#123;                    FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean;                    boolean isEagerInit;                    // SmartFactoryBean是FactoryBean的特殊类型；                    // 可以通过isEagerInit方法来判断其内部的bean是否需要提前实例化。                    if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123;                        isEagerInit = AccessController.doPrivileged(                                (PrivilegedAction&lt;Boolean&gt;) ((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit,                                getAccessControlContext());                    &#125;                    else &#123;                        isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp;                                ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit());                    &#125;                    // 如果需要提前实例化内部实例，则调用getBean进行实例化。（注意内部实例没有&amp;前缀）                    if (isEagerInit) &#123;                        getBean(beanName);                    &#125;                &#125;            &#125;            else &#123;                getBean(beanName);            &#125;        &#125;    &#125;// ......&#125;</code></pre><p>从上边我们可以有以下结论：</p><ul><li>1.工厂bean可以分为FactoryBean和SmartFactoryBean两种，后者的唯一区别是可以指示是否在初始化工厂Bean之后立即初始化内部实例；</li><li>2.工厂bean的名字以&amp;为前缀，去掉该前缀则为内部实例的默认名字。例如:”&amp;studentFactoryBean”为工厂bean名，而”studentFactoryBean”是内部实例bean名；</li></ul><p>从getBean方法跟踪进去，我们会发现实例化的时候针对工厂bean有特殊的初始化逻辑：</p><pre><code class="java">protected Object getObjectForBeanInstance(            Object beanInstance, String name, String beanName, @Nullable RootBeanDefinition mbd) &#123;    // Don&#39;t let calling code try to dereference the factory if the bean isn&#39;t a factory.    if (BeanFactoryUtils.isFactoryDereference(name)) &#123;        if (beanInstance instanceof NullBean) &#123;            return beanInstance;        &#125;        if (!(beanInstance instanceof FactoryBean)) &#123;            throw new BeanIsNotAFactoryException(beanName, beanInstance.getClass());        &#125;        if (mbd != null) &#123;            mbd.isFactoryBean = true;        &#125;        return beanInstance;    &#125;    // 如果不是FactoryBean，则直接返回，不执行以下逻辑    if (!(beanInstance instanceof FactoryBean)) &#123;        return beanInstance;    &#125;    Object object = null;    if (mbd != null) &#123;        mbd.isFactoryBean = true;    &#125;    else &#123;        // 工厂bean的内部实例初始化后会有缓存，先尝试通过缓存获取        object = getCachedObjectForFactoryBean(beanName);    &#125;    if (object == null) &#123;        // 没有内部实例缓存，则尝试初始化        FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) beanInstance;        // Caches object obtained from FactoryBean if it is a singleton.        if (mbd == null &amp;&amp; containsBeanDefinition(beanName)) &#123;            mbd = getMergedLocalBeanDefinition(beanName);        &#125;        boolean synthetic = (mbd != null &amp;&amp; mbd.isSynthetic());        object = getObjectFromFactoryBean(factory, beanName, !synthetic);    &#125;    return object;&#125;</code></pre><p>内部实例的初始化过程与其他单例的初始化过程类似：</p><pre><code class="java">protected Object getObjectFromFactoryBean(FactoryBean&lt;?&gt; factory, String beanName, boolean shouldPostProcess) &#123;    if (factory.isSingleton() &amp;&amp; containsSingleton(beanName)) &#123;        // 单例情况下，需要先加锁，然后检查缓存中是否已存在实例        synchronized (getSingletonMutex()) &#123;            Object object = this.factoryBeanObjectCache.get(beanName);            if (object == null) &#123;                // 通过工厂bean获取实例                object = doGetObjectFromFactoryBean(factory, beanName);                // Only post-process and store if not put there already during getObject() call above                // (e.g. because of circular reference processing triggered by custom getBean calls)                Object alreadyThere = this.factoryBeanObjectCache.get(beanName);                if (alreadyThere != null) &#123;                    object = alreadyThere;                &#125;                else &#123;                    if (shouldPostProcess) &#123;                        if (isSingletonCurrentlyInCreation(beanName)) &#123;                            // Temporarily return non-post-processed object, not storing it yet..                            return object;                        &#125;                        beforeSingletonCreation(beanName);                        try &#123;                            object = postProcessObjectFromFactoryBean(object, beanName);                        &#125;                        catch (Throwable ex) &#123;                            throw new BeanCreationException(beanName,                                    &quot;Post-processing of FactoryBean&#39;s singleton object failed&quot;, ex);                        &#125;                        finally &#123;                            afterSingletonCreation(beanName);                        &#125;                    &#125;                    if (containsSingleton(beanName)) &#123;                        // 加入缓存                        this.factoryBeanObjectCache.put(beanName, object);                    &#125;                &#125;            &#125;            return object;        &#125;    &#125;    else &#123;        // 非单例情况下，直接获取新实例        Object object = doGetObjectFromFactoryBean(factory, beanName);        if (shouldPostProcess) &#123;            try &#123;                object = postProcessObjectFromFactoryBean(object, beanName);            &#125;            catch (Throwable ex) &#123;                throw new BeanCreationException(beanName, &quot;Post-processing of FactoryBean&#39;s object failed&quot;, ex);            &#125;        &#125;        return object;    &#125;&#125;</code></pre><p>从上我们可以得知，如果是单例的FactoryBean，实例化后的内部实例会放进缓存中，反复复用；而非单例的FactoryBean，每次实例化都会获取新建新的内部实例。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文详细介绍了FactoryBean的使用方法、实现原理和应用场景。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://juejin.im/post/6844903954615107597">FactoryBean——Spring的扩展点之一</a></li><li><a href="https://spring.io/blog/2011/08/09/what-s-a-factorybean">What’s a FactoryBean?</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 源码分析 </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>再读Spring源码之一 Spring如何对付循环引用</title>
      <link href="/2020/08/21/%E5%86%8D%E8%AF%BBSpring%E6%BA%90%E7%A0%81%E4%B9%8B%E4%B8%80-Spring%E5%A6%82%E4%BD%95%E5%AF%B9%E4%BB%98%E5%BE%AA%E7%8E%AF%E5%BC%95%E7%94%A8/"/>
      <url>/2020/08/21/%E5%86%8D%E8%AF%BBSpring%E6%BA%90%E7%A0%81%E4%B9%8B%E4%B8%80-Spring%E5%A6%82%E4%BD%95%E5%AF%B9%E4%BB%98%E5%BE%AA%E7%8E%AF%E5%BC%95%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>关于Spring如何解决循环依赖这个问题，以前写过一篇文章<a href="https://blog.duval.top/2018/10/12/Spring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%903-%E5%AF%B9Bean%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E7%9A%84%E5%A4%84%E7%90%86/">Spring源码分析3-对Bean循环依赖的处理</a>。但是如今回头看，写得还是略粗糙，而且细节也忘得差不多了。所以决定再写一写，重新理一遍思路。</p><span id="more"></span><h2 id="Bean循环依赖"><a href="#Bean循环依赖" class="headerlink" title="Bean循环依赖"></a>Bean循环依赖</h2><p>spring框架的bean可以互相依赖，因此，可能存在循环依赖的情况，例如：</p><pre><code class="xml">    &lt;!--构造器循环依赖（单例）--&gt;    &lt;bean id = &quot;testA&quot; class=&quot;org.demo.circle.TestA&quot;&gt;        &lt;constructor-arg index = &quot;0&quot; ref=&quot;testB&quot;/&gt;    &lt;/bean&gt;    &lt;bean id = &quot;testB&quot; class=&quot;org.demo.circle.TestB&quot;&gt;        &lt;constructor-arg index = &quot;0&quot; ref=&quot;testC&quot;/&gt;    &lt;/bean&gt;    &lt;bean id = &quot;testC&quot; class=&quot;org.demo.circle.TestC&quot;&gt;        &lt;constructor-arg index = &quot;0&quot; ref=&quot;testA&quot;/&gt;    &lt;/bean&gt;    &lt;!--构造器循环依赖(prototype)--&gt;    &lt;bean id = &quot;testA0&quot; class=&quot;org.demo.circle.TestA&quot; scope=&quot;prototype&quot;&gt;        &lt;constructor-arg index = &quot;0&quot; ref=&quot;testB0&quot;/&gt;    &lt;/bean&gt;    &lt;bean id = &quot;testB0&quot; class=&quot;org.demo.circle.TestB&quot; scope=&quot;prototype&quot;&gt;        &lt;constructor-arg index = &quot;0&quot; ref=&quot;testC0&quot;/&gt;    &lt;/bean&gt;    &lt;bean id = &quot;testC0&quot; class=&quot;org.demo.circle.TestC&quot; scope=&quot;prototype&quot;&gt;        &lt;constructor-arg index = &quot;0&quot; ref=&quot;testA0&quot;/&gt;    &lt;/bean&gt;    &lt;!--属性注入循环依赖（单例）--&gt;    &lt;bean id = &quot;testA1&quot; class=&quot;org.demo.circle.TestA&quot;&gt;        &lt;property name=&quot;testB&quot; ref = &quot;testB1&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;bean id = &quot;testB1&quot; class=&quot;org.demo.circle.TestB&quot;&gt;        &lt;property name=&quot;testC&quot; ref = &quot;testC1&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;bean id = &quot;testC1&quot; class=&quot;org.demo.circle.TestC&quot;&gt;        &lt;property name=&quot;testA&quot; ref = &quot;testA1&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;!--属性注入循环依赖（prototype）--&gt;    &lt;bean id = &quot;testA2&quot; class=&quot;org.demo.circle.TestA&quot; scope=&quot;prototype&quot;&gt;        &lt;property name=&quot;testB&quot; ref = &quot;testB2&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;bean id = &quot;testB2&quot; class=&quot;org.demo.circle.TestB&quot; scope=&quot;prototype&quot;&gt;        &lt;property name=&quot;testC&quot; ref = &quot;testC2&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;    &lt;bean id = &quot;testC2&quot; class=&quot;org.demo.circle.TestC&quot; scope=&quot;prototype&quot;&gt;        &lt;property name=&quot;testA&quot; ref = &quot;testA2&quot;&gt;&lt;/property&gt;    &lt;/bean&gt;</code></pre><p>如上配置文件，包含常见的几种循环依赖，可以归类为以下两大类：</p><ul><li><p>通过构造器注入形成循环依赖：</p><ul><li>testA –&gt; testB –&gt; testC –&gt; testA –&gt; …</li><li>testA0 –&gt; testB0 –&gt; testC0 –&gt; testA0 –&gt; …</li></ul></li><li><p>通过属性注入形成循环依赖： </p><ul><li>testA1 –&gt; testB1 –&gt; testC1 –&gt; testA1 –&gt; …</li><li>testA2 –&gt; testB2 –&gt; testC2 –&gt; testA2 –&gt; …</li></ul></li></ul><p>按照bean的类型又可以细分为单例和prototype两种（其他scope类型不常用暂不讨论）</p><p>本文主要探讨spring对这几种循环依赖的处理策略和原理。</p><h2 id="Spring处理策略"><a href="#Spring处理策略" class="headerlink" title="Spring处理策略"></a>Spring处理策略</h2><p>先来说结论，通过测试用例我们可以简单验证以上几种循环依赖的处理策略：</p><pre><code class="java">  /**     * 测试构造器注入循环依赖(单例）     */    @Test(expected = BeanCreationException.class)    public void testCircleRefByConstructor() &#123;        BeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(&quot;circle.xml&quot;));        TestA testA = (TestA) beanFactory.getBean(&quot;testA&quot;);    &#125;    /**     * 测试构造器注入循环依赖(prototype类型）     */    @Test(expected = BeanCreationException.class)    public void testCircleRefByConstructorForPrototype() &#123;        BeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(&quot;circle.xml&quot;));        TestA testA = (TestA) beanFactory.getBean(&quot;testA0&quot;);    &#125;    /**     * 测试属性注入循环依赖（单例）     */    @Test    public void testCircleRefBySetter() &#123;        BeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(&quot;circle.xml&quot;));        TestA testA = (TestA) beanFactory.getBean(&quot;testA1&quot;);    &#125;    /**     * 测试的属性注入循环依赖（prototype类型）     */    @Test(expected = BeanCreationException.class)    public void testPrototypeRefBySetter() &#123;        BeanFactory beanFactory = new XmlBeanFactory(new ClassPathResource(&quot;circle.xml&quot;));        TestA testA = (TestA) beanFactory.getBean(&quot;testA2&quot;);    &#125;</code></pre><p>本文的测试用例代码可以移步<a href="https://github.com/duval1024/spring-tool/blob/master/spring-learn/src/test/java/org/demo/BeanFactoryTest.java">spring-learn仓库</a></p><p>测试结果表明：<strong>只有单例模式下通过属性注入才能够实现循环依赖</strong>，其他情况下都将抛出以下异常BeanCreationException。</p><h2 id="源码实现"><a href="#源码实现" class="headerlink" title="源码实现"></a>源码实现</h2><h3 id="调用时序图"><a href="#调用时序图" class="headerlink" title="调用时序图"></a>调用时序图</h3><p>我们从上边的测试用例出发分析源码实现，主要涉及的类包括XmlBeanFactory及其父类AbstractBeanFactory，和DefaultSingletonBeanRegistry以及它的父类AbstractAutowireCapableBeanFactory。核心的方法如下时序图：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E5%86%8D%E8%AF%BBSpring%E6%BA%90%E7%A0%81%E4%B9%8B%E4%B8%80%20Spring%E5%A6%82%E4%BD%95%E5%AF%B9%E4%BB%98%E5%BE%AA%E7%8E%AF%E5%BC%95%E7%94%A8%2Fspring-bean-%E5%8A%A0%E8%BD%BD%E6%97%B6%E5%BA%8F%E5%9B%BE.png" alt="spring-bean-加载时序图.png"></p><p>读者可以沿着这个时序图的思路去阅读下bean初始化构建的源码。</p><h3 id="检查缓存的单例"><a href="#检查缓存的单例" class="headerlink" title="检查缓存的单例"></a>检查缓存的单例</h3><p>我们直接从AbstractBeanFactory#doGetBean开始深入。这个方法一开始先调用getSingleton(beanName)检查缓存里是否有名为name的单例Bean缓存。</p><pre><code class="java">protected &lt;T&gt; T doGetBean( String name, @Nullable Class&lt;T&gt; requiredType, @Nullable Object[] args, boolean typeCheckOnly)            throws BeansException &#123;        String beanName = transformedBeanName(name);  Object bean;  // 获取已经注册的单例bean实例  Object sharedInstance = getSingleton(beanName);  // ...&#125;</code></pre><p>注意getSingleton(beanName)默认传入的allowEarlyReference参数为true。EarlyReference（早期引用）其实就是spring将还没有初始化完毕的单例bean放进缓存的bean引用，当发生循环依赖的时候，可以直接引用这个早期引用，而不会发生死循环不断地进行bean初始化。</p><pre><code class="java">@Override@Nullablepublic Object getSingleton(String beanName) &#123;  return getSingleton(beanName, true);&#125;@Nullableprotected Object getSingleton(String beanName, boolean allowEarlyReference) &#123;  // 从singletonObjects获取已经初始化完毕的单例对象  Object singletonObject = this.singletonObjects.get(beanName);  // 判断该bean是不是正在初始化的单例bean  if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123;    synchronized (this.singletonObjects) &#123;      // 从earlySingletonObjects中获取单例bean      singletonObject = this.earlySingletonObjects.get(beanName);      if (singletonObject == null &amp;&amp; allowEarlyReference) &#123;        // 从singletonFactories缓存里获取单例工厂对象        ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName);        if (singletonFactory != null) &#123;          // 通过单例工厂对象中获取早期单例bean对象，并缓存到earlySingletonObjects中          singletonObject = singletonFactory.getObject();          this.earlySingletonObjects.put(beanName, singletonObject);          this.singletonFactories.remove(beanName);        &#125;      &#125;    &#125;  &#125;  return singletonObject;&#125;public boolean isSingletonCurrentlyInCreation(String beanName) &#123;  return this.singletonsCurrentlyInCreation.contains(beanName);&#125;</code></pre><p>总结下，getSingleton的流程就是：</p><ul><li>如果该单例已经初始化完毕，直接返回；</li><li>如果是在建的单例，则尝试返回单例bean早期引用（也就是尚未构建完的半成品bean引用）；</li><li>如果有单例工厂对象，则使用该对象获取单例bean早期引用，加进缓存并返回；</li></ul><p>这里先记住这个几个缓存很重要，尤其关注singletonFactories，下文会用到它。</p><h3 id="检查prototype循环依赖"><a href="#检查prototype循环依赖" class="headerlink" title="检查prototype循环依赖"></a>检查prototype循环依赖</h3><p>上述检查单例如果返回null，则会进入Prototype的循环依赖检测：</p><pre><code class="java">Object sharedInstance = getSingleton(beanName);if (sharedInstance != null &amp;&amp; args == null) &#123;  // ...&#125; else &#123;  // prototype循环依赖检测  if (isPrototypeCurrentlyInCreation(beanName)) &#123;    throw new BeanCurrentlyInCreationException(beanName);  &#125;  // ...&#125;         </code></pre><p>这里检查到该bean是prototype，而且处于构建中状态，则意味着形成了循环依赖，直接抛异常终止初始化过程。</p><pre><code class="java">protected boolean isPrototypeCurrentlyInCreation(String beanName) &#123;  Object curVal = this.prototypesCurrentlyInCreation.get();  return (curVal != null &amp;&amp;      (curVal.equals(beanName) || (curVal instanceof Set &amp;&amp; ((Set&lt;?&gt;) curVal).contains(beanName))));&#125;</code></pre><p>检查方法很简单，通过名字相同来判断是否为同一个bean。注意因为是prototype，所以缓存字段prototypesCurrentlyInCreation可能为Set，包含多个bean实例。</p><p>因此我们知道，<strong>prototype的bean无论是构造器或者属性注入，都不允许实现循环依赖</strong>。</p><h3 id="构建不同类型的实例"><a href="#构建不同类型的实例" class="headerlink" title="构建不同类型的实例"></a>构建不同类型的实例</h3><p>根据bean类型，分别有各自的构建类型，分为单例、prototype和其他类型三种情况：</p><pre><code class="java">//单例if (mbd.isSingleton()) &#123;  sharedInstance = getSingleton(beanName, () -&gt; &#123;    try &#123;      return createBean(beanName, mbd, args);    &#125;    catch (BeansException ex) &#123;      // Explicitly remove instance from singleton cache: It might have been put there      // eagerly by the creation process, to allow for circular reference resolution.      // Also remove any beans that received a temporary reference to the bean.      destroySingleton(beanName);      throw ex;    &#125;  &#125;);  bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);&#125;// prototype类型else if (mbd.isPrototype()) &#123;  // It&#39;s a prototype -&gt; create a new instance.  Object prototypeInstance = null;  try &#123;    beforePrototypeCreation(beanName);    prototypeInstance = createBean(beanName, mbd, args);  &#125;  finally &#123;    afterPrototypeCreation(beanName);  &#125;  bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);&#125;// 其他类型else &#123;  String scopeName = mbd.getScope();  if (!StringUtils.hasLength(scopeName)) &#123;    throw new IllegalStateException(&quot;No scope name defined for bean ´&quot; + beanName + &quot;&#39;&quot;);  &#125;  Scope scope = this.scopes.get(scopeName);  if (scope == null) &#123;    throw new IllegalStateException(&quot;No Scope registered for scope name &#39;&quot; + scopeName + &quot;&#39;&quot;);  &#125;  try &#123;    Object scopedInstance = scope.get(beanName, () -&gt; &#123;      beforePrototypeCreation(beanName);      try &#123;        return createBean(beanName, mbd, args);      &#125;      finally &#123;        afterPrototypeCreation(beanName);      &#125;    &#125;);    bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd);  &#125;  catch (IllegalStateException ex) &#123;    throw new BeanCreationException(beanName,        &quot;Scope &#39;&quot; + scopeName + &quot;&#39; is not active for the current thread; consider &quot; +        &quot;defining a scoped proxy for this bean if you intend to refer to it from a singleton&quot;,        ex);  &#125;&#125;</code></pre><p>值得注意的是构建实例前，spring都会在缓存里标记该bean正常构建中。</p><p>比如单例类型在构建前会调用beforeSingletonCreation(beanName),该方法会把该beanName加入缓存中。在前一个章节 <em>《检查缓存的单例》</em> 中会使用这里的缓存来判断这个bean是否处于单例构建状态。注意这个方法，如果缓存里边已存在该bean，会抛出BeanCurrentlyInCreationException异常。<strong>这个异常正是在构造器循环依赖（单例）的时候抛出。</strong></p><pre><code class="java">protected void beforeSingletonCreation(String beanName) &#123;  if (!this.inCreationCheckExclusions.contains(beanName) &amp;&amp; !this.singletonsCurrentlyInCreation.add(beanName)) &#123;    throw new BeanCurrentlyInCreationException(beanName);  &#125;&#125;</code></pre><p>而prototype以及其他类型调用的是beforePrototypeCreation(beanName)，同样也是将beanName加入缓存：</p><pre><code class="java">protected void beforePrototypeCreation(String beanName) &#123;  Object curVal = this.prototypesCurrentlyInCreation.get();  if (curVal == null) &#123;    this.prototypesCurrentlyInCreation.set(beanName);  &#125;  else if (curVal instanceof String) &#123;    Set&lt;String&gt; beanNameSet = new HashSet&lt;&gt;(2);    beanNameSet.add((String) curVal);    beanNameSet.add(beanName);    this.prototypesCurrentlyInCreation.set(beanNameSet);  &#125;  else &#123;    Set&lt;String&gt; beanNameSet = (Set&lt;String&gt;) curVal;    beanNameSet.add(beanName);  &#125;&#125;</code></pre><p>这里用到的缓存prototypesCurrentlyInCreation，也正好呼应了是前一章 <em>《检查prototype循环依赖》</em>。</p><p>其他类型的bean和prototype类型相同。</p><p>因此，spring在构建bean之前都会在缓存里标记该bean处于构建中，所以当发生循环依赖的时候可以快速感知到。</p><h3 id="单例对象的早期引用"><a href="#单例对象的早期引用" class="headerlink" title="单例对象的早期引用"></a>单例对象的早期引用</h3><p>接上文，如果是单例对象，会调用匿名函数新建createBean进行单例bean构建：</p><pre><code class="java">if (mbd.isSingleton()) &#123;  sharedInstance = getSingleton(beanName, () -&gt; &#123;    try &#123;      return createBean(beanName, mbd, args);    &#125;    catch (BeansException ex) &#123;      // Explicitly remove instance from singleton cache: It might have been put there      // eagerly by the creation process, to allow for circular reference resolution.      // Also remove any beans that received a temporary reference to the bean.      destroySingleton(beanName);      throw ex;    &#125;  &#125;);&#125;</code></pre><p>createBean只是做一些构造前的准备，实际的构建过程在doCreateBean中。这很符合spring一贯的命名风格：</p><pre><code class="java">protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123;  /// ...  if (instanceWrapper == null) &#123;    instanceWrapper = createBeanInstance(beanName, mbd, args);  &#125;  Object bean = instanceWrapper.getWrappedInstance();  /// ...  // Eagerly cache singletons to be able to resolve circular references  // even when triggered by lifecycle interfaces like BeanFactoryAware.  boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp;      isSingletonCurrentlyInCreation(beanName));  if (earlySingletonExposure) &#123;    if (logger.isTraceEnabled()) &#123;      logger.trace(&quot;Eagerly caching bean &#39;&quot; + beanName +          &quot;&#39; to allow for resolving potential circular references&quot;);    &#125;    addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));  &#125;  // Initialize the bean instance.  Object exposedObject = bean;  try &#123;    populateBean(beanName, mbd, instanceWrapper);    exposedObject = initializeBean(beanName, exposedObject, mbd);  &#125;  /// ...&#125;</code></pre><p>doCreateBean比较长，上边只保留核心代码。可以看到主要包含三个步骤：</p><ul><li>1.调用createBeanInstance初始化一个半成品的bean，该方法中会寻找满足条件的构造函数进行bean的初始化；</li><li>2.如果是构建中的单例bean，并且允许循环依赖（默认允许），那么就会尝试调用addSingletonFactory方法提前曝光一个早期引用（也就是一个半成品bean）到缓存中；</li><li>3.调用populateBean、initializeBean，将半成品的bean进一步初始化，主要是处理属性注入等等；</li></ul><p>扼要地讲，步骤一处理了构造器注入；步骤二进行了半成品bean的早期引用曝光；步骤三进行了属性注入！</p><p>我们来看看早期引用曝光的逻辑：</p><pre><code class="java">protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123;  Assert.notNull(singletonFactory, &quot;Singleton factory must not be null&quot;);  synchronized (this.singletonObjects) &#123;    if (!this.singletonObjects.containsKey(beanName)) &#123;      this.singletonFactories.put(beanName, singletonFactory);      this.earlySingletonObjects.remove(beanName);      this.registeredSingletons.add(beanName);    &#125;  &#125;&#125;</code></pre><p>我们看到singletonFactories中会缓存一个工厂对象ObjectFactory，而这个ObjectFactory的getObject方法正是可以返回一个处于构建中半成品bean对象引用。</p><p>我们在前边已经讲到，单例对象构建中如果发现出现循环依赖，会尝试从单例的工厂对象中获得一个早期bean对象，并返回，从而避免循环依赖出现死循环。我们再来回忆下：</p><pre><code class="java">@Nullableprotected Object getSingleton(String beanName, boolean allowEarlyReference) &#123;  // 从singletonObjects获取已经初始化完毕的单例对象  Object singletonObject = this.singletonObjects.get(beanName);  // 判断该bean是不是正在初始化的单例bean  if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123;    synchronized (this.singletonObjects) &#123;      // 从earlySingletonObjects中获取单例bean      singletonObject = this.earlySingletonObjects.get(beanName);      if (singletonObject == null &amp;&amp; allowEarlyReference) &#123;        // 从singletonFactories缓存里获取单例工厂对象        ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName);        if (singletonFactory != null) &#123;          // 通过单例工厂对象中获取早期单例bean对象，并缓存到earlySingletonObjects中          singletonObject = singletonFactory.getObject();          this.earlySingletonObjects.put(beanName, singletonObject);          this.singletonFactories.remove(beanName);        &#125;      &#125;    &#125;  &#125;  return singletonObject;&#125;</code></pre><p>因此看到这里你就应该明白，<strong>单例对象的构造器注入没有进行早期引用曝光，所以是不能实现循环依赖的！但是单例对象的属性注入是先进行了早期引用曝光，在进行属性注入，所以是支持循环依赖的！</strong></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要是探讨spring对循环依赖的处理策略和实现原理。我们认识到spring只支持单例对象的属性注入循环依赖，而其他类型的循环依赖都不支持。</p>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 源码分析 </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Netty 源码分析之 六 流水线处理器: Handler</title>
      <link href="/2020/07/15/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E5%85%AD-%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%A4%84%E7%90%86%E5%99%A8-Handler/"/>
      <url>/2020/07/15/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E5%85%AD-%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%A4%84%E7%90%86%E5%99%A8-Handler/</url>
      
        <content type="html"><![CDATA[<p>本文是永顺大牛写的系列教程<a href="https://segmentfault.com/a/1190000007282628#comment-area">《源码之下无秘密 ── 做最好的 Netty 源码分析教程》</a>的续写章节。本章主要介绍Netty中用来处理数据流的handler以及底层原理。</p><span id="more"></span><h2 id="写在最前"><a href="#写在最前" class="headerlink" title="写在最前"></a>写在最前</h2><p>永顺前辈已写完的章节有如下：</p><ul><li><a href="https://segmentfault.com/a/1190000006824091">Netty 源码分析之 番外篇 Java NIO 的前生今世</a></li><li><a href="https://segmentfault.com/a/1190000007282597">Netty 源码分析之 零 磨刀不误砍柴工 源码分析环境搭建</a></li><li><a href="https://segmentfault.com/a/1190000007282789">Netty 源码分析之 一 揭开 Bootstrap 神秘的红盖头 (客户端)</a></li><li><a href="https://segmentfault.com/a/1190000007283053">Netty 源码分析之 一 揭开 Bootstrap 神秘的红盖头 (服务器端)</a></li><li><a href="https://segmentfault.com/a/1190000007308934">Netty 源码分析之 二 贯穿 Netty 的大动脉 ── ChannelPipeline (一)</a></li><li><a href="https://segmentfault.com/a/1190000007309311">Netty 源码分析之 二 贯穿 Netty 的大动脉 ── ChannelPipeline (二)</a></li><li><a href="https://segmentfault.com/a/1190000007403873">Netty 源码分析之 三 我就是大名鼎鼎的 EventLoop(一)</a></li><li><a href="https://segmentfault.com/a/1190000007403937">Netty 源码分析之 三 我就是大名鼎鼎的 EventLoop(二)</a></li></ul><p>笔者尝试续写的章节：</p><ul><li><a href="https://blog.duval.top/2020/07/04/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E5%9B%9B-Promise-%E4%B8%8E-Future-%E5%8F%8C%E5%AD%90%E6%98%9F%E7%9A%84%E7%A7%98%E5%AF%86/">Netty 源码分析之 四 Promise 与 Future: 双子星的秘密</a></li><li><a href="https://blog.duval.top/2020/07/09/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E4%BA%94-%E5%A5%94%E8%85%BE%E7%9A%84%E8%A1%80%E6%B6%B2-ByteBuf/">Netty 源码分析之 五 奔腾的血液: ByteBuf</a></li><li><a href="https://blog.duval.top/2020/07/15/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E5%85%AD-%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%A4%84%E7%90%86%E5%99%A8-Handler/">Netty 源码分析之 六 流水线处理器: Handler</a></li></ul><p><em>本文使用的netty版本为4.1.33.Final</em></p><h2 id="回忆handler"><a href="#回忆handler" class="headerlink" title="回忆handler"></a>回忆handler</h2><h3 id="链式结构"><a href="#链式结构" class="headerlink" title="链式结构"></a>链式结构</h3><p>我们先来回忆下在<a href="https://segmentfault.com/a/1190000007308934">《Netty 源码分析之 二 贯穿 Netty 的大动脉 ── ChannelPipeline (一)》</a>提到过来的handler链式结构：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FNetty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%20%E5%85%AD%20Handler%20%E7%9A%84%E5%90%84%E7%A7%8D%E5%A7%BF%E5%8A%BF%2FNettyHandler%E9%93%BE%E5%BC%8F%E7%BB%93%E6%9E%84.png" alt="NettyHandler链式结构.png"></p><ul><li>handler分为实现ChannelInboundHandler接口的入站处理器和实现ChannelOutboundHandler接口的出站处理器；</li><li>handler由DefaultChannelHandlerContext进行包装，并组成一个双向链表；</li><li>所有的入站操作从HeadContext出发，沿着链表经由每一个入站处理器处理后向TailContext方向传递；</li><li>所有的出站操作从TailContext出发，沿着链表经由每一个出站处理器处理后向HeadContext方向传递；</li><li>无论是入站操作抑或是出站操作的传递，都可以在handler中按照业务需求被中断或者改变传递方向。</li></ul><p>本文的封面图使用了一张流水线卡通图，正因为这个链式结构非常类似于制造业里的流水线，handler就像是流水里的处理节点，而入站出站数据就如同流水线上被加工的产品。</p><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>一个常见的客户端初始化过程是这个样子的：</p><pre><code class="java">      Bootstrap bootstrap = new Bootstrap();        ChannelFuture future = bootstrap.group(new NioEventLoopGroup(10))                .channel(NioSocketChannel.class)                .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;                    @Override                    protected void initChannel(SocketChannel ch) throws Exception &#123;                        // 管道中添加基于换行符分割字符串的解析器                        ch.pipeline().addLast(new LineBasedFrameDecoder(1024));                        // 管道中添加字符串编码解码器                        ch.pipeline().addLast(new StringDecoder(Charset.forName(&quot;UTF-8&quot;)));                        ch.pipeline().addLast(new StringEncoder(Charset.forName(&quot;UTF-8&quot;)));                        // 管道中添加服务端处理逻辑                        ch.pipeline().addLast(new MyClientEchoHandler());                    &#125;                &#125;).connect(&quot;127.0.0.1&quot;, 9898).sync();    future.channel().closeFuture().sync();</code></pre><p>在ChannelInitializer的实现方法中，调用ch.pipeline().addLast方法，不断地将handler追加到双向链表中（TailContext之前），从而形成上图所示的双向链表结构。</p><h2 id="入站handler"><a href="#入站handler" class="headerlink" title="入站handler"></a>入站handler</h2><p>入站handler都实现了ChannelInboundHandler接口：</p><pre><code class="java">public interface ChannelInboundHandler extends ChannelHandler &#123;    void channelRegistered(ChannelHandlerContext ctx) throws Exception;    void channelUnregistered(ChannelHandlerContext ctx) throws Exception;    void channelActive(ChannelHandlerContext ctx) throws Exception;    void channelInactive(ChannelHandlerContext ctx) throws Exception;    void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception;    void channelReadComplete(ChannelHandlerContext ctx) throws Exception;    void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception;    void channelWritabilityChanged(ChannelHandlerContext ctx) throws Exception;    @Override    @SuppressWarnings(&quot;deprecation&quot;)    void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception;&#125;</code></pre><p>该接口内定义了常见的入站操作包括channelActive、channelRead、channelInactive等，还支持用户自定义入站操作userEventTriggered。</p><p>ChannelInboundHandlerAdapter是ChannelInboundHandler接口的一个默认实现，内部所有方法都是将入站操作往后传递，不作任何业务处理，如channelRead方法：</p><pre><code class="java">    @Override    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;        ctx.fireChannelRead(msg);    &#125;</code></pre><p>ChannelInboundHandlerAdapter并没有包含任何业务逻辑，用户的handler子类可以继承它，然后覆盖并实现其中的部分方法。下文要提到的<strong>SimpleChannelInboundHandler</strong>以及<strong>ByteToMessageDecoder</strong>正是其中两个案例。</p><h2 id="出站handler"><a href="#出站handler" class="headerlink" title="出站handler"></a>出站handler</h2><p>出站handler都实现了ChannelOutboundHandler接口，并提供常见的出站操作（bind、connect、close、write、flush等等）：</p><pre><code class="java">public interface ChannelOutboundHandler extends ChannelHandler &#123;    void bind(ChannelHandlerContext ctx, SocketAddress localAddress, ChannelPromise promise) throws Exception;    void connect(ChannelHandlerContext ctx, SocketAddress remoteAddress,            SocketAddress localAddress, ChannelPromise promise) throws Exception;    void disconnect(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception;    void close(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception;    void deregister(ChannelHandlerContext ctx, ChannelPromise promise) throws Exception;    void read(ChannelHandlerContext ctx) throws Exception;    void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception;    void flush(ChannelHandlerContext ctx) throws Exception;&#125;</code></pre><p>类似地，ChannelOutboundHandlerAdapter是该接口的一个默认实现，内部所有方法都是将出站操作往前传递，不作任何业务处理，如write方法：</p><pre><code class="java">    @Override    public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception &#123;        ctx.write(msg, promise);    &#125;</code></pre><p>同样地，子类可以继承ChannelOutboundHandlerAdapter，并覆盖实现其中的任何方法。MessageToByteEncoder和MessageToMessageEncoder这两个编码器是常见的实现子类。</p><h2 id="解码器decoder"><a href="#解码器decoder" class="headerlink" title="解码器decoder"></a>解码器decoder</h2><p>解码器是典型的入站处理器。解码器处理的入站数据结构一般是ByteBuf。</p><h3 id="ByteToMessageDecoder"><a href="#ByteToMessageDecoder" class="headerlink" title="ByteToMessageDecoder"></a>ByteToMessageDecoder</h3><p>例如ByteToMessageDecoder，可以从ByteBuf这种字节流中读取数据，然后转换为其他形式的消息对象（也可以是ByteBuf）。</p><pre><code class="java">     @Override    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;        if (msg instanceof ByteBuf) &#123;            // 仅处理ByteBuf对象            // 新建out列表，用于保存解码得到的对象列表            CodecOutputList out = CodecOutputList.newInstance();            try &#123;                ByteBuf data = (ByteBuf) msg;                first = cumulation == null;                if (first) &#123;                    cumulation = data;                &#125; else &#123;                    cumulation = cumulator.cumulate(ctx.alloc(), cumulation, data);                &#125;                // 调用解码实现方法                callDecode(ctx, cumulation, out);            &#125; catch (DecoderException e) &#123;                throw e;            &#125; catch (Exception e) &#123;                throw new DecoderException(e);            &#125; finally &#123;                if (cumulation != null &amp;&amp; !cumulation.isReadable()) &#123;                    numReads = 0;                    cumulation.release();                    cumulation = null;                &#125; else if (++ numReads &gt;= discardAfterReads) &#123;                    // We did enough reads already try to discard some bytes so we not risk to see a OOME.                    // See https://github.com/netty/netty/issues/4275                    numReads = 0;                    discardSomeReadBytes();                &#125;                int size = out.size();                decodeWasNull = !out.insertSinceRecycled();                // 调用fireChannelRead传递解码得到的对象列表out                fireChannelRead(ctx, out, size);                // 回收对象                out.recycle();            &#125;        &#125; else &#123;            ctx.fireChannelRead(msg);        &#125;    &#125;</code></pre><pre><code class="java">    protected void callDecode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) &#123;        try &#123;            while (in.isReadable()) &#123;                // ...省略部分代码...                decodeRemovalReentryProtection(ctx, in, out);                // ...省略部分代码...            &#125;        &#125; catch (DecoderException e) &#123;             throw e;        &#125; catch (Exception cause) &#123;             throw new DecoderException(cause);        &#125;     &#125;     final void decodeRemovalReentryProtection(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123;        decodeState = STATE_CALLING_CHILD_DECODE;        try &#123;            decode(ctx, in, out);        &#125; finally &#123;            boolean removePending = decodeState == STATE_HANDLER_REMOVED_PENDING;            decodeState = STATE_INIT;            if (removePending) &#123;                handlerRemoved(ctx);            &#125;        &#125;    &#125;</code></pre><p>可见callDecode内部持续循环消费字节流，然后底层调用了子类实现的抽象方法decode进行解码。其中，常见的实现类有LineBasedFrameDecoder。</p><h3 id="LineBasedFrameDecoder"><a href="#LineBasedFrameDecoder" class="headerlink" title="LineBasedFrameDecoder"></a>LineBasedFrameDecoder</h3><p>LineBasedFrameDecoder实现了根据一个ByteBuf以换行符分割为多个ByteBuf的功能，核心实现如下：</p><pre><code class="java">    @Override    protected final void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123;        // 解码得到的对象都放out列表中        Object decoded = decode(ctx, in);        if (decoded != null) &#123;            out.add(decoded);        &#125;    &#125;    protected Object decode(ChannelHandlerContext ctx, ByteBuf buffer) throws Exception &#123;        final int eol = findEndOfLine(buffer);        if (!discarding) &#123;            if (eol &gt;= 0) &#123;                // 如果找到换行符                final ByteBuf frame;                // 计算当前帧的长度以及分隔符长度                final int length = eol - buffer.readerIndex();                final int delimLength = buffer.getByte(eol) == &#39;\r&#39;? 2 : 1;                    if (length &gt; maxLength) &#123;                    // 如果该帧长度大于最大长度，则抛异常                    buffer.readerIndex(eol + delimLength);                    fail(ctx, length);                    return null;                &#125;                if (stripDelimiter) &#123;                    // frame去掉分隔符                    frame = buffer.readRetainedSlice(length);                    buffer.skipBytes(delimLength);                &#125; else &#123;                    // frame包含分隔符                    frame = buffer.readRetainedSlice(length + delimLength);                &#125;                return frame;            &#125; else &#123;                final int length = buffer.readableBytes();                if (length &gt; maxLength) &#123;                    // 如果没有换行符，而且该帧长度大于最大长度                    // 则标记discarding为true，且丢弃所有可读数据                    discardedBytes = length;                    buffer.readerIndex(buffer.writerIndex());                    discarding = true;                    offset = 0;                    if (failFast) &#123;                        fail(ctx, &quot;over &quot; + discardedBytes);                    &#125;                &#125;                return null;            &#125;        &#125; else &#123;            if (eol &gt;= 0) &#123;                // 如果有换行符，丢弃换行符前的所有可读数据                final int length = discardedBytes + eol - buffer.readerIndex();                final int delimLength = buffer.getByte(eol) == &#39;\r&#39;? 2 : 1;                buffer.readerIndex(eol + delimLength);                discardedBytes = 0;                discarding = false;                if (!failFast) &#123;                    fail(ctx, length);                &#125;            &#125; else &#123;                // 如果没有换行符，丢弃所有可读数据                discardedBytes += buffer.readableBytes();                buffer.readerIndex(buffer.writerIndex());                // We skip everything in the buffer, we need to set the offset to 0 again.                offset = 0;            &#125;            return null;        &#125;    &#125;     private int findEndOfLine(final ByteBuf buffer) &#123;        int totalLength = buffer.readableBytes();        // 找到换行符\n所在的下标        int i = buffer.forEachByte(buffer.readerIndex() + offset, totalLength - offset, ByteProcessor.FIND_LF);        if (i &gt;= 0) &#123;            offset = 0;            // 某些系统以\r\n作为换行符，这里修改下标为\r的下标            if (i &gt; 0 &amp;&amp; buffer.getByte(i - 1) == &#39;\r&#39;) &#123;                i--;            &#125;        &#125; else &#123;            offset = totalLength;        &#125;        return i;    &#125;</code></pre><h3 id="MessageToMessageDecoder"><a href="#MessageToMessageDecoder" class="headerlink" title="MessageToMessageDecoder"></a>MessageToMessageDecoder</h3><p>上一小节的ByteToMessageDecoder实现了从ByteBuf到消息对象的解码转换，而MessageToMessageDecoder可以实现消息之间的解码转换。核心实现如下：</p><pre><code class="java"> @Override    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;        CodecOutputList out = CodecOutputList.newInstance();        try &#123;            // 检查msg是否满足指定的模板类型I            if (acceptInboundMessage(msg)) &#123;                @SuppressWarnings(&quot;unchecked&quot;)                I cast = (I) msg;                try &#123;                    // 调用decode抽象方法                    decode(ctx, cast, out);                &#125; finally &#123;                    ReferenceCountUtil.release(cast);                &#125;            &#125; else &#123;                out.add(msg);            &#125;        &#125; catch (DecoderException e) &#123;            throw e;        &#125; catch (Exception e) &#123;            throw new DecoderException(e);        &#125; finally &#123;            int size = out.size();            for (int i = 0; i &lt; size; i ++) &#123;                ctx.fireChannelRead(out.getUnsafe(i));            &#125;            out.recycle();        &#125;    &#125;    /**     * Decode from one message to an other. This method will be called for each written message that can be handled     * by this decoder.     *     * @param ctx           the &#123;@link ChannelHandlerContext&#125; which this &#123;@link MessageToMessageDecoder&#125; belongs to     * @param msg           the message to decode to an other one     * @param out           the &#123;@link List&#125; to which decoded messages should be added     * @throws Exception    is thrown if an error occurs     */    protected abstract void decode(ChannelHandlerContext ctx, I msg, List&lt;Object&gt; out) throws Exception;</code></pre><p>MessageToMessageDecoder里的业务非常少，核心的解码转换逻辑还需要子类去实现。常用的实现类有StringDecoder。</p><h3 id="StringDecoder"><a href="#StringDecoder" class="headerlink" title="StringDecoder"></a>StringDecoder</h3><p>StringDecoder非常简单，输入模板类型ByteBuf，然后转换为String。核心解码转换方法如下：</p><pre><code class="java">@Overrideprotected void decode(ChannelHandlerContext ctx, ByteBuf msg, List&lt;Object&gt; out) throws Exception &#123;    out.add(msg.toString(charset));&#125;</code></pre><h2 id="编码器encoder"><a href="#编码器encoder" class="headerlink" title="编码器encoder"></a>编码器encoder</h2><p>编码器是典型的出站处理器。同时，也分为MessageToMessageEncoder和MessageToByteEncoder两种。其功能和实现刚好是解码器的逆过程，所以这里不再详细分析，不然本文就沦为水文一篇了。</p><p>此外，类似地，StringEncoder也是StringDecoder的逆过程，实现也非常简单此处不作赘言。</p><h2 id="SimpleChannelInboundHandler"><a href="#SimpleChannelInboundHandler" class="headerlink" title="SimpleChannelInboundHandler"></a>SimpleChannelInboundHandler</h2><p>用户自定义handler的时候最常用到的父类是SimpleChannelInboundHandler。相比ChannelInboundHandlerAdapter，它为用户做了消息对象的数据类型强制转换，方便数据处理，并且确保消息对象被释放掉。核心实现如下：</p><pre><code class="java">    @Override    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123;        boolean release = true;        try &#123;            if (acceptInboundMessage(msg)) &#123;                // 类型强制转换                @SuppressWarnings(&quot;unchecked&quot;)                I imsg = (I) msg;                channelRead0(ctx, imsg);            &#125; else &#123;                release = false;                ctx.fireChannelRead(msg);            &#125;        &#125; finally &#123;            if (autoRelease &amp;&amp; release) &#123;                ReferenceCountUtil.release(msg);            &#125;        &#125;    &#125;    protected abstract void channelRead0(ChannelHandlerContext ctx, I msg) throws Exception;</code></pre><p>用户需要实现channelRead0方法，自定义业务逻辑。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后以一张类图温习本文：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FNetty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%20%E5%85%AD%20Handler%20%E7%9A%84%E5%90%84%E7%A7%8D%E5%A7%BF%E5%8A%BF%2FNetty%20Handler%E7%B1%BB%E5%9B%BE.png" alt="Netty Handler类图.png"></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Netty </tag>
            
            <tag> 源码分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Netty 源码分析之 五 奔腾的血液: ByteBuf</title>
      <link href="/2020/07/09/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E4%BA%94-%E5%A5%94%E8%85%BE%E7%9A%84%E8%A1%80%E6%B6%B2-ByteBuf/"/>
      <url>/2020/07/09/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E4%BA%94-%E5%A5%94%E8%85%BE%E7%9A%84%E8%A1%80%E6%B6%B2-ByteBuf/</url>
      
        <content type="html"><![CDATA[<p>本文是永顺大牛写的系列教程<a href="https://segmentfault.com/a/1190000007282628#comment-area">《源码之下无秘密 ── 做最好的 Netty 源码分析教程》</a>的续写章节。本章主要介绍Netty中用来承接数据的ByteBuf的底层实现原理。</p><span id="more"></span><h2 id="写在最前"><a href="#写在最前" class="headerlink" title="写在最前"></a>写在最前</h2><p>永顺前辈已写完的章节有如下：</p><ul><li><a href="https://segmentfault.com/a/1190000006824091">Netty 源码分析之 番外篇 Java NIO 的前生今世</a></li><li><a href="https://segmentfault.com/a/1190000007282597">Netty 源码分析之 零 磨刀不误砍柴工 源码分析环境搭建</a></li><li><a href="https://segmentfault.com/a/1190000007282789">Netty 源码分析之 一 揭开 Bootstrap 神秘的红盖头 (客户端)</a></li><li><a href="https://segmentfault.com/a/1190000007283053">Netty 源码分析之 一 揭开 Bootstrap 神秘的红盖头 (服务器端)</a></li><li><a href="https://segmentfault.com/a/1190000007308934">Netty 源码分析之 二 贯穿 Netty 的大动脉 ── ChannelPipeline (一)</a></li><li><a href="https://segmentfault.com/a/1190000007309311">Netty 源码分析之 二 贯穿 Netty 的大动脉 ── ChannelPipeline (二)</a></li><li><a href="https://segmentfault.com/a/1190000007403873">Netty 源码分析之 三 我就是大名鼎鼎的 EventLoop(一)</a></li><li><a href="https://segmentfault.com/a/1190000007403937">Netty 源码分析之 三 我就是大名鼎鼎的 EventLoop(二)</a></li></ul><p>笔者尝试续写的章节：</p><ul><li><a href="https://blog.duval.top/2020/07/04/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E5%9B%9B-Promise-%E4%B8%8E-Future-%E5%8F%8C%E5%AD%90%E6%98%9F%E7%9A%84%E7%A7%98%E5%AF%86/">Netty 源码分析之 四 Promise 与 Future: 双子星的秘密</a></li><li><a href="https://blog.duval.top/2020/07/09/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E4%BA%94-%E5%A5%94%E8%85%BE%E7%9A%84%E8%A1%80%E6%B6%B2-ByteBuf/">Netty 源码分析之 五 奔腾的血液: ByteBuf</a></li><li><a href="https://blog.duval.top/2020/07/15/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E5%85%AD-%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%A4%84%E7%90%86%E5%99%A8-Handler/">Netty 源码分析之 六 流水线处理器: Handler</a></li></ul><p><em>本文使用的netty版本为4.1.33.Final</em></p><h2 id="ByteBuf与ByteBuffer"><a href="#ByteBuf与ByteBuffer" class="headerlink" title="ByteBuf与ByteBuffer"></a>ByteBuf与ByteBuffer</h2><p>我们在<a href="https://segmentfault.com/a/1190000006824155">《Java NIO 的前生今世 之三 NIO Buffer 详解》</a>以及<a href="https://blog.duval.top/2020/05/14/%E8%AE%A4%E8%AF%86Java-NIO/">《认识 Java NIO》</a>已经详细了解了NIO Buffer。这里先回忆下NIO Buffer的一些特性：</p><ul><li>ByteBuffer底层实现包含四个关键字段，并满足大小关系：mark &lt;&#x3D; position &lt;&#x3D; limit &lt;&#x3D; capacity；</li><li>ByteBuffer存在写模式和读模式两种状态，内部方法可以触发状态切换，比如flip方法从写状态切换为读状态；</li><li>不同类型的ByteBuffer支持不同的数据类型，包括ByteBuffer、ShortBuffer、CharBuffer、DoubleBuffer、FloatBuffer、IntBuffer等类型。</li></ul><p>Netty的ByteBuf的底层实现有些许类似，但相比ByteBuffer实现了非常多扩展，并摒弃了一些不足：</p><ul><li>不区分读写状态，不需要切换状态；</li><li>支持池化，避免频繁的GC回收；</li><li>支持引用计数；</li><li>类型兼容（同一个ByteBuf可以承载各种数据类型）；</li><li>支持Unsafe操作的ByteBuf；</li><li>支持堆外和堆内两种ByteBuf；</li><li>支持零拷贝的复合类型CompositeByteBuf；</li><li>…</li></ul><h2 id="ByteBuf继承关系"><a href="#ByteBuf继承关系" class="headerlink" title="ByteBuf继承关系"></a>ByteBuf继承关系</h2><p>我们先来看看ByteBuf的类图：<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FNetty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%20%E4%BA%94%20%E5%A5%94%E8%85%BE%E7%9A%84%E8%A1%80%E6%B6%B2%3A%20ByteBuf%2Fclass-diagram.png" alt="class-diagram.png"></p><p>ByteBuf以及其子类的命名非常规整，仅从名字上我们就可以将各个子类划分为以下几类：</p><ul><li>池化和非池化的ByteBuf，例如：PooledHeapByteBuf 和 UnpooledHeapByteBuf；</li><li>含Unsafe操作的ByteBuf，例如：PooledUnsafeHeapByteBuf;</li><li>分片类型的ByteBuf，例如：PooledSliceByteBuf和PooledDuplicatedByteBuf；</li><li>组合ByteBuf，例如：CompositeBuf;</li><li>实现了引用计数的ByteBuf。</li></ul><p>以上各种类型的都会在下文展开分析。</p><h2 id="ByteBuf的读写指针"><a href="#ByteBuf的读写指针" class="headerlink" title="ByteBuf的读写指针"></a>ByteBuf的读写指针</h2><p>类似NIO ByteBuffer，ByteBuf底层实现也是字节数组，也同样由读写指针来控制读写位置。在ByteBuf的继承类AbstractByteBuf中定义了以下读写指针字段：</p><pre><code class="java">    // 当前读指针    int readerIndex;    // 当前写指针    int writerIndex;    // 暂存的读指针    private int markedReaderIndex;    // 暂存的写指针    private int markedWriterIndex;    // 最大容量    private int maxCapacity;</code></pre><p>需要注意的事maxCapacity是对底层字节数组进行扩容的最大容量，并不是当前容量capacity。通过这几个指针，其实可以将字节数组划分为以下几部分：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FNetty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%20%E4%BA%94%20%E5%A5%94%E8%85%BE%E7%9A%84%E8%A1%80%E6%B6%B2%3A%20ByteBuf%2FByteBuf%E8%AF%BB%E5%86%99%E6%8C%87%E9%92%88.png" alt="ByteBuf读写指针.png"></p><p>有如下性质：</p><ul><li>每读取一个字节，readerIndex递增1；直到readerIndex等于writerIndex，表示ByteBuf已经不可读；</li><li>每写入一个字节，writerIndex递增1；直到writerIndex等于capacity，表示ByteBuf已经不可写；</li><li>当writerIndex等于capacity表示底层字节数组需要扩容，且最大扩容不能超过max capacity。</li></ul><p>有如上性质，可以推出以下ByteBuf的一些方法实现：</p><ul><li>readableBytes()：可读字节数 –&gt; this.writerIndex - this.readerIndex</li><li>writableBytes()：可写字节数 –&gt; this.capacity - this.writerIndex</li><li>isReadable()：是否可读 –&gt; this.writerIndex - this.readerIndex &gt; 0</li><li>isWritable()：是否可写 –&gt; this.capacity - this.writerIndex &gt; 0</li></ul><p>更多方法见下。</p><h2 id="ByteBuf接口常用方法"><a href="#ByteBuf接口常用方法" class="headerlink" title="ByteBuf接口常用方法"></a>ByteBuf接口常用方法</h2><p>ByteBuf继承了Comparable和RefrenceCounted，其中后者是支持引用计数的接口，它的核心方法包含两个：</p><pre><code class="java">    // 引用数加1    ReferenceCounted retain();    // 引用数减1，如果引用数减为0，则释放该对象。    // 如果该对象被释放则返回true，否则返回false。    // 注意：子类实现其实是减2，后文会提到。    boolean release();</code></pre><p>再来看ByteBuf的核心方法：</p><ul><li>容量有关方法</li></ul><pre><code class="java">    // 1.返回当前容量    public abstract int capacity();    // 2.调整当前容量    public abstract ByteBuf capacity(int newCapacity);    // 3.最大容量（capacity的最大上限）    public abstract int maxCapacity();</code></pre><p>注意 capacity() &lt;&#x3D; maxCapacity()。</p><ul><li>读写指针有关方法</li></ul><pre><code class="java">    // 读写指针相关方法    // 1.获取当前读指针    public abstract int readerIndex();    // 2.设置当前读指针    public abstract ByteBuf readerIndex(int readerIndex);    // 3.获取当前写指针    public abstract int writerIndex();    // 4.设置当前写指针    public abstract ByteBuf writerIndex(int writerIndex);    // 5.同时设置读写指针    public abstract ByteBuf setIndex(int readerIndex, int writerIndex);    // 6.获取可读字节数(this.writerIndex - this.readerIndex)    public abstract int readableBytes();    // 7.获取可写字节数(this.capacity - this.writerIndex)    public abstract int writableBytes();    // 8.获取最大可写字节数 (this.maxCapacity - this.writerIndex)&#125;    public abstract int maxWritableBytes();    // 9.是否可读(this.writerIndex - this.readerIndex)    public abstract boolean isReadable();    // 10.是否可写(this.capacity - this.writerIndex)    public abstract boolean isWritable();    // 11.清空(相当于setIndex(0, 0))    public abstract ByteBuf clear();    // 12.记录读指针    public abstract ByteBuf markReaderIndex();    // 13.从记录中恢复读指针    public abstract ByteBuf resetReaderIndex();    // 14.记录写指针     public abstract ByteBuf markWriterIndex();    // 15.从记录中恢复写指针    public abstract ByteBuf resetWriterIndex();    // 16.丢弃已读字节    public abstract ByteBuf discardReadBytes();</code></pre><p>上述方法都是围绕着readerIndex、writerIndex、capital、maxcapital等四个值衍生的方法。实现都非常类似而简单。</p><ul><li>随机读写数据有关方法</li></ul><pre><code class="java">    // 随机读写数据    // ... 这部分类似的方法非常多，以下只列举一部分 ...    // 1.从指定位置读取数据    public abstract boolean getBoolean(int index);    public abstract short getUnsignedByte(int index);    public abstract short getShort(int index);    public abstract int getUnsignedShort(int index);    public abstract int   getInt(int index);    public abstract long  getLong(int index);    public abstract double getDouble(int index);    public abstract short getShortLE(int index);（LE：Little Endian byte order，表示小端序，下同）    public abstract int   getIntLE(int index);    public abstract long  getLongLE(int index);    // 略...    // 2.在指定位置写入数据    public abstract ByteBuf setBoolean(int index, boolean value);    public abstract ByteBuf setByte(int index, int value);    public abstract ByteBuf setShortLE(int index, int value);    public abstract ByteBuf setInt(int index, int value);    public abstract ByteBuf setIntLE(int index, int value);    // 略... </code></pre><p>上述方法支持指定位置的读写数据，其中读数据并不会改变指针值。</p><ul><li>顺序读写数据有关方法。</li></ul><pre><code class="java">    // 1. 在readerIndex位置读取数据并移动指针    public abstract boolean readBoolean();    public abstract byte  readByte();    public abstract short readShort();    public abstract short readShortLE();    public abstract int   readInt();    public abstract int   readIntLE();    // 略...    // 2. 在位置写入数据并移动指针    public abstract ByteBuf writeBoolean(boolean value);    public abstract ByteBuf writeByte(int value);    public abstract ByteBuf writeShort(int value);    public abstract ByteBuf writeShortLE(int value);    public abstract ByteBuf writeInt(int value);    public abstract ByteBuf writeIntLE(int value);    // 略...</code></pre><p>上述方法从读(或写)指针位置顺序往后读(或写)数据，并移动读(或写)指针。</p><ul><li>分片相关方法</li></ul><pre><code class="java">    public abstract ByteBuf slice();    public abstract ByteBuf slice(int index, int length);    public abstract ByteBuf duplicate();    public abstract ByteBuf retainedSlice(); // 更新引用计数    public abstract ByteBuf retainedDuplicate(); // 更新引用计数</code></pre><p>ByteBuf支持分片获取，实现快速的低成本浅复制。</p><ul><li>其他方法</li></ul><pre><code class="java">    // 判断底层是否为NIO direct buffer    public abstract boolean isDirect();</code></pre><h2 id="ByteBuf浅复制实现"><a href="#ByteBuf浅复制实现" class="headerlink" title="ByteBuf浅复制实现"></a>ByteBuf浅复制实现</h2><p>上一节我们提到了ByteBuf支持浅复制分片，其中分为slice浅复制和duplicate浅复制。duplicate与slice的区别是，duplicate是对整个ByteBuf的浅复制，而slice只是对ByteBuf中的一部分进行浅复制。</p><p>ByteBuf的浅复制分片其实就是与原来的ByteBuf共享同一个存储空间，并且也可以被多个分片同时共享。以slice(int index, int length)方法为例：</p><pre><code class="java">    // io.netty.buffer.AbstractByteBuf.java    @Override    public ByteBuf slice(int index, int length) &#123;        ensureAccessible();        return new UnpooledSlicedByteBuf(this, index, length);    &#125;</code></pre><p>slice方法内非常简单，只是新建了一个分片对象<em>UnpooledSlicedByteBuf</em>，构造函数传入了当前ByteBuf（this）、开始索引（index）以及分片长度（length）；</p><p>在父类的构造行数里，对该分片对象进行了初始化：</p><pre><code class="java">    // 被分片的ByteBuf    private final ByteBuf buffer;    // 偏移量    private final int adjustment;    AbstractUnpooledSlicedByteBuf(ByteBuf buffer, int index, int length) &#123;        super(length);        checkSliceOutOfBounds(index, length, buffer);        if (buffer instanceof AbstractUnpooledSlicedByteBuf) &#123;            // 如果传入的是slice分片，则需要叠加其偏移量            this.buffer = ((AbstractUnpooledSlicedByteBuf) buffer).buffer;            adjustment = ((AbstractUnpooledSlicedByteBuf) buffer).adjustment + index;        &#125; else if (buffer instanceof DuplicatedByteBuf) &#123;            // 如果传入的是dulicated分片，不需要叠加(因为其偏移量为0)            this.buffer = buffer.unwrap();            adjustment = index;        &#125; else &#123;            this.buffer = buffer;            adjustment = index;        &#125;        // 初始化当前最大容量，对分片来说，最大容量不能超过length        initLength(length);        // 初始化写指针        writerIndex(length);    &#125;</code></pre><p>可见，slice分片仅仅是对原ByteBuf进行了一层封装，并没有发生任何内存复制行为，所以是非常高效快捷的操作。</p><p>与slice类似，duplicate也是如此手法。唯一不同是，duplicate是对整个ByteBuf进行浅复制：</p><pre><code class="java">    public DuplicatedByteBuf(ByteBuf buffer) &#123;        this(buffer, buffer.readerIndex(), buffer.writerIndex());    &#125;    DuplicatedByteBuf(ByteBuf buffer, int readerIndex, int writerIndex) &#123;        super(buffer.maxCapacity());        if (buffer instanceof DuplicatedByteBuf) &#123;            this.buffer = ((DuplicatedByteBuf) buffer).buffer;        &#125; else if (buffer instanceof AbstractPooledDerivedByteBuf) &#123;            this.buffer = buffer.unwrap();        &#125; else &#123;            this.buffer = buffer;        &#125;        // 直接复用原ByteBuf的读写指针        setIndex(readerIndex, writerIndex);        markReaderIndex();        markWriterIndex();    &#125;</code></pre><p><strong>值得注意的是，无论是slice还是duplicate，都没有调用retain()方法来改变底层ByteBuf的引用计数。</strong> 所以，如果底层ByteBuf调用release()后被释放，那么所有基于该ByteBuf的浅复制对象都不能进行读写。所以要确保浅复制实例的使用安全，需要通过调用一次retain()方法来递增底层ByteBuf的引用计数；然后在浅复制实例使用结束后，再调用一次release()来递减底层ByteBuf的引用计数。</p><h2 id="CompositeByteBuf"><a href="#CompositeByteBuf" class="headerlink" title="CompositeByteBuf"></a>CompositeByteBuf</h2><p>CompositeByteBuf也是一个非常典型的ByteBuf，用来将多个ByteBuf组合在一起，形成一个逻辑上的ByteBuf。这点和分片ByteBuf非常类似，都属于在逻辑层面上避免拷贝，实现所谓的“零复制”（Zero Copy)。</p><p>CompositeByteBuf在内部维护一个可扩容的components数组，所有被组合的ByteBuf被封装为Component对象，对象中缓存了该ByteBuf的偏移量adjustment、开始索引offset、结束索引endOffset等。</p><pre><code class="java">    private Component[] components; // resized when needed    private static final class Component &#123;        final ByteBuf buf;        int adjustment;        int offset;        int endOffset;        private ByteBuf slice; // cached slice, may be null    &#125;</code></pre><p>对CompositeByteBuf的读写，需要先在components数组里二分查找对应索引所在的Component对象，然后对Component对象所包装的ByteBuf进行读写。如下：</p><pre><code class="java">    @Override    protected byte _getByte(int index) &#123;        // 确定索引index所在的Component对象        Component c = findComponent0(index);        // 对Component对象所包装的ByteBuf进行读写        return c.buf.getByte(c.idx(index));    &#125;    private Component findComponent0(int offset) &#123;        // 先检查最近访问的Component是否满足条件        Component la = lastAccessed;        if (la != null &amp;&amp; offset &gt;= la.offset &amp;&amp; offset &lt; la.endOffset) &#123;           return la;        &#125;        // 否则二分查找        return findIt(offset);    &#125;    // 二分查找    private Component findIt(int offset) &#123;        for (int low = 0, high = componentCount; low &lt;= high;) &#123;            int mid = low + high &gt;&gt;&gt; 1;            Component c = components[mid];            if (offset &gt;= c.endOffset) &#123;                low = mid + 1;            &#125; else if (offset &lt; c.offset) &#123;                high = mid - 1;            &#125; else &#123;                lastAccessed = c;                return c;            &#125;        &#125;        throw new Error(&quot;should not reach here&quot;);    &#125;</code></pre><p>CompositeByteBuf的核心思想大致如上，其他细节不作深究。</p><h2 id="ByteBuf引用计数实现"><a href="#ByteBuf引用计数实现" class="headerlink" title="ByteBuf引用计数实现"></a>ByteBuf引用计数实现</h2><h3 id="引用计数字段"><a href="#引用计数字段" class="headerlink" title="引用计数字段"></a>引用计数字段</h3><p>引用计数功能是在<em>AbstractReferenceCountedByteBuf</em>类中实现的。核心功能使用CAS原子操作和位运算实现。关键字段有两个：</p><pre><code class="java">    private static final AtomicIntegerFieldUpdater&lt;AbstractReferenceCountedByteBuf&gt; refCntUpdater =            AtomicIntegerFieldUpdater.newUpdater(AbstractReferenceCountedByteBuf.class, &quot;refCnt&quot;);    // even =&gt; &quot;real&quot; refcount is (refCnt &gt;&gt;&gt; 1); odd =&gt; &quot;real&quot; refcount is 0    @SuppressWarnings(&quot;unused&quot;)    private volatile int refCnt = 2;</code></pre><p>refCntUpdater是修改refCnt字段的原子更新器。而refCnt是存储引用计数的字段。注意，当前ByteBuf的引用数为 refCnt &#x2F; 2，因此当refCnt等于1时，引用数为0。</p><h3 id="增加引用retain"><a href="#增加引用retain" class="headerlink" title="增加引用retain"></a>增加引用retain</h3><p>retain方法可以增加ByteBuf的引用计数。核心代码如下：</p><pre><code class="java">    @Override    public ByteBuf retain() &#123;        return retain0(1);    &#125;    private ByteBuf retain0(final int increment) &#123;        // 将increment扩大两倍为adjustedIncrement        int adjustedIncrement = increment &lt;&lt; 1; // 此处允许溢出，因为后边有判断溢出的逻辑        // 将adjustedIncrement更新到refCnt，因此refCnt初始值为2，所以恒为偶数        int oldRef = refCntUpdater.getAndAdd(this, adjustedIncrement);        // 如果oldRef不是偶数，直接抛异常        if ((oldRef &amp; 1) != 0) &#123;            throw new IllegalReferenceCountException(0, increment);        &#125;        // 如果oldRef 和 oldRef + adjustedIncrement 正负异号，则意味着已经溢出。        if ((oldRef &lt;= 0 &amp;&amp; oldRef + adjustedIncrement &gt;= 0)                || (oldRef &gt;= 0 &amp;&amp; oldRef + adjustedIncrement &lt; oldRef)) &#123;            // 发生溢出需要回滚adjustedIncrement            refCntUpdater.getAndAdd(this, -adjustedIncrement);            // 然后抛异常            throw new IllegalReferenceCountException(realRefCnt(oldRef), increment);        &#125;        return this;    &#125;</code></pre><p>注释已经讲得很明白，这里再补充下：每次调用retain()，都会尝试给refCnt加2，所以确保了refCnt恒为偶数，也就是说当前引用数为refCnt &#x2F; 2。这里为啥设计为递增2而不是递增1，估计是位运算更加高效吧，而且实际应用中Integer.MAX_VALUE &#x2F; 2的引用数也是绰绰有余。</p><h3 id="释放引用release"><a href="#释放引用release" class="headerlink" title="释放引用release"></a>释放引用release</h3><p>恰恰相反，release()操作每次减少引用计数2，如下：</p><pre><code class="java">    @Override    public boolean release() &#123;        return release0(1);    &#125;    private boolean release0(int decrement) &#123;        int rawCnt = nonVolatileRawCnt(), realCnt = toLiveRealCnt(rawCnt, decrement);        if (decrement == realCnt) &#123;            // 如果decrement == realCnt，意味着需要释放对象            if (refCntUpdater.compareAndSet(this, rawCnt, 1)) &#123;                deallocate();                return true;            &#125;            return retryRelease0(decrement);        &#125;        return releaseNonFinal0(decrement, rawCnt, realCnt);    &#125;    private boolean releaseNonFinal0(int decrement, int rawCnt, int realCnt) &#123;        if (decrement &lt; realCnt                // all changes to the raw count are 2x the &quot;real&quot; change                &amp;&amp; refCntUpdater.compareAndSet(this, rawCnt, rawCnt - (decrement &lt;&lt; 1))) &#123;            return false;        &#125;        // 上述更新失败则调用重试方法        return retryRelease0(decrement);    &#125;    private boolean retryRelease0(int decrement) &#123;        // 死循环不断重试释放引用        for (;;) &#123;            int rawCnt = refCntUpdater.get(this), realCnt = toLiveRealCnt(rawCnt, decrement);            if (decrement == realCnt) &#123;                if (refCntUpdater.compareAndSet(this, rawCnt, 1)) &#123;                    // 如果refCnt为1，意味着实际的引用数为1/2=0，所以需要释放掉                    deallocate();                    return true;                &#125;            &#125; else if (decrement &lt; realCnt) &#123;                // 如果当前引用数realCnt大于decrement，则可以正常更新                if (refCntUpdater.compareAndSet(this, rawCnt, rawCnt - (decrement &lt;&lt; 1))) &#123;                    return false;                &#125;            &#125; else &#123;                // 如果当前引用数realCnt小于decrement，则抛出引用异常                throw new IllegalReferenceCountException(realCnt, -decrement);            &#125;            Thread.yield(); // this benefits throughput under high contention        &#125;    &#125;    /**     * Like &#123;@link #realRefCnt(int)&#125; but throws if refCnt == 0     */    private static int toLiveRealCnt(int rawCnt, int decrement) &#123;        if ((rawCnt &amp; 1) == 0) &#123;            // 如果是偶数，则引用数为rawCnt &gt;&gt;&gt; 1            return rawCnt &gt;&gt;&gt; 1;        &#125;        // 如果是奇数，意味着该对象可能已经被释放掉        throw new IllegalReferenceCountException(0, -decrement);    &#125;</code></pre><p><strong>release0算法流程：</strong></p><ul><li><ol><li>获取当前计数rawCnt，获取实际引用数realCnt；</li></ol></li><li><ol start="2"><li>判断decrement是否等于realCnt；</li></ol></li><li><ul><li>2.1 如果相等，意味着本次release之后，对象需要被释放，尝试原子操作修改引用数；</li></ul></li><li><ul><li><ul><li>2.1.1 如果修改成功，直接释放对象并返回true；</li></ul></li></ul></li><li><ul><li><ul><li>2.2.2 如果修改失败，调用retryRelease0进行循环重试释放；</li></ul></li></ul></li><li><ul><li>2.2 如果不相等，意味着本次release之后，对象依然存活，尝试调用releaseNonFinal0；</li></ul></li><li><ul><li><ul><li>2.2.1 如果decrement &lt; realCnt，且原子修改引用计数成功，直接返回false；</li></ul></li></ul></li><li><ul><li><ul><li>2.2.2 否则，调用retryRelease0进行循环重试释放。</li></ul></li></ul></li></ul><p><strong>retryRelease0算法流程：</strong></p><ul><li><ol><li>死循环开始；</li></ol></li><li><ol start="2"><li>获取当前计数rawCnt，获取实际引用数realCnt；</li></ol></li><li><ol start="3"><li>判断decrement &#x3D;&#x3D; realCnt；</li></ol></li><li><ul><li>3.1 如果相等，意味着本次release之后，对象需要被释放，尝试原子操作修改引用数；</li></ul></li><li><ul><li><ul><li>3.1.1 如果修改成功，直接释放对象并返回true；</li></ul></li></ul></li><li><ul><li><ul><li>3.1.2 否则跳转6；</li></ul></li></ul></li><li><ol start="4"><li>判断decrement &lt; realCnt；</li></ol></li><li><ul><li>4.1 如果成立，意味着本次release之后，对象依然存活，尝试原子更新引用计数；</li></ul></li><li><ul><li><ul><li>4.1.1 如果修改成功，直接返回false；</li></ul></li></ul></li><li><ul><li><ul><li>4.1.2 否则跳转6；</li></ul></li></ul></li><li><ol start="5"><li>其他情况（decrement &gt; realCnt) 直接抛异常；</li></ol></li><li><ol start="6"><li>Thread.yield()；</li></ol></li><li><ol start="7"><li>跳转到1。</li></ol></li></ul><h2 id="池化和非池化"><a href="#池化和非池化" class="headerlink" title="池化和非池化"></a>池化和非池化</h2><p>我们看到ByteBuf分为两类池化(Pooled)和非池化(Unpooled)。非池化的ByteBuf每次新建都会申请新的内存空间，并且用完即弃，给JVM的垃圾回收带来负担；而池化的ByteBuf通过内部栈来保存闲置的对象空间，每次新建ByteBuf的时候，优先向内部栈申请闲置的对象空间，并且用完之后重新归还给内部栈，从而减少了JVM的垃圾回收压力。</p><h3 id="非池化实现"><a href="#非池化实现" class="headerlink" title="非池化实现"></a>非池化实现</h3><p>非池化的ByteBuf实现非常简单粗暴。下边分别以UnpooledHeapByteBuf和UnpooledDirectByteBuf为例：</p><ul><li>对象分配<br>UnpooledHeapByteBuf在构造函数里直接新建了一个字节数组来保存数据：</li></ul><pre><code class="java">    private final ByteBufAllocator alloc;    // 使用字节数组保存数据    byte[] array;    public UnpooledHeapByteBuf(ByteBufAllocator alloc, int initialCapacity, int maxCapacity) &#123;        super(maxCapacity);        checkNotNull(alloc, &quot;alloc&quot;);        if (initialCapacity &gt; maxCapacity) &#123;            throw new IllegalArgumentException(String.format(                    &quot;initialCapacity(%d) &gt; maxCapacity(%d)&quot;, initialCapacity, maxCapacity));        &#125;        this.alloc = alloc;        setArray(allocateArray(initialCapacity));        setIndex(0, 0);    &#125;    // 分配字节数组    protected byte [] allocateArray(int initialCapacity) &#123;        return new byte[initialCapacity];    &#125;</code></pre><p>而UnpooledDirectByteBuf则在构造函数中直接新建了一个DirectBuffer：</p><pre><code class="java">    // 使用DirectBuffer保存数据    private ByteBuffer buffer;    public UnpooledDirectByteBuf(ByteBufAllocator alloc, int initialCapacity, int maxCapacity) &#123;        super(maxCapacity);        if (alloc == null) &#123;            throw new NullPointerException(&quot;alloc&quot;);        &#125;        if (initialCapacity &lt; 0) &#123;            throw new IllegalArgumentException(&quot;initialCapacity: &quot; + initialCapacity);        &#125;        if (maxCapacity &lt; 0) &#123;            throw new IllegalArgumentException(&quot;maxCapacity: &quot; + maxCapacity);        &#125;        if (initialCapacity &gt; maxCapacity) &#123;            throw new IllegalArgumentException(String.format(                    &quot;initialCapacity(%d) &gt; maxCapacity(%d)&quot;, initialCapacity, maxCapacity));        &#125;        this.alloc = alloc;        setByteBuffer(allocateDirect(initialCapacity));    &#125;    // 分配DirectBuffer    protected ByteBuffer allocateDirect(int initialCapacity) &#123;        return ByteBuffer.allocateDirect(initialCapacity);    &#125;</code></pre><ul><li>对象释放<br>UnpooledHeapByteBuf的释放全权交给JVM：</li></ul><pre><code class="java">    @Override    protected void deallocate() &#123;        freeArray(array);        array = EmptyArrays.EMPTY_BYTES;    &#125;    protected void freeArray(byte[] array) &#123;        // NOOP    &#125;</code></pre><p>而UnpooledDirectByteBuf则尝试主动释放其拥有的DirectBuffer：</p><pre><code class="java">    @Override    protected void deallocate() &#123;        ByteBuffer buffer = this.buffer;        if (buffer == null) &#123;            return;        &#125;        this.buffer = null;        if (!doNotFree) &#123;            // 如果DirectBuffer还没被释放，则尝试释放之            freeDirect(buffer);        &#125;    &#125;    /**     * Free a direct &#123;@link ByteBuffer&#125;     */    protected void freeDirect(ByteBuffer buffer) &#123;        PlatformDependent.freeDirectBuffer(buffer);    &#125;</code></pre><h3 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h3><p>池化的ByteBuf都继承自PooledByteBuf<T>类，包括PooledHeapByteBuf、PooledDirectByteBuf、PooledUnsafeDirectByteBuf、PooledUnsafeHeapByteBuf。</p><p>这四个子类都持有一个回收器字段，例如，在PooledHeapByteBuf中有：</p><pre><code class="java">    private static final Recycler&lt;PooledHeapByteBuf&gt; RECYCLER = new Recycler&lt;PooledHeapByteBuf&gt;() &#123;        @Override        protected PooledHeapByteBuf newObject(Handle&lt;PooledHeapByteBuf&gt; handle) &#123;            return new PooledHeapByteBuf(handle, 0);        &#125;    &#125;;</code></pre><p>Recycler<T>是一个抽象类，所有的子类都要实现一个newObject方法，用于新建一个子类ByteBuf对象。</p><p>Recycler<T>本质上实现的是一个栈的功能，新建ByteBuf的时候，可以向Recycler<T>申请一个闲置对象；当ByteBuf使用完毕后，可以回收并归还给Recycler<T>。</p><ul><li><strong>申请ByteBuf</strong></li></ul><p>子类调用RECYCLER.get()来申请闲置对象，方法实现：</p><pre><code class="java">    public final T get() &#123;        if (maxCapacityPerThread == 0) &#123;            return newObject((Handle&lt;T&gt;) NOOP_HANDLE);        &#125;        // 尝试从栈中获取闲置对象        Stack&lt;T&gt; stack = threadLocal.get();        DefaultHandle&lt;T&gt; handle = stack.pop();        if (handle == null) &#123;            // 如果没有闲置对象，调用newObject新建一个新的对象。            handle = stack.newHandle();            handle.value = newObject(handle);        &#125;        return (T) handle.value;    &#125;</code></pre><p>可见，新建池化的ByteBuf都是优先从栈中获取闲置对象；当栈没有闲置对象再新建。值得注意的是，新建对象还传入了新建的handle，这个handle在对象回收阶段会使用到。</p><p>另外为了抹去历史的使用痕迹，每个新申请的ByteBuf对象，都会调用reuse方法进行初始化（以PooledDirectByteBuf为例）：</p><pre><code class="java">    static PooledDirectByteBuf newInstance(int maxCapacity) &#123;        PooledDirectByteBuf buf = RECYCLER.get();        buf.reuse(maxCapacity);        return buf;    &#125;    /**     * Method must be called before reuse this &#123;@link PooledByteBufAllocator&#125;     */    final void reuse(int maxCapacity) &#123;        maxCapacity(maxCapacity);        setRefCnt(1);        setIndex0(0, 0);        discardMarks();    &#125;</code></pre><ul><li><strong>回收ByteBuf</strong></li></ul><p>前面我们提到：当ByteBuf引用数为0的时候，会调用deallocate()方法进行释放。实现如下：</p><pre><code class="java">    @Override    protected final void deallocate() &#123;        if (handle &gt;= 0) &#123;            final long handle = this.handle;            this.handle = -1;            memory = null;            chunk.arena.free(chunk, tmpNioBuf, handle, maxLength, cache);            tmpNioBuf = null;            chunk = null;            recycle();        &#125;    &#125;    private void recycle() &#123;        recyclerHandle.recycle(this);    &#125;</code></pre><p>如上，最后调用了handler进行回收。所谓的回收动作，其实就是放回栈中：</p><pre><code class="java">    static final class DefaultHandle&lt;T&gt; implements Handle&lt;T&gt; &#123;        private int lastRecycledId;        private int recycleId;        boolean hasBeenRecycled;        private Stack&lt;?&gt; stack;        private Object value;        DefaultHandle(Stack&lt;?&gt; stack) &#123;            this.stack = stack;        &#125;        @Override        public void recycle(Object object) &#123;            if (object != value) &#123;                throw new IllegalArgumentException(&quot;object does not belong to handle&quot;);            &#125;            Stack&lt;?&gt; stack = this.stack;            if (lastRecycledId != recycleId || stack == null) &#123;                throw new IllegalStateException(&quot;recycled already&quot;);            &#125;            // 将该handler重新放入栈中            stack.push(this);        &#125;    &#125;</code></pre><h2 id="Unsafe"><a href="#Unsafe" class="headerlink" title="Unsafe"></a>Unsafe</h2><h3 id="Unsafe实现"><a href="#Unsafe实现" class="headerlink" title="Unsafe实现"></a>Unsafe实现</h3><p>还有一类使用了Unsafe操作的ByteBuf，例如：UnpooledUnsafeDirectByteBuf、UnpooledUnsafeHeapByteBuf、PooledUnsafeHeapByteBuf、PooledUnsafeDirectByteBuf。</p><p>这类ByteBuf的特点就是所有的读写操作都是用了sun.misc.Unsafe。如下：</p><pre><code class="java">    @Override    protected byte _getByte(int index) &#123;        return UnsafeByteBufUtil.getByte(addr(index));    &#125;</code></pre><p>而UnsafeByteBufUtil底层调用了sum.misc.Unsafe ：</p><pre><code class="java">    static byte getByte(long address) &#123;        return UNSAFE.getByte(address);    &#125;</code></pre><p>而不是用Unsafe操作的ByteBuf，一般使用的是HeapByteBufUtil：</p><pre><code class="java">    @Override    protected byte _getByte(int index) &#123;        return HeapByteBufUtil.getByte(memory, idx(index));    &#125;</code></pre><p>而HeapByteBufUtil底层其实是简单的数组寻址：</p><pre><code class="java">    static byte getByte(byte[] memory, int index) &#123;        return memory[index];    &#125;</code></pre><h3 id="Unsafe的性能提升"><a href="#Unsafe的性能提升" class="headerlink" title="Unsafe的性能提升"></a>Unsafe的性能提升</h3><p>Unsafe操作可以带来非常可观的性能提升，我写了一个简单的Benchmark测了下：</p><pre><code class="java">    @BenchmarkMode(&#123;Mode.Throughput&#125;)    @Warmup(iterations = 1)    @Measurement(iterations = 2, time = 1)    @OutputTimeUnit(TimeUnit.SECONDS)    @Fork(value = 2)    @Threads(8)    @State(Scope.Benchmark)    @OperationsPerInvocation    public class UnsafeBenchmark &#123;        private static byte[] unsafeByteArray;        private static byte[] safeByteArray;        @Setup        public void setup() &#123;            unsafeByteArray = new byte[100];            safeByteArray = new byte[100];        &#125;        @Benchmark        public void unsafeMethod() &#123;            int value = 1;            UnsafeByteBufUtil.setByte(unsafeByteArray, 0, value);            UnsafeByteBufUtil.getByte(unsafeByteArray, 0);            long longValue = 100L;            UnsafeByteBufUtil.setLong(unsafeByteArray, 0, longValue);            UnsafeByteBufUtil.getLong(unsafeByteArray, 0);        &#125;        @Benchmark        public void safeMethod() &#123;            int value = 1;            HeapByteBufUtil.setByte(safeByteArray, 0, value);            HeapByteBufUtil.getByte(safeByteArray, 0);            long longValue = 100L;            HeapByteBufUtil.setLong(safeByteArray, 0, longValue);            HeapByteBufUtil.getLong(safeByteArray, 0);        &#125;        public static void main(String[] args) throws RunnerException &#123;            Options opt = new OptionsBuilder()                    .include(UnsafeBenchmark.class.getSimpleName())                    .build();            new Runner(opt).run();        &#125;    &#125;</code></pre><p>测试结果显示UnsafeByteBufUtil的性能非常优越：</p><pre><code class="bash">Benchmark                                Mode  Samples           Score            Error  Unitsc.t.n.u.UnsafeBenchmark.safeMethod      thrpt        4   168827679.833 ±   71641561.636  ops/sc.t.n.u.UnsafeBenchmark.unsafeMethod    thrpt        4  3141320463.164 ± 1204482723.948  ops/s</code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文详细介绍了ByteBuf及其子类的实现原理，包括读写指针、常用方法、浅复制、引用计数、池化、Unsafe对象等实现原理。<br>通过上述深入分析，我们了解到ByteBuf在Netty中承担着运载数据的重要功能。如果将Netty比作一个完整的生物体，那么将ByteBuf比作血液，那就再恰当不过了。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://blog.csdn.net/mycs2012/article/details/94591307">Netty ByteBuf（图解 ）之一</a></li><li><a href="https://blog.csdn.net/crazymakercircle/article/details/84205697">Netty ByteBuf（图解二）：API 图解</a></li><li><a href="https://blog.csdn.net/mycs2012/article/details/94591307">池化和非池化ByteBuf</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Netty </tag>
            
            <tag> 源码分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Netty 源码分析之 四 Promise 与 Future: 双子星的秘密</title>
      <link href="/2020/07/04/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E5%9B%9B-Promise-%E4%B8%8E-Future-%E5%8F%8C%E5%AD%90%E6%98%9F%E7%9A%84%E7%A7%98%E5%AF%86/"/>
      <url>/2020/07/04/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E5%9B%9B-Promise-%E4%B8%8E-Future-%E5%8F%8C%E5%AD%90%E6%98%9F%E7%9A%84%E7%A7%98%E5%AF%86/</url>
      
        <content type="html"><![CDATA[<p>永顺大牛写的系列教程<a href="https://segmentfault.com/a/1190000007282628#comment-area">《源码之下无秘密 ── 做最好的 Netty 源码分析教程》</a>是目前我读过最好的netty源码分析文章。但不知道什么原因，作者在写到第三章的时候停更了。因此，我想尝试凭着个人的理解，续写后边几个章节。</p><span id="more"></span><h2 id="写在最前"><a href="#写在最前" class="headerlink" title="写在最前"></a>写在最前</h2><p>永顺前辈已经写完章节有如下：</p><ul><li><a href="https://segmentfault.com/a/1190000006824091">Netty 源码分析之 番外篇 Java NIO 的前生今世</a></li><li><a href="https://segmentfault.com/a/1190000007282597">Netty 源码分析之 零 磨刀不误砍柴工 源码分析环境搭建</a></li><li><a href="https://segmentfault.com/a/1190000007282789">Netty 源码分析之 一 揭开 Bootstrap 神秘的红盖头 (客户端)</a></li><li><a href="https://segmentfault.com/a/1190000007283053">Netty 源码分析之 一 揭开 Bootstrap 神秘的红盖头 (服务器端)</a></li><li><a href="https://segmentfault.com/a/1190000007308934">Netty 源码分析之 二 贯穿 Netty 的大动脉 ── ChannelPipeline (一)</a></li><li><a href="https://segmentfault.com/a/1190000007309311">Netty 源码分析之 二 贯穿 Netty 的大动脉 ── ChannelPipeline (二)</a></li><li><a href="https://segmentfault.com/a/1190000007403873">Netty 源码分析之 三 我就是大名鼎鼎的 EventLoop(一)</a></li><li><a href="https://segmentfault.com/a/1190000007403937">Netty 源码分析之 三 我就是大名鼎鼎的 EventLoop(二)</a></li></ul><p>续写章节：</p><ul><li><a href="https://blog.duval.top/2020/07/04/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E5%9B%9B-Promise-%E4%B8%8E-Future-%E5%8F%8C%E5%AD%90%E6%98%9F%E7%9A%84%E7%A7%98%E5%AF%86/">Netty 源码分析之 四 Promise 与 Future: 双子星的秘密</a></li><li><a href="https://blog.duval.top/2020/07/09/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E4%BA%94-%E5%A5%94%E8%85%BE%E7%9A%84%E8%A1%80%E6%B6%B2-ByteBuf/">Netty 源码分析之 五 奔腾的血液: ByteBuf</a></li><li><a href="https://blog.duval.top/2020/07/15/Netty-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B-%E5%85%AD-%E6%B5%81%E6%B0%B4%E7%BA%BF%E5%A4%84%E7%90%86%E5%99%A8-Handler/">Netty 源码分析之 六 流水线处理器: Handler</a></li></ul><p><em>本文使用的netty版本为4.1.33</em></p><h2 id="Future和Promise的关系"><a href="#Future和Promise的关系" class="headerlink" title="Future和Promise的关系"></a>Future<V>和Promise<V>的关系</h2><p>Netty内部的io.netty.util.concurrent.Future<V> 继承自java.util.concurrent.Future<V>，而Promise<V>是前者的一个特殊实现。<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2FNetty%20%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%20%E5%9B%9B%20Promise%20%E4%B8%8E%20Future%3A%20%E5%8F%8C%E5%AD%90%E6%98%9F%E7%9A%84%E7%A7%98%E5%AF%86%2FFuture%E5%92%8CPromise%E7%B1%BB%E5%9B%BE.png" alt="Future和Promise类图.png"></p><h2 id="Java原生Future"><a href="#Java原生Future" class="headerlink" title="Java原生Future"></a>Java原生Future<V></h2><p>Java并发编程包下提供了Future<V>接口。Future在异步编程中表示该异步操作的结果，通过Future<V>的内部方法可以实现状态检查、取消执行、获取执行结果等操作。内部的方法如下：</p><pre><code class="java">    // 尝试取消执行    boolean cancel(boolean mayInterruptIfRunning);    // 是否已经被取消执行    boolean isCancelled();    // 是否已经执行完毕    boolean isDone();    // 阻塞获取执行结果    V get() throws InterruptedException, ExecutionException;    // 阻塞获取执行结果或超时后返回    V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;</code></pre><h2 id="Netty对Future的扩展"><a href="#Netty对Future的扩展" class="headerlink" title="Netty对Future的扩展"></a>Netty对Future<V>的扩展</h2><p>原生的Future<V>功能比较有限，Netty扩展了Future<V>并增加了以下方法：</p><ul><li>增加了更加丰富的状态判断方法</li></ul><pre><code class="java">    // 判断是否执行成功    boolean isSuccess();    // 判断是否可以取消执行    boolean isCancellable();</code></pre><ul><li>支持获取导致I&#x2F;O操作异常</li></ul><pre><code class="java">    Throwable cause();</code></pre><ul><li>增加了监听回调有关方法，支持future完成后执行用户指定的回调方法</li></ul><pre><code class="java">    // 增加回调方法    Future&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener);    // 增加多个回调方法    Future&lt;V&gt; addListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners);    // 删除回调方法    Future&lt;V&gt; removeListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener);    // 删除多个回调方法    Future&lt;V&gt; removeListeners(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt;... listeners);</code></pre><ul><li>增加了更丰富的阻塞等待结果返回的两类方法。其中一类是sync方法，阻塞等待结果且如果执行失败后向外抛出导致失败的异常；另外一类是await方法，仅阻塞等待结果返回，不向外抛出异常。</li></ul><pre><code class="java">    // 阻塞等待，且如果失败抛出异常    Future&lt;V&gt; sync() throws InterruptedException;    // 同上，区别是不可中断阻塞等待过程    Future&lt;V&gt; syncUninterruptibly();    // 阻塞等待    Future&lt;V&gt; await() throws InterruptedException;    // 同上，区别是不可中断阻塞等待过程    Future&lt;V&gt; awaitUninterruptibly();</code></pre><h2 id="Promise"><a href="#Promise" class="headerlink" title="Promise"></a>Promise<V></h2><p>Promise<V>接口继续继承了Future<V>，并增加若干个设置状态并回调的方法：</p><pre><code class="java">    // 设置成功状态并回调    Promise&lt;V&gt; setSuccess(V result);    boolean trySuccess(V result);    // 设置失败状态并回调    Promise&lt;V&gt; setFailure(Throwable cause);    boolean tryFailure(Throwable cause);    // 设置为不可取消状态    boolean setUncancellable();</code></pre><p>可见，Promise<V>作为一个特殊的Future<V>，只是增加了一些状态设置方法。所以它常用于传入I&#x2F;O业务代码中，用于I&#x2F;O结束后设置成功（或失败）状态，并回调方法。</p><h2 id="通过Promise设置I-O执行结果"><a href="#通过Promise设置I-O执行结果" class="headerlink" title="通过Promise设置I&#x2F;O执行结果"></a>通过Promise设置I&#x2F;O执行结果</h2><p>以客户端连接的注册过程为例，调用链路如下：</p><pre><code class="java">io.netty.bootstrap.Bootstrap.connect()--&gt; io.netty.bootstrap.Bootstrap.doResolveAndConnect()----&gt;io.netty.bootstrap.AbstractBootstrap.initAndRegister()------&gt;io.netty.channel.MultithreadEventLoopGroup.register()--------&gt;io.netty.channel.SingleThreadEventLoop.register()</code></pre><p>一直跟踪到SingleThreadEventLoop中，会看到这段代码：</p><pre><code class="java">    @Override    public ChannelFuture register(Channel channel) &#123;        return register(new DefaultChannelPromise(channel, this));    &#125;</code></pre><p>此处新建了一个DefaultChannelPromise，构造函数传入了当前的channel以及当前所在的线程this。从第一节的类图我们知道，DefaultChannelPromise同时实现了Future和Promise，具有上述提到的所有方法。</p><p>然后继续将该promise传递进另外一个register方法中：</p><pre><code class="java">    @Override    public ChannelFuture register(final ChannelPromise promise) &#123;        ObjectUtil.checkNotNull(promise, &quot;promise&quot;);        promise.channel().unsafe().register(this, promise);        return promise;    &#125;</code></pre><p>在该register方法中，继续将promise传递到Unsafe的register方法中，而立即返回了以ChannelFuture的形式返回了该promise。显然这里是一个异步回调处理：上层的业务可以拿到返回的ChannelFuture阻塞等待结果或者设置回调方法，而继续往下传的Promise可以用于设置执行状态并且回调设置的方法。</p><p>我们继续往下debug可以看到：</p><pre><code class="java"> // io.netty.channel.AbstractChannel.AbstractUnsafe.java @Override        public final void register(EventLoop eventLoop, final ChannelPromise promise) &#123;            if (eventLoop == null) &#123;                throw new NullPointerException(&quot;eventLoop&quot;);            &#125;            if (isRegistered()) &#123;                // 如果已经注册过，则置为失败                promise.setFailure(new IllegalStateException(&quot;registered to an event loop already&quot;));                return;            &#125;            if (!isCompatible(eventLoop)) &#123;                // 如果线程类型不兼容，则置为失败                promise.setFailure(                        new IllegalStateException(&quot;incompatible event loop type: &quot; + eventLoop.getClass().getName()));                return;            &#125;            AbstractChannel.this.eventLoop = eventLoop;            if (eventLoop.inEventLoop()) &#123;                register0(promise);            &#125; else &#123;                try &#123;                    eventLoop.execute(new Runnable() &#123;                        @Override                        public void run() &#123;                            register0(promise);                        &#125;                    &#125;);                &#125; catch (Throwable t) &#123;                    logger.warn(                            &quot;Force-closing a channel whose registration task was not accepted by an event loop: &#123;&#125;&quot;,                            AbstractChannel.this, t);                    closeForcibly();                    closeFuture.setClosed();                    // 出现异常情况置promise为失败                    safeSetFailure(promise, t);                &#125;            &#125;        &#125;        private void register0(ChannelPromise promise) &#123;            try &#123;                // 注册之前，先将promise置为不可取消转态                if (!promise.setUncancellable() || !ensureOpen(promise)) &#123;                    return;                &#125;                boolean firstRegistration = neverRegistered;                doRegister();                neverRegistered = false;                registered = true;                pipeline.invokeHandlerAddedIfNeeded();                // promise置为成功                safeSetSuccess(promise);                pipeline.fireChannelRegistered();                             if (isActive()) &#123;                    if (firstRegistration) &#123;                        pipeline.fireChannelActive();                    &#125; else if (config().isAutoRead()) &#123;                        beginRead();                    &#125;                &#125;            &#125; catch (Throwable t) &#123;                // Close the channel directly to avoid FD leak.                closeForcibly();                closeFuture.setClosed();                // 出现异常情况置promise为失败                safeSetFailure(promise, t);            &#125;        &#125;</code></pre><p>可见，底层的I&#x2F;O操作成功与否都可以通过Promise设置状态，并使得外层的ChannelFuture可以感知得到I&#x2F;O操作的结果。</p><h2 id="通过ChannelFuture获取I-O执行结果"><a href="#通过ChannelFuture获取I-O执行结果" class="headerlink" title="通过ChannelFuture获取I&#x2F;O执行结果"></a>通过ChannelFuture获取I&#x2F;O执行结果</h2><p>我们再来看看被返回的ChannelFuture的用途：</p><pre><code class="java">// io.netty.bootstrap.AbstractBootstrap.java    final ChannelFuture initAndRegister() &#123;        //...        ChannelFuture regFuture = config().group().register(channel);        // 如果异常不为null，则意味着底层的I/O已经失败，并且promise设置了失败异常        if (regFuture.cause() != null) &#123;            if (channel.isRegistered()) &#123;                channel.close();            &#125; else &#123;                channel.unsafe().closeForcibly();            &#125;        &#125;        return regFuture;    &#125;</code></pre><p>这里通过检查失败异常栈是否为空，可以提前检查到I&#x2F;O是否失败。继续回溯，还可以看到：</p><pre><code class="java">// io.netty.bootstrap.AbstractBootstrap.java private ChannelFuture doBind(final SocketAddress localAddress) &#123;    final ChannelFuture regFuture = initAndRegister();    final Channel channel = regFuture.channel();    if (regFuture.cause() != null) &#123;        return regFuture;    &#125;    if (regFuture.isDone()) &#123;        // 如果注册已经成功        ChannelPromise promise = channel.newPromise();        doBind0(regFuture, channel, localAddress, promise);        return promise;    &#125; else &#123;       // 如果注册尚未完成       // ...    &#125;&#125;</code></pre><p>此处，通过ChannelFuture#isDone()方法可以知道底层的注册是否完成，如果完成，则继续进行bind操作。</p><p>但是因为注册是个异步操作，如果此时注册可能还没完成，那就会进入如下逻辑：</p><pre><code class="java">// io.netty.bootstrap.AbstractBootstrap.java//...else &#123;    // Registration future is almost always fulfilled already, but just in case it&#39;s not.    final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel);    regFuture.addListener(new ChannelFutureListener() &#123;        @Override        public void operationComplete(ChannelFuture future) throws Exception &#123;            Throwable cause = future.cause();            if (cause != null) &#123;                // Registration on the EventLoop failed so fail the ChannelPromise directly to not cause an                // IllegalStateException once we try to access the EventLoop of the Channel.                promise.setFailure(cause);            &#125; else &#123;                // Registration was successful, so set the correct executor to use.                // See https://github.com/netty/netty/issues/2586                promise.registered();                doBind0(regFuture, channel, localAddress, promise);            &#125;        &#125;    &#125;);    return promise;&#125;</code></pre><p>这里新建了一个新的PendingRegistrationPromise，并为原来的ChannelFuture对象添加了一个回调方法，并在回调中更改PendingRegistrationPromise的状态，而且PendingRegistrationPromise会继续被传递到上层。当底层的Promise状态被设置并且回调，就会进入该回调方法。从而将I&#x2F;O状态继续向外传递。</p><h2 id="DefaultChannelPromise的结果传递实现原理"><a href="#DefaultChannelPromise的结果传递实现原理" class="headerlink" title="DefaultChannelPromise的结果传递实现原理"></a>DefaultChannelPromise的结果传递实现原理</h2><p>我们已经了解清楚了Promise和Future的异步模型。再来看看底层是如何实现的。以最常用的DefaultChannelPromise为例，内部非常简单，我们主要看它的父类DefaultPromise：</p><pre><code class="java">    // result字段的原子更新器    @SuppressWarnings(&quot;rawtypes&quot;)    private static final AtomicReferenceFieldUpdater&lt;DefaultPromise, Object&gt; RESULT_UPDATER =            AtomicReferenceFieldUpdater.newUpdater(DefaultPromise.class, Object.class, &quot;result&quot;);    // 缓存执行结果的字段    private volatile Object result;    // promise所在的线程    private final EventExecutor executor;    // 一个或者多个回调方法    private Object listeners;    // 阻塞线程数量计数器      private short waiters;</code></pre><h3 id="设置状态"><a href="#设置状态" class="headerlink" title="设置状态"></a>设置状态</h3><p>以设置成功状态为例（setSuccess）：</p><pre><code class="java">    @Override    public Promise&lt;V&gt; setSuccess(V result) &#123;        if (setSuccess0(result)) &#123;            // 调用回调方法            notifyListeners();            return this;        &#125;        throw new IllegalStateException(&quot;complete already: &quot; + this);    &#125;    private boolean setSuccess0(V result) &#123;        return setValue0(result == null ? SUCCESS : result);    &#125;    private boolean setValue0(Object objResult) &#123;        // 原子修改result字段为objResult        if (RESULT_UPDATER.compareAndSet(this, null, objResult) ||            RESULT_UPDATER.compareAndSet(this, UNCANCELLABLE, objResult)) &#123;            checkNotifyWaiters();            return true;        &#125;        return false;    &#125;    private synchronized void checkNotifyWaiters() &#123;        if (waiters &gt; 0) &#123;            // 如果有其他线程在等待该promise的结果，则唤醒他们            notifyAll();        &#125;    &#125;</code></pre><p>设置promise的状态其实就是原子地修改result字段为传入的执行结果。值得注意的是，result字段带有volatile关键字来确保多线程之间的可见性。另外，设置完毕状态后，会尝试唤醒所有在阻塞等待该promise返回结果的线程。</p><p>其他设置状态方法不再赘言，基本上大同小异。</p><h3 id="阻塞线程以等待执行结果"><a href="#阻塞线程以等待执行结果" class="headerlink" title="阻塞线程以等待执行结果"></a>阻塞线程以等待执行结果</h3><p>上文提到其他线程会阻塞等待该promise返回结果，具体实现以sync方法为例：</p><pre><code class="java">    @Override    public Promise&lt;V&gt; sync() throws InterruptedException &#123;        // 阻塞等待        await();        // 如果有异常则抛出        rethrowIfFailed();        return this;    &#125;    @Override    public Promise&lt;V&gt; await() throws InterruptedException &#123;        if (isDone()) &#123;            // 如果已经完成，直接返回            return this;        &#125;        // 可以被中断        if (Thread.interrupted()) &#123;            throw new InterruptedException(toString());        &#125;        //检查死循环        checkDeadLock();        synchronized (this) &#123;            while (!isDone()) &#123;                // 递增计数器（用于记录有多少个线程在等待该promise返回结果）                incWaiters();                try &#123;                    // 阻塞等待结果                    wait();                &#125; finally &#123;                    // 递减计数器                    decWaiters();                &#125;            &#125;        &#125;        return this;    &#125;</code></pre><p>所有调用sync方法的线程，都会被阻塞，直到promise被设置为成功或者失败。这也解释了为何Netty客户端或者服务端启动的时候一般都会调用sync方法，本质上都是阻塞当前线程而异步地等待I&#x2F;O结果返回，如下：</p><pre><code class="java">    Bootstrap bootstrap = new Bootstrap();    ChannelFuture future = bootstrap.group(new NioEventLoopGroup(10))            .channel(NioSocketChannel.class)            .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123;                @Override                protected void initChannel(SocketChannel ch) throws Exception &#123;                    // 管道中添加基于换行符分割字符串的解析器                    ch.pipeline().addLast(new LineBasedFrameDecoder(1024));                    // 管道中添加字符串编码解码器                    ch.pipeline().addLast(new StringDecoder(Charset.forName(&quot;UTF-8&quot;)));                    ch.pipeline().addLast(new StringEncoder(Charset.forName(&quot;UTF-8&quot;)));                    // 管道中添加服务端处理逻辑                    ch.pipeline().addLast(new MyClientEchoHandler());                &#125;            &#125;).connect(&quot;127.0.0.1&quot;, 9898).sync();    future.channel().closeFuture().sync();</code></pre><h3 id="回调机制"><a href="#回调机制" class="headerlink" title="回调机制"></a>回调机制</h3><pre><code class="java">    @Override    public Promise&lt;V&gt; addListener(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener) &#123;        checkNotNull(listener, &quot;listener&quot;);        synchronized (this) &#123;            // 添加回调方法            addListener0(listener);        &#125;        if (isDone()) &#123;            // 如果I/O操作已经结束，直接触发回调            notifyListeners();        &#125;        return this;    &#125;    private void addListener0(GenericFutureListener&lt;? extends Future&lt;? super V&gt;&gt; listener) &#123;        if (listeners == null) &#123;            // 只有一个回调方法直接赋值            listeners = listener;        &#125; else if (listeners instanceof DefaultFutureListeners) &#123;            // 将回调方法添加到DefaultFutureListeners内部维护的listeners数组中            ((DefaultFutureListeners) listeners).add(listener);        &#125; else &#123;            // 如果有多个回调方法，新建一个DefaultFutureListeners以保存更多的回调方法            listeners = new DefaultFutureListeners((GenericFutureListener&lt;?&gt;) listeners, listener);        &#125;    &#125;</code></pre><p>从上边可以看到，添加回调方法完成之后，会立即检查promise是否已经完成；如果promise已经完成，则马上调用回调方法。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Netty的Promise和Future机制是基于Java并发包下的Future<V>开发的。其中Future支持阻塞等待、添加回调方法、判断执行状态等，而Promise主要是支持状态设置相关方法。当底层I&#x2F;O操作通过Promise改变执行状态，我们可以通过同步等待的Future立即得到结果。</p><p>因此，就像永顺大牛标题所言，在Netty的异步模型里，Promise和Future就像是双子星一般紧密相连。但我觉得这两者更像是量子纠缠里的两个电子，因为改变其中一个方的状态，另外一方能够马上感知。</p><p>至此，Promise和Future的核心原理已经分析完毕。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Netty </tag>
            
            <tag> 源码分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java高性能网络编程--Reactor模型</title>
      <link href="/2020/06/12/Java%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B-Reactor%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/06/12/Java%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B-Reactor%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p>Reactor模型是基于事件驱动的模型，是高性能网络编程中非常重要概念，常用于解决多核服务器下的如何处理海量I&#x2F;O问题。Java中大名鼎鼎的Netty网络编程框架的线程模型正是基于Reactor模型。</p><p>本文主要基于Doug Lea的文章<a href="http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf">Scalable IO in Java</a>来介绍下Reactor模型。<br>本文所有内容均基于前人资料总结而成，如有侵权必删。</p><span id="more"></span><h2 id="传统网络编程"><a href="#传统网络编程" class="headerlink" title="传统网络编程"></a>传统网络编程</h2><p>初学Java网络编程的时候，我们学过使用ServerSocket以及Socket来编码客户端与服务端的网络通讯程序。常见的服务端逻辑如下：</p><pre><code class="java">class Server implements Runnable &#123;    public void run() &#123;        try &#123;            ServerSocket ss = new ServerSocket(PORT);            while (!Thread.interrupted())                new Thread(new Handler(ss.accept())).start();            // or, single-threaded, or a thread pool        &#125; catch (IOException ex) &#123; /* ... */ &#125;    &#125;    static class Handler implements Runnable &#123;        final Socket socket;        Handler(Socket s) &#123;            socket = s;        &#125;        public void run() &#123;            try &#123;                byte[] input = new byte[MAX_INPUT];                socket.getInputStream().read(input);                byte[] output = process(input);                socket.getOutputStream().write(output);            &#125; catch (IOException ex) &#123; /* ... */ &#125;        &#125;        private byte[] process(byte[] cmd) &#123; /* ... */ &#125;    &#125;&#125;</code></pre><p>上述样例代码是一个典型的TPC（Thread Per Connection)模式，这种模式有几个显而易见的问题：</p><ul><li>1.所有的I&#x2F;O操作都是阻塞的，包括accept、read、write等操作都会阻塞所在线程；</li><li>2.每个连接都会新建一个线程，连接结束后线程即被销毁，频繁创建线程带来较高的性能损耗；</li><li>3.I&#x2F;O线程和业务process线程耦合；</li><li>4.服务端采用单线程accept客户端的请求，海量I&#x2F;O下存在性能瓶颈。</li></ul><p>因此，这种TPC的网络模式只适合并发请求量较小的业务情景。</p><p>为了解决以上的问题，于是有了Reactor模型。</p><h2 id="单线程版本"><a href="#单线程版本" class="headerlink" title="单线程版本"></a>单线程版本</h2><p>先来看看最简单的单线程版本Reactor模型。如下图所示：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B--Reactor%E6%A8%A1%E5%9E%8B%2F%E5%8D%95%E7%BA%BF%E7%A8%8BReactor%E6%A8%A1%E5%9E%8B.jpg" alt="单线程Reactor模型.jpg"></p><p>配图是Doug Lea在他的文章中的图。从图里可以看到:</p><ul><li>Reactor对象负责监听事件，并将事件委派给各个I&#x2F;O方法执行；</li><li>Reactor线程收到accept事件后，便交给acceptor实例进行处理（注意acceptor实例属于Reactor线程）；</li><li>acceptor处理完accept事件后，会将该channel重新注册会Reactor线程中；</li><li>Reactor线程中继续监听这些channel的其他I&#x2F;O事件，并通过dispatch方法分别处理read、decode、compute、encode、send等I&#x2F;O事件。</li></ul><p>值得注意的是，这张图比较容易混淆的地方是Acceptor并不是一个单独的线程，而是Reactor线程内部的一个实例；且以上所有步骤都是在同一个Reactor线程内完成的。</p><p>因为只有一个线程，所以这种单线程的Reactor模型，并没有充分利用多核服务器的CPU资源，性能上甚至不如上边提到的TPC。</p><p>Java一般基于NIO的来实现Reactor模型，样例如下：</p><pre><code class="java">class Reactor implements Runnable&#123;    final Selector selector;    final ServerSocketChannel serverSocket;    Reactor(int port) throws IOException    &#123; //Reactor初始化        selector = Selector.open();        serverSocket = ServerSocketChannel.open();        serverSocket.socket().bind(new InetSocketAddress(port));        //非阻塞        serverSocket.configureBlocking(false);        //分步处理,第一步,接收accept事件        SelectionKey sk =                serverSocket.register(selector, SelectionKey.OP_ACCEPT);        //附加一个Acceptor实例        sk.attach(new Acceptor());    &#125;    public void run()    &#123;        try        &#123;            while (!Thread.interrupted())            &#123;                selector.select();                Set selected = selector.selectedKeys();                Iterator it = selected.iterator();                while (it.hasNext())                &#123;                    //Reactor负责dispatch收到的事件                    dispatch((SelectionKey) (it.next()));                &#125;                selected.clear();            &#125;        &#125; catch (IOException ex)        &#123; /* ... */ &#125;    &#125;    void dispatch(SelectionKey k)    &#123;        Runnable r = (Runnable) (k.attachment());        //调用之前注册的callback对象        if (r != null)        &#123;            r.run();        &#125;    &#125;    // inner class    class Acceptor implements Runnable    &#123;        public void run()        &#123;            try            &#123;                SocketChannel channel = serverSocket.accept();                if (channel != null)                    new Handler(selector, channel);            &#125; catch (IOException ex)            &#123; /* ... */ &#125;        &#125;    &#125;&#125;</code></pre><pre><code class="java">class Handler implements Runnable&#123;    final SocketChannel channel;    final SelectionKey sk;    ByteBuffer input = ByteBuffer.allocate(SystemConfig.INPUT_SIZE);    ByteBuffer output = ByteBuffer.allocate(SystemConfig.SEND_SIZE);    static final int READING = 0, SENDING = 1;    int state = READING;    Handler(Selector selector, SocketChannel c) throws IOException    &#123;        channel = c;        c.configureBlocking(false);        // 一般来说先注册读时间        sk = channel.register(selector, 0);        sk.attach(this);        sk.interestOps(SelectionKey.OP_READ);        selector.wakeup();    &#125;    boolean inputIsComplete()    &#123;        /* ... */        return false;    &#125;    boolean outputIsComplete()    &#123;        /* ... */        return false;    &#125;    void process()    &#123;        /* ... */        return;    &#125;    public void run()    &#123;        try        &#123;            if (state == READING)            &#123;                read();            &#125;            else if (state == SENDING)            &#123;                send();            &#125;        &#125; catch (IOException ex)        &#123; /* ... */ &#125;    &#125;    void read() throws IOException    &#123;        channel.read(input);        if (inputIsComplete())        &#123;            // 进行其他业务处理            process();            state = SENDING;            // 一般来说读完数据之后，重新注册写实践到Selector中            sk.interestOps(SelectionKey.OP_WRITE);        &#125;    &#125;    void send() throws IOException    &#123;        channel.write(output);        //write事件结束后, 关闭select key        if (outputIsComplete())        &#123;            sk.cancel();        &#125;    &#125;&#125;</code></pre><p>如上实现，Acceptor只是Reactor线程内部实例，相当于一个特殊的Handler。</p><h2 id="多线程版本"><a href="#多线程版本" class="headerlink" title="多线程版本"></a>多线程版本</h2><p>单线程版本的主要问题之一是：I&#x2F;O处理逻辑与Reactor耦合共用了同一个线程。于是，将I&#x2F;O处理逻辑剥离出来，交由单独的线程池来运行。于是有如下设计：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B--Reactor%E6%A8%A1%E5%9E%8B%2F%E5%A4%9A%E7%BA%BF%E7%A8%8BReactor%E6%A8%A1%E5%9E%8B.jpg" alt="多线程Reactor模型.jpg"></p><p>实现上只需要变更Handler的代码，由一个全局的线程池来执行任务即可：</p><pre><code class="java">class Handler implements Runnable &#123;    // 全局公用的线程池    static PooledExecutor pool = new PooledExecutor(...);    static final int PROCESSING = 3;    // ...    synchronized void read() &#123; // ...        socket.read(input);        if (inputIsComplete()) &#123;            state = PROCESSING;            pool.execute(new Processer());        &#125;    &#125;    synchronized void processAndHandOff() &#123;        process();        state = SENDING; // or rebind attachment        sk.interest(SelectionKey.OP_WRITE);    &#125;    class Processer implements Runnable &#123;        public void run() &#123; processAndHandOff(); &#125;    &#125;&#125;</code></pre><p>该版本存在问题是：acceptor与Reactor共用一个线程，如果有海量的请求或者连接时候需要身份认证等耗时操作，会阻塞Reactor线程，影响了Reactor线程监控I&#x2F;O事件而成为性能瓶颈。</p><h2 id="主从Reator多线程版本"><a href="#主从Reator多线程版本" class="headerlink" title="主从Reator多线程版本"></a>主从Reator多线程版本</h2><p>为了解决以上问题，多Reactor多线程版本，引入多个Reactor，部分Reactor线程专门负责处理请求事件，以应对海量的请求或者耗时的连接操作；而其他的Reactor线程负责监听其他I&#x2F;O事件。于是有如下设计：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B--Reactor%E6%A8%A1%E5%9E%8B%2F%E5%A4%9AReactor%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.jpg" alt="多Reactor多线程模型.jpg"></p><p>这个版本有如下特点：</p><ul><li>单独的mainReactor线程来监听accept事件；</li><li>单独的subReactor线程来监听其他I&#x2F;O事件；</li><li>使用单独的线程池来处理业务。</li><li>实际生产中常用线程池来运行mainReactor和subReactor</li></ul><p><strong>现在许多高性能的网络应用或中间件都是采用这种主从多线程版本。</strong></p><h2 id="Reactor模型在Netty中的应用"><a href="#Reactor模型在Netty中的应用" class="headerlink" title="Reactor模型在Netty中的应用"></a>Reactor模型在Netty中的应用</h2><p>Netty的服务端在初始化ServerBootstrap的时候可以指定parentGroup和childGroup两个线程池。这两个线程池正好对应承载mainReactor和subReactor的两个线程池。</p><pre><code class="java">// io.netty.bootstrap.ServerBootstrap@Overridepublic ServerBootstrap group(EventLoopGroup group) &#123;    return group(group, group);&#125;/**    * Set the &#123;@link EventLoopGroup&#125; for the parent (acceptor) and the child (client). These    * &#123;@link EventLoopGroup&#125;&#39;s are used to handle all the events and IO for &#123;@link ServerChannel&#125; and    * &#123;@link Channel&#125;&#39;s.    */public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup) &#123;    super.group(parentGroup);    if (childGroup == null) &#123;        throw new NullPointerException(&quot;childGroup&quot;);    &#125;    if (this.childGroup != null) &#123;        throw new IllegalStateException(&quot;childGroup set already&quot;);    &#125;    this.childGroup = childGroup;    return this;&#125;</code></pre><p>因此通过控制parentGroup和childGroup的线程池大小，可以实现以上各个版本的reactor模型。</p><ul><li>单线程版本：</li></ul><pre><code class="java">NioEventLoopGroup group = new NioEventLoopGroup(1);        ServerBootstrap bootstrap = new ServerBootstrap();        bootstrap.group(group)                .channel(NioServerSocketChannel.class)                .channel(NioServerSocketChannel.class)                .option(ChannelOption.TCP_NODELAY, true)                .option(ChannelOption.SO_BACKLOG, 1024)                .childHandler(new ServerHandlerInitializer());</code></pre><ul><li>多线程版本:</li></ul><pre><code class="java">NioEventLoopGroup eventGroup = new NioEventLoopGroup();ServerBootstrap bootstrap = new ServerBootstrap();bootstrap.group(eventGroup)        .channel(NioServerSocketChannel.class)        .option(ChannelOption.TCP_NODELAY, true)        .option(ChannelOption.SO_BACKLOG, 1024)        .childHandler(new ServerHandlerInitializer());</code></pre><ul><li>主从多线程版本</li></ul><pre><code class="java">NioEventLoopGroup bossGroup = new NioEventLoopGroup();NioEventLoopGroup workerGroup = new NioEventLoopGroup();ServerBootstrap bootstrap = new ServerBootstrap();bootstrap.group(bossGroup,workerGroup)        .channel(NioServerSocketChannel.class)        .option(ChannelOption.TCP_NODELAY, true)        .option(ChannelOption.SO_BACKLOG, 1024)        .childHandler(new ServerHandlerInitializer());</code></pre><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf">Scalable IO in Java</a>   Doug Lea大牛写的文章，简明扼要，网上的资料基本都是从这文章衍生出来的。</li><li><a href="https://www.cnblogs.com/crazymakercircle/p/9833847.html">Reactor模式</a> 这篇文章讲得比较清晰，但是画的图相对容易理解，但是不完全吻合Doug Lea在文章所描述的意思。</li><li><a href="https://segmentfault.com/a/1190000007403873">Netty源码分析</a> 目前网上最好的Netty源码分析</li><li><a href="https://www.infoq.cn/article/netty-threading-model">Netty 系列之 Netty 线程模型</a> 这文章线程模型总结的比较细致</li><li><a href="https://time.geekbang.org/column/article/8805">单服务器高性能模式：Reactor与Proactor</a> 这文章介绍了Reactor模型以及Proactor模型</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NIO </tag>
            
            <tag> Reactor </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>认识 Java NIO</title>
      <link href="/2020/05/14/%E8%AE%A4%E8%AF%86Java-NIO/"/>
      <url>/2020/05/14/%E8%AE%A4%E8%AF%86Java-NIO/</url>
      
        <content type="html"><![CDATA[<p>Java支持三种IO模式，分别是同步阻塞IO（BIO）、同步非阻塞IO（NIO)、多路复用IO（I&#x2F;O multiplexing）以及异步IO(AIO)。本文第一章节将简单介绍这三种IO模式，后续章节将详细介绍同步非阻塞IO（NIO）以及多路复用IO。</p><p>(首页图是蔚来NIO图，侵权必删。&#x3D; &#x3D;! )</p><span id="more"></span><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="同步阻塞IO"><a href="#同步阻塞IO" class="headerlink" title="同步阻塞IO"></a>同步阻塞IO</h3><p>传统的IO是同步阻塞型IO（BIO）。阻塞型IO主要问题是会造成大量的系统资源浪费。例如我们通过Socket读取一个TCP连接的数据，当没有读取到数据时，read方法会阻塞当前线程。如下：</p><p>服务端socket读取数据将阻塞线程：</p><pre><code class="java">ServerSocket serverSocket = bind(listenIp, listenPort);while (true) &#123;    // 阻塞等待数据到来    Socket socket = serverSocket.accept();    // 新建线程来处理该socket数据    executorService.execute(() -&gt; &#123;        BufferedReader br = new BufferedReader(new InputStreamReader(socket.getInputStream()));        // 读取socket中的数据，如无数据将发生阻塞        while (StringUtils.isNotBlank(str = br.readLine()))&#123;            //doSomething        &#125;    &#125;&#125;</code></pre><p>客户端读取数据同样会阻塞线程：</p><pre><code class="java">this.socket = new Socket(this.host, this.port);this.is = socket.getInputStream();// 阻塞读取this.is.read();</code></pre><p>如果服务端接受了大量客户端请求，很有可能使得大量的线程阻塞而占用大量机器资源，甚至使得服务器崩溃。</p><p>除此之外，传统IO是基于字节流的，用户只能顺序地从流中读取数据，且不能随意改变读取指针。</p><h3 id="Java-NIO"><a href="#Java-NIO" class="headerlink" title="Java NIO"></a>Java NIO</h3><p>Java NIO是同步非阻塞型IO。NIO引入了Channel和Buffer这两个概念，用户可以从Channel中读取Buffer，也可以将Buffer写入Channel。<br>实现了AbstractSelectableChannel父类的Channel，可以通过configureBlocking方法可以将一个Channel设置为非阻塞模式，如下：</p><pre><code class="java">serverSocketChannel.configureBlocking(false);</code></pre><h3 id="Java-多路复用IO"><a href="#Java-多路复用IO" class="headerlink" title="Java 多路复用IO"></a>Java 多路复用IO</h3><p>我在这里将多路复用IO从上一小节剥离出来，是想让大家区分同步非阻塞型IO和多路复用IO的区别。</p><p>基于Java NIO的同步非阻塞IO，再结合Java NIO提供的Selector多路复用选择器，Java可以实现多路复用IO。NIO通过将Chanel注册进Selector中，由Selector来监听多个Channel的IO事件，从而避免单个Channel的读写阻塞导致整个线程挂起的情况。这样子，NIO就可以通过一个线程同时高效地管理多个Channel。</p><p>Selector的底层使用了底层系统调用，包括epoll、select等等，在主流的各个系统都有支持。但这部分内容不在本文的探讨范围之内。</p><h3 id="Java-AIO"><a href="#Java-AIO" class="headerlink" title="Java AIO"></a>Java AIO</h3><p>AIO在Java中不常用，可以参考大咖写的 <a href="https://colobu.com/2014/11/13/java-aio-introduction/">Java AIO编程</a></p><h2 id="Buffer"><a href="#Buffer" class="headerlink" title="Buffer"></a>Buffer</h2><p>Buffer在NIO中作为数据的载体，用户可以从Channel中读取Buffer，也可以将Buffer写入Channel。</p><p>Buffer根据数据类型划分为ByteBuffer、ShortBuffer、CharBuffer、DoubleBuffer、FloatBuffer、IntBuffer等类型。这些Buffer都包含了两个子类实现，一个是DirectBuffer，另外一个是HeapBuffer。</p><p>其中以ByteBuffer类型为例，继承关系图如下所示：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E4%BA%86%E8%A7%A3Java%20NIO%2FByteBuffer.png" alt="ByteBuffer.png"></p><h3 id="Buffer使用"><a href="#Buffer使用" class="headerlink" title="Buffer使用"></a>Buffer使用</h3><p>Buffer使用步骤非常简单：</p><ul><li>初始化指定容量大小，并分配directBuffer或heapBuffer；</li><li>初始化后Buffer默认为写模式，用户可以向Buffer中写入数据；</li><li>用户写入完成后，调用flip()方法之后可以切换到读模式；</li><li>Buffer处于读模式下，用户可以读取数据；</li><li>数据读取完毕后，用户可以调用clear()进行清理，或者调用compact()进行压缩。</li></ul><p>使用样例如下:</p><pre><code class="java">public static void main(String[] args) &#123;    //ByteBuffer byteBuffer = ByteBuffer.allocateDirect(9); // direct buffer    ByteBuffer byteBuffer = ByteBuffer.allocate(9);    byteBuffer.put(&quot;hello&quot;.getBytes());    byteBuffer.put(&quot; &quot;.getBytes());    byteBuffer.put(&quot;NIO&quot;.getBytes());    // 写模式切换到读模式    byteBuffer.flip();    byte[] content = new byte[9];    byteBuffer.get(content);    System.out.println(new String(content));&#125;</code></pre><h3 id="Buffer底层实现"><a href="#Buffer底层实现" class="headerlink" title="Buffer底层实现"></a>Buffer底层实现</h3><p>Buffer抽象类里有四个关键字段，他们的大小关系为：mark &lt;&#x3D; position &lt;&#x3D; limit &lt;&#x3D; capacity，分别含义是：</p><ul><li><strong>mark</strong> 调用mark()时候会缓存position的值，等待调用reset()时候恢复使用，默认值为-1；</li><li><strong>postition</strong> 当前的读指针或者写指针所在位置；</li><li><strong>limit</strong> 写模式下等于capacity，而读模式写对应的是写模式下的position；</li><li><strong>capacity</strong> 最大容量，与buffer所处的模式无关。</li></ul><p>测试样例如下：</p><pre><code>@Testpublic void test() &#123;    IntBuffer intBuffer = IntBuffer.allocate(10);    LOG.info(&quot;position=&#123;&#125;, limit=&#123;&#125;, capacity=&#123;&#125;&quot;, intBuffer.position(), intBuffer.limit(), intBuffer.capacity());    intBuffer.put(0);    intBuffer.put(1);    LOG.info(&quot;position=&#123;&#125;, limit=&#123;&#125;, capacity=&#123;&#125;&quot;, intBuffer.position(), intBuffer.limit(), intBuffer.capacity());    intBuffer.flip();    LOG.info(&quot;position=&#123;&#125;, limit=&#123;&#125;, capacity=&#123;&#125;&quot;, intBuffer.position(), intBuffer.limit(), intBuffer.capacity());    intBuffer.get();    LOG.info(&quot;position=&#123;&#125;, limit=&#123;&#125;, capacity=&#123;&#125;&quot;, intBuffer.position(), intBuffer.limit(), intBuffer.capacity());&#125;</code></pre><pre><code>2020-05-15 16:32:20.934 [main] INFO  [IntBufferTest:18] - position=0, limit=10, capacity=102020-05-15 16:32:20.944 [main] INFO  [IntBufferTest:21] - position=2, limit=10, capacity=102020-05-15 16:32:20.944 [main] INFO  [IntBufferTest:23] - position=0, limit=2, capacity=102020-05-15 16:32:20.945 [main] INFO  [IntBufferTest:25] - position=1, limit=2, capacity=10</code></pre><h3 id="Buffer常用API"><a href="#Buffer常用API" class="headerlink" title="Buffer常用API"></a>Buffer常用API</h3><h4 id="flip-写-读"><a href="#flip-写-读" class="headerlink" title="flip 写-&gt;读"></a>flip 写-&gt;读</h4><p>flip方法可以将buffer从写模式切换到读模式。原理很简单，就是将limit置为当前position，且position置0。</p><pre><code class="java">public final Buffer flip() &#123;    limit = position;    position = 0;    mark = -1;    return this;&#125;</code></pre><h4 id="clear-读-写-读"><a href="#clear-读-写-读" class="headerlink" title="clear 读,写 -&gt; 读"></a>clear 读,写 -&gt; 读</h4><p>clear方法不管buffer是读或写状态，都会清空buffer，重新恢复为初始写状态。但需要注意clear并<strong>没有清空原有数据</strong>，仅仅是修改了指针位置。依然可以读取到老的数据。</p><pre><code class="java">public final Buffer clear() &#123;    position = 0;    limit = capacity;    mark = -1;    return this;&#125;</code></pre><h4 id="compact-读-写"><a href="#compact-读-写" class="headerlink" title="compact 读 -&gt; 写"></a>compact 读 -&gt; 写</h4><p>该方法是Buffer子类里的方法，用于在读模式下压缩空间，将还没读到的数据复制到缓存数组开头，也就是从[position, limit)复制到[0, limit-position)。注意compact仅限于读模式下调用，调用之后buffer切换为写模式。以HeapIntBuffer为例：</p><pre><code class="java">public IntBuffer compact() &#123;    // 复制[position, limit)到[0, limit-position)    System.arraycopy(hb, ix(position()), hb, ix(0), remaining());    // position置为limit-position，也就是写指针所在位置    position(remaining());    // 写模式下limit等于capacity    limit(capacity());    // 丢弃mark状态    discardMark();    return this;&#125;</code></pre><h4 id="rewind"><a href="#rewind" class="headerlink" title="rewind"></a>rewind</h4><p>很容易将clear和revind混淆，其实看看源码就知道区别：</p><pre><code class="java">public final Buffer rewind() &#123;    position = 0;    mark = -1;    return this;&#125;</code></pre><p>由上可见，rewind没有修改limit，也就是没有切换buffer的读写模式，单纯是将position置为0。如果是读模式，相当于将读过的数据，重新从指针0开始再读一遍；如果是写模式，则是忽略已经写过的数据，从指针0位置重新开始写。</p><h4 id="mark-reset"><a href="#mark-reset" class="headerlink" title="mark &amp;&amp; reset"></a>mark &amp;&amp; reset</h4><p>mark方法可以缓存当前的position指针，而reset方法则是将position恢复为之前mark所缓存的值。</p><p>注意上边提及的所有方法都可以丢弃mark缓存，也就是说mark &amp;&amp; reset只有在读模式或者写模式写才能有效。例如：</p><pre><code class="java">@Testpublic void testMark() &#123;    IntBuffer intBuffer = IntBuffer.allocate(10);    intBuffer.put(0);    intBuffer.put(1);    LOG.info(&quot;buffer=&#123;&#125;&quot;, intBuffer);    intBuffer.mark();    intBuffer.put(2);    intBuffer.put(3);    intBuffer.reset();    LOG.info(&quot;buffer=&#123;&#125;&quot;, intBuffer);&#125;</code></pre><pre><code class="bash">2020-05-15 18:04:23.873 [main] INFO  [IntBufferTest:60] - buffer=java.nio.HeapIntBuffer[pos=2 lim=10 cap=10]2020-05-15 18:04:23.880 [main] INFO  [IntBufferTest:65] - buffer=java.nio.HeapIntBuffer[pos=2 lim=10 cap=10]</code></pre><p>如图调用reset方法后，position重新恢复为mark所缓存的值。这时候继续写入数据的话，就会覆盖掉数值2和3。</p><h3 id="Buffer的比较"><a href="#Buffer的比较" class="headerlink" title="Buffer的比较"></a>Buffer的比较</h3><p>以IntBuffer为例子，请见源码：</p><pre><code class="java">public int compareTo(IntBuffer that) &#123;    int n = this.position() + Math.min(this.remaining(), that.remaining());    for (int i = this.position(), j = that.position(); i &lt; n; i++, j++) &#123;        int cmp = compare(this.get(i), that.get(j));        if (cmp != 0)            return cmp;    &#125;    return this.remaining() - that.remaining();&#125;</code></pre><p>从源码可以看出两个buffer的比较其实只是对剩余未读的数据进行对比。换言之，只有处于读模式的buffer进行比较才会有意义。</p><h2 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h2><p>channel在NIO中作为数据流的通道。常用几个Channel子类包括：FileChannel、DatagramChannel、SocketChannel、ServerSocketChannel等。继承关系如下：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E4%BA%86%E8%A7%A3Java%20NIO%2Fchannel%E7%BB%A7%E6%89%BF%E5%85%B3%E7%B3%BB.png" alt="channel继承关系.png"></p><h3 id="FileChannel"><a href="#FileChannel" class="headerlink" title="FileChannel"></a>FileChannel</h3><p>常用API：</p><ul><li><strong>open(Path path, OpenOption… options)</strong> 打开文件，可以通过options指定文件的打开参数（读写模式等）；</li><li><strong>read(ByteBuffer dst)</strong> 从channel中读取数据，并写入ByteBuffer中；</li><li><strong>write(ByteBuffer src)</strong> 读取ByteBuffer中的数据，并写入channel中；</li><li><strong>position(long newPosition)</strong> 设置channel的position；</li><li><strong>force(boolean metaData)</strong> 强制使得文件的所有变更落盘。metaData为true表示文件元数据变更也落盘，否则仅文件内容变更落盘；</li><li><strong>transferTo(long position, long count,WritableByteChannel target)</strong> 将该fileChannel内容写入目标channel中；</li><li><strong>truncate(long size)</strong> 将该channel截取为若干字节。</li></ul><p>使用样例：</p><pre><code class="java">     @Test    public void testInputFromFileChannel() &#123;        FileChannel fileChannel = null;        try &#123;            fileChannel = FileChannel.open(new File(&quot;/Users/duval/input.txt&quot;).toPath(), StandardOpenOption.READ);            ByteBuffer readBuffer = ByteBuffer.allocate(100);            StringBuilder fileContent = new StringBuilder();            while (fileChannel.read(readBuffer) != -1) &#123;                readBuffer.flip();                fileContent.append(new String(readBuffer.array()));                readBuffer.clear();            &#125;            System.out.println(fileContent.toString());        &#125; catch (IOException e) &#123;            LOG.error(&quot;read failed&quot;, e);        &#125; finally &#123;            IOUtils.closeQuietly(fileChannel);        &#125;    &#125;    @Test    public void testOutputToFileChannel() &#123;        FileChannel fileChannel = null;        try &#123;            fileChannel =  FileChannel.open(new File(&quot;/Users/duval/output.txt&quot;).toPath(), StandardOpenOption.WRITE, StandardOpenOption.CREATE);            ByteBuffer writeBuffer = ByteBuffer.allocate(1000);            writeBuffer.put(&quot;hello nio&quot;.getBytes());            writeBuffer.flip();            while (writeBuffer.hasRemaining()) &#123;                fileChannel.write(writeBuffer);            &#125;            // 强制数据落盘            fileChannel.force(true);        &#125; catch (IOException e) &#123;            LOG.error(&quot;write failed&quot;, e);        &#125; finally &#123;            IOUtils.closeQuietly(fileChannel);        &#125;    &#125;</code></pre><h3 id="DatagramChannel"><a href="#DatagramChannel" class="headerlink" title="DatagramChannel"></a>DatagramChannel</h3><p>DatagramChannel可以用来实现UDP通讯。常用的API如下:</p><ul><li><strong>DatagramChannel open()</strong> 打开一个新的channel；</li><li><strong>DatagramChannel bind(SocketAddress local)</strong> 将该channel绑定到某个地址上（ip+端口）；</li><li><strong>SocketAddress receive(java.nio.ByteBuffer dst)</strong> 接收数据；</li><li><strong>int send(java.nio.ByteBuffer src, java.net.SocketAddress target)</strong> 发送数据；</li></ul><p>使用样例：</p><pre><code class="java">// UdpServer.java/** * @author duval * @date 2020-05-17 20:17 */@Slf4jpublic class UdpServer extends Thread &#123;    private DatagramChannel channel;    public UdpServer() throws IOException &#123;        this.channel = DatagramChannel.open();        this.channel.bind(new InetSocketAddress(&quot;localhost&quot;, 8080));    &#125;    @Override    public void run() &#123;        int num = 0;        while (true) &#123;            SocketAddress address;            ByteBuffer byteBuffer = ByteBuffer.allocate(15);            try &#123;                address = channel.receive(byteBuffer);                if (address != null &amp;&amp; byteBuffer.hasRemaining()) &#123;                    byte[] array = new byte[byteBuffer.position()];                    byteBuffer.flip();                    byteBuffer.get(array);                    byteBuffer.clear();                    log.info(&quot;reveive:&#123;&#125;&quot;, new String(array));                    response(address, num++);                &#125;            &#125; catch (IOException e) &#123;                log.error(&quot;receive failed&quot;, e);            &#125;        &#125;    &#125;    private void response(SocketAddress address, int num) throws IOException &#123;        ByteBuffer content = ByteBuffer.allocate(15);        content.put((&quot;resp &quot; + num).getBytes());        content.flip();        channel.send(content, address);    &#125;    public static void main(String args[]) throws IOException, InterruptedException &#123;        UdpServer server = new UdpServer();        server.start();        server.join();    &#125;&#125;</code></pre><pre><code class="java">// UdpClient.java@Slf4jpublic class UdpClient extends Thread &#123;    private DatagramChannel channel;    public UdpClient() throws IOException &#123;        this.channel = DatagramChannel.open();    &#125;    @Override    public void run() &#123;        new Thread(new Runnable() &#123;            @Override            public void run() &#123;                while (true) &#123;                    SocketAddress address;                    ByteBuffer dataBuffer = ByteBuffer.allocate(15);                    try &#123;                        address = channel.receive(dataBuffer);                        if (address != null &amp;&amp; dataBuffer.hasRemaining()) &#123;                            byte [] array = new byte[dataBuffer.position()];                            dataBuffer.flip();                            dataBuffer.get(array);                            dataBuffer.clear();                            log.info(&quot;reveive:&#123;&#125;&quot;, new String(array));                        &#125;                    &#125; catch (IOException e) &#123;                        log.error(&quot;receive failed&quot;, e);                    &#125;                &#125;            &#125;        &#125;).start();        Scanner scanner = new Scanner(System.in);        while (true) &#123;            String inputData =  scanner.nextLine();            if (inputData.length() &gt; 10) &#123;                log.error(&quot;too long&quot;);                continue;            &#125;            ByteBuffer dataBuffer = ByteBuffer.allocate(15);            dataBuffer.put(inputData.getBytes());            dataBuffer.flip();            try &#123;                channel.send(dataBuffer, new InetSocketAddress(&quot;localhost&quot;, 8080));            &#125; catch (IOException e) &#123;                log.error(&quot;send failed&quot;, e);            &#125;        &#125;    &#125;    public static void main(String args[]) throws IOException, InterruptedException &#123;        UdpClient client = new UdpClient();        client.run();        client.join();    &#125;&#125;</code></pre><h3 id="ServerSocketChannel"><a href="#ServerSocketChannel" class="headerlink" title="ServerSocketChannel"></a>ServerSocketChannel</h3><p>ServerSocketChannel用于TCP连接的服务器端。常用的API如下所示：</p><ul><li>打开Channel、关闭Channel</li></ul><pre><code class="java">ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.close();</code></pre><ul><li>绑定监听地址端口</li></ul><pre><code class="java">serverSocketChannel.socket().bind(new InetSocketAddress(8080));</code></pre><ul><li>等待客户度连接</li></ul><pre><code class="java">SocketChannel clientChannel = serverSocketChannel.accept();</code></pre><ul><li>指定阻塞或非阻塞</li></ul><pre><code class="java">serverSocketChannel.configureBlocking(false);</code></pre><p>ServerSocketChannel初始化后默认是阻塞模式。比方说在阻塞模式下调用accept()方法后会阻塞进程等待直到有新的客户端连接到来，而在非阻塞模式下调用accept()方法不会发生阻塞而立即返回客户端socket（没有客户端连接时候返回null）。</p><ul><li>将channel注册到selector中</li></ul><pre><code class="java">serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);</code></pre><p>Selector是NIO里核心组件，下一个章节将会详细介绍。当channel处于非阻塞模式，可以被注册到Selector中，由Selector代理接收所有的IO事件。</p><h3 id="SocketChannel"><a href="#SocketChannel" class="headerlink" title="SocketChannel"></a>SocketChannel</h3><p>与ServerSocketChannel对应，SocketChannel适用于TCP连接的客户端。常用API如下：</p><ul><li>打开关闭Channel</li></ul><pre><code class="java">SocketChannel sc = SocketChannel.open();sc.close();</code></pre><ul><li>连接服务器</li></ul><pre><code class="java">sc.connect(new InetSocketAddress(&quot;localhost&quot;, 8080));</code></pre><ul><li>指定阻塞或非阻塞</li></ul><pre><code class="java">sc.configureBlocking(false);</code></pre><ul><li>注册到Selector</li></ul><pre><code class="java">sc.register(selector, SelectionKey.OP_CONNECT);</code></pre><ul><li>读写数据</li></ul><pre><code>sc.write(writeBuffer);sc.read(readBuffer);</code></pre><h2 id="Selector"><a href="#Selector" class="headerlink" title="Selector"></a>Selector</h2><p>Selector是NIO实现IO多路复用模型的重要组件。多个Channel可以被注册到同一个Selector上，然后Selector会不断的轮询注册在它上面的Channel。一旦某个Channel有了新的IO事件就会被筛选出来进一步处理。因此，只需要一个线程负责Selector的轮询，就能够支撑大量的连接，从而能够支撑高并发服务的开发。基于Selector实现的IO多路复用模型示意图如下：</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E4%BA%86%E8%A7%A3Java%20NIO%2FIO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E6%A8%A1%E5%9E%8B.png" alt="IO多路复用模型.png"></p><h3 id="KQueueSelectorImpl"><a href="#KQueueSelectorImpl" class="headerlink" title="KQueueSelectorImpl"></a>KQueueSelectorImpl</h3><p>在MacOS下，Selector的默认实现是KQueueSelectorImpl，可以在JDK8源码下找到：openjdk-jdk8u-jdk8u&#x2F;jdk&#x2F;src&#x2F;macosx&#x2F;classes&#x2F;sun&#x2F;nio&#x2F;ch&#x2F;KQueueSelectorImpl.java</p><p>KQueueSelectorImpl继承关系如下：<br><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog%2F%E4%BA%86%E8%A7%A3Java%20NIO%2FKQueueSelectorImpl.jpg" alt="KQueueSelectorImpl.jpg"></p><p>而在Linux 2.6+内核下，Selector的默认实现是是EPollSelectorImpl，源码在中：openjdk-jdk8u-jdk8u&#x2F;jdk&#x2F;src&#x2F;solaris&#x2F;classes&#x2F;sun&#x2F;nio&#x2F;ch&#x2F;EPollSelectorImpl.java</p><p>我们从父类SelectorImpl里可以看到两个字段：</p><pre><code class="java">    // The set of keys with data ready for an operation    protected Set&lt;SelectionKey&gt; selectedKeys;    // The set of keys registered with this Selector    protected HashSet&lt;SelectionKey&gt; keys;</code></pre><p>selectedKeys保存的是有新IO事件等待处理的Key；而keys保存的是所有的被注册到该Selector的key。</p><h3 id="SelectionKey"><a href="#SelectionKey" class="headerlink" title="SelectionKey"></a>SelectionKey</h3><p>上文提到SelectionKey，这究竟为何物，我们一起来探讨下。先看看常用的API：</p><ul><li><strong>public final Object attachment()</strong> 获取该SelectionKey的附加物。attachment常常用来附加数据。</li><li><strong>public abstract int interestOps()</strong> 获取感兴趣事件集合。Channel在注册时候可以指定感兴趣的事件。这里返回int，因为用位来表示事件。</li><li><strong>public abstract int readyOps()</strong> 获取已经就绪的事件集合。这里返回int，因为用位来表示事件。</li><li><strong>public abstract SelectableChannel channel()</strong> 返回该key关联的channel实例。</li><li><strong>public abstract Selector selector()</strong> 返回该key关联的Selector</li><li><strong>public final boolean isAcceptable()</strong> 检查OP_ACCEPT事件是否就绪。如果就绪，表示有新的stocket连接。</li><li><strong>public final boolean isConnectable()</strong> 检查OP_CONNECT事件是否就绪。如果就绪，表示可以发起连接到服务器。</li><li><strong>public final boolean isReadable()</strong> 检查OP_READ事件是否就绪，如果就绪则表示可以开始读取socket中的数据。</li><li><strong>public final boolean isWritable()</strong> 检查OP_WRITE事件是否就绪，如果就绪，表示可以写数据到Channel中。</li></ul><p>从上可以看到，SelectionKey其实是将channel实例和Selector关联起来，并且包含了就绪事件集合以及附加物的一个数据结构。</p><h3 id="将Channel注册到Selector"><a href="#将Channel注册到Selector" class="headerlink" title="将Channel注册到Selector"></a>将Channel注册到Selector</h3><p>实现了SelectableChannel的实例可以调用register方法进行注册。</p><pre><code class="java">SelectionKey selectionKey = socketChannel.register(selector, SelectionKey.OP_WRITE);</code></pre><p>从register调试，就到了AbstractSelectableChannel的register方法：</p><pre><code class="java">public final SelectionKey register(Selector sel, int ops,                                       Object att)        throws ClosedChannelException    &#123;        synchronized (regLock) &#123;            if (!isOpen())                throw new ClosedChannelException();            if ((ops &amp; ~validOps()) != 0)                throw new IllegalArgumentException();            // 如果是阻塞型Channel，则抛异常终止。            // 所以需要调用configureBlocking(false)，标记为非阻塞Channel            if (blocking)                throw new IllegalBlockingModeException();            // 从缓存中加锁获取与该Selector对应的SelectionKey            SelectionKey k = findKey(sel);            if (k != null) &#123;                // 将入参指定的事件ops记录到interestOps中去。                k.interestOps(ops);                // 更新附加物，这里默认为null                k.attach(att);            &#125;            // 如果SelectionKey不存在，则调用Selector的register方法来注册。            if (k == null) &#123;                // New registration                synchronized (keyLock) &#123;                    if (!isOpen())                        throw new ClosedChannelException();                    k = ((AbstractSelector)sel).register(this, ops, att);                    addKey(k);                &#125;            &#125;            return k;        &#125;    &#125;</code></pre><p>注册步骤总结：</p><ul><li><ol><li>实现了SelectableChannel的实例调用register方法，入参需要指定Selector和注册事件，也可以指定附加物；</li></ol></li><li><ol start="2"><li>在SelectableChannel的register方法中，先加锁去缓存中找有没有Selector对应的SelectionKey</li></ol><ul><li>2.1 如果有，就直接通过缓存的key来更新注册时间以及附加物。（因为这两个字段都是volatile，能确保可见性)。</li><li>2.2 如果没有，则通过Selector的register方法来注册事件，并返回新建的key。</li></ul></li></ul><h3 id="Selector使用样例"><a href="#Selector使用样例" class="headerlink" title="Selector使用样例"></a>Selector使用样例</h3><h4 id="Sever端"><a href="#Sever端" class="headerlink" title="Sever端"></a>Sever端</h4><pre><code class="java">public class NioEchoServer &#123;    private ByteBuffer writeBuffer = ByteBuffer.allocate(1024);    private ByteBuffer readBuffer = ByteBuffer.allocate(1024);    private static final int BUF_SIZE = 256;    private static final int TIMEOUT = 10000;    public void start() throws Exception &#123;        // 打开服务端 Socket        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();                // 打开 Selector        Selector selector = Selector.open();        // 服务端 Socket 监听8080端口, 并配置为非阻塞模式        serverSocketChannel.socket().bind(new InetSocketAddress(8080));        serverSocketChannel.configureBlocking(false);        // 将 channel 注册到 selector 中.        // 通常我们都是先注册一个 OP_ACCEPT 事件, 然后在 OP_ACCEPT 到来时, 再将这个 Channel 的 OP_READ        // 注册到 Selector 中.        serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);        Scanner scanner = new Scanner(System.in);        while (true) &#123;            // 通过调用 select 方法, 阻塞地等待 channel I/O 可操作            if (selector.select(TIMEOUT) == 0) &#123;                System.out.println(&quot;.&quot;);                continue;            &#125;            // 获取 I/O 操作就绪的 SelectionKey, 通过 SelectionKey 可以知道哪些 Channel 的哪类 I/O 操作已经就绪.            Iterator&lt;SelectionKey&gt; keyIterator = selector.selectedKeys().iterator();            while (keyIterator.hasNext()) &#123;                SelectionKey key = keyIterator.next();                // 当获取一个 SelectionKey 后, 就要将它删除, 表示我们已经对这个 IO 事件进行了处理.                keyIterator.remove();                if (key.isAcceptable()) &#123;                    System.out.println(&quot;new client connected...&quot;);                    // 当 OP_ACCEPT 事件到来时, 我们就有从 ServerSocketChannel 中获取一个 SocketChannel,                    // 代表客户端的连接                    // 注意, 在 OP_ACCEPT 事件中, 从 key.channel() 返回的 Channel 是 ServerSocketChannel.                    // 而在 OP_WRITE 和 OP_READ 中, 从 key.channel() 返回的是 SocketChannel.                    SocketChannel clientChannel = ((ServerSocketChannel) key.channel()).accept();                    clientChannel.configureBlocking(false);                    //在 OP_ACCEPT 到来时, 再将这个 Channel 的 OP_READ 注册到 Selector 中.                    // 注意, 这里我们如果没有设置 OP_READ 的话, 即 interest set 仍然是 OP_CONNECT 的话, 那么 select 方法会一直直接返回.                    clientChannel.register(key.selector(), OP_READ, ByteBuffer.allocate(BUF_SIZE));                &#125;                if (key.isReadable()) &#123;                    SocketChannel clientChannel = (SocketChannel) key.channel();                    readBuffer = (ByteBuffer) key.attachment();                    int bytesRead = clientChannel.read(readBuffer);                    if (bytesRead == -1) &#123;                        clientChannel.close();                    &#125; else if (bytesRead &gt; 0) &#123;                        key.interestOps(OP_READ | SelectionKey.OP_WRITE);                        System.out.println(&quot;receive:&quot; + new String(readBuffer.array(), 0, bytesRead));                    &#125;                &#125;                if (key.isValid() &amp;&amp; key.isWritable()) &#123;                    System.out.print(&quot;send:&quot;);                    String input = scanner.nextLine();                    writeBuffer.clear();                    writeBuffer.put(input.getBytes());                    //将缓冲区各标志复位,因为向里面put了数据标志被改变要想从中读取数据发向服务器,就要复位                    writeBuffer.flip();                    SocketChannel clientChannel = (SocketChannel) key.channel();                    clientChannel.write(writeBuffer);                    if (!writeBuffer.hasRemaining()) &#123;                        key.interestOps(OP_READ);                    &#125;                    writeBuffer.compact();                &#125;            &#125;        &#125;    &#125;    public static void main(String args[]) throws Exception &#123;        new NioEchoServer().start();    &#125;&#125;</code></pre><h3 id="Client端"><a href="#Client端" class="headerlink" title="Client端"></a>Client端</h3><pre><code class="java">public class NioEchoClient &#123;    private static ByteBuffer writeBuffer = ByteBuffer.allocate(1024);    private static ByteBuffer readBuffer = ByteBuffer.allocate(1024);    private static final int TIMEOUT = 10000;    public static void main(String[] args) throws IOException &#123;        // 打开socket通道        SocketChannel sc = SocketChannel.open();        // 设置为非阻塞        sc.configureBlocking(false);        // 连接服务器        sc.connect(new InetSocketAddress(&quot;localhost&quot;, 8080));        // 打开选择器        Selector selector = Selector.open();        // 注册连接服务器        sc.register(selector, SelectionKey.OP_CONNECT);        Scanner scanner = new Scanner(System.in);        while (true) &#123;            while (selector.select(TIMEOUT) == 0) &#123;                System.out.println(&quot;.&quot;);                continue;            &#125;            //返回此选择器的已选择键集。            Set&lt;SelectionKey&gt; keys = selector.selectedKeys();            Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator();            while (keyIterator.hasNext()) &#123;                SelectionKey key = keyIterator.next();                keyIterator.remove();                // 判断此通道上是否正在进行连接操作。                if (key.isConnectable()) &#123;                    sc.finishConnect();                    sc.register(selector, SelectionKey.OP_WRITE);                    System.out.println(&quot;server connected...&quot;);                    break;                &#125; else if (key.isWritable()) &#123;                    System.out.print(&quot;send:&quot;);                    String message = scanner.nextLine();                    writeBuffer.clear();                    writeBuffer.put(message.getBytes());                    //将缓冲区各标志复位,因为向里面put了数据标志被改变要想从中读取数据发向服务器,就要复位                    writeBuffer.flip();                    sc.write(writeBuffer);                    //注册写操作,每个chanel只能注册一个操作，最后注册的一个生效                    //如果你对不止一种事件感兴趣，那么可以用“位或”操作符将常量连接起来                    //int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE;                    //使用interest集合                    sc.register(selector, SelectionKey.OP_READ);                    sc.register(selector, SelectionKey.OP_WRITE);                    sc.register(selector, SelectionKey.OP_READ);                &#125; else if (key.isReadable()) &#123;                    SocketChannel client = (SocketChannel) key.channel();                    //将缓冲区清空以备下次读取                    readBuffer.clear();                    int num = client.read(readBuffer);                    System.out.println(&quot;receive:&quot; + new String(readBuffer.array(), 0, num));                    //注册读操作，下一次读取                    sc.register(selector, SelectionKey.OP_WRITE);                &#125;            &#125;        &#125;    &#125;&#125;</code></pre><ul><li><strong>参考资料</strong></li><li><a href="http://tutorials.jenkov.com/java-nio/index.html"><strong>Java NIO Tutorial</strong></a> 很好的NIO教程，比国内的大部分资料都齐全。</li><li><a href="https://www.cnblogs.com/crazymakercircle/p/10225159.html"><strong>10分钟看懂， Java NIO 底层原理</strong></a> 将Java四大IO模型讲得通俗易懂透彻的文章。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NIO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生产问题(1) Java进程CPU占用过高</title>
      <link href="/2020/02/11/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98-1-Java%E8%BF%9B%E7%A8%8BCPU%E5%8D%A0%E7%94%A8%E8%BF%87%E9%AB%98/"/>
      <url>/2020/02/11/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98-1-Java%E8%BF%9B%E7%A8%8BCPU%E5%8D%A0%E7%94%A8%E8%BF%87%E9%AB%98/</url>
      
        <content type="html"><![CDATA[<p>从一个实际生产问题出发，教你如何排查Java进程CPU占用过高。</p><span id="more"></span><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>最近我开发了一个流量非常大的股票数据分发服务。服务上线后，服务器的CPU占用一直很高。初期考虑到股票流量很大，而且下游支撑了很多服务的分发需求，线程之间切换频繁，CPU占用高似乎也合理。</p><p>后来，在一次交易所休市时段，我偶然上服务器top了一下，竟然发现该服务的CPU占比依然非常高：</p><pre><code class="bash">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND  2652 prod     20   0   12.0g   7.8g  18008 S 202.0 57.1 117424:06 java</code></pre><p>从上边看到，这个Java进程占用了两个CPU核心。而当前是交易所休市阶段，流量非常低，这个CPU占用肯定是不正常。于是我决定好好排查下。</p><h2 id="问题推测"><a href="#问题推测" class="headerlink" title="问题推测"></a>问题推测</h2><h3 id="服务器负载过高？"><a href="#服务器负载过高？" class="headerlink" title="服务器负载过高？"></a>服务器负载过高？</h3><p>首先是怀疑服务的确是处于非常高的负载状态。但查看服务后台监控系统发现实时流量才小十几万帧&#x2F;分钟，并且这个服务属于IO密集型而不是CPU密集型，这么小的流量完全不可能占用200%CPU。</p><p><img src="https://pic-bed-sz.oss-cn-shenzhen.aliyuncs.com/blog/%E7%94%9F%E4%BA%A7%E9%97%AE%E9%A2%98--Java%E8%BF%9B%E7%A8%8BCPU%E5%8D%A0%E7%94%A8%E8%BF%87%E9%AB%98/QDS%E9%9B%86%E7%BE%A4%E5%88%86%E5%8F%91%E8%B4%9F%E8%BD%BD.png" alt="集群负载截图"></p><h3 id="死循环？"><a href="#死循环？" class="headerlink" title="死循环？"></a>死循环？</h3><p>排除掉负载问题后，只能考虑是有些线程出现了死循环。于是尝试<strong>查看线程的CPU占用情况</strong>。使用命令： <em>top -H -p [JAVA进程号]</em> ，如下：</p><pre><code class="bash">  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND 2972 prod      20   0   12.0g   7.8g  18008 R 99.9 57.1  54624:29 java 2971 prod      20   0   12.0g   7.8g  18008 R 99.9 57.1  54620:12 java 3233 prod      20   0   12.0g   7.8g  18008 S  0.3 57.1 886:17.26 java 3248 prod      20   0   12.0g   7.8g  18008 S  0.3 57.1 994:43.62 java 8902 prod      20   0   12.0g   7.8g  18008 S  0.3 57.1 511:27.79 java......</code></pre><p>上边的列表打印出来了这个JAVA进程的线程号(PID)、CPU占用（%CPU)等信息。呵！可以看到PID为2971和2972的线程排在前边，两个都几乎占了一个CPU核心！想必就是死循环了吧!</p><h2 id="问题诊断"><a href="#问题诊断" class="headerlink" title="问题诊断"></a>问题诊断</h2><p>既然明确了是这两个线程的问题，那就把这两个线程找出来，看看代码逻辑便知。</p><p>这里要用到 jstack 命令,这个命令在<a href="https://blog.duval.top/2017/06/18/JVM%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E6%80%BB%E7%BB%93/">《JVM性能监控工具总结》</a>讲过，这里不重复。</p><p>这两个线程的PID从<a href="https://tool.oschina.net/hexconvert">十进制转化为十六进制</a>，分别是b9b和b9c，然后用这两个值去jstack结果里边查找一下，便有如下结果：</p><pre><code class="bash">[prod@xxxxxxxxxxxx xxxx-xxxxxxxxx-service]$ jstack 2652 |egrep -A 8 &quot;b9b|b9c&quot;&quot;Pool-Default-schedule-0&quot; #26 prio=5 os_prio=0 tid=0x00007f9eb243e000 nid=0xb9c runnable [0x00007f9e1dff6000]   java.lang.Thread.State: RUNNABLE    at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.poll(ScheduledThreadPoolExecutor.java:809)    at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)    at java.lang.Thread.run(Thread.java:748)&quot;Pool-Monitor-schedule-0&quot; #25 prio=5 os_prio=0 tid=0x00007f9eb2576000 nid=0xb9b runnable [0x00007f9e1e0f7000]   java.lang.Thread.State: RUNNABLE    at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.poll(ScheduledThreadPoolExecutor.java:809)    at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)    at java.lang.Thread.run(Thread.java:748)</code></pre><p>这个查询结果让人非常费解，堆栈显示这明明是java的concurrent包的代码栈，而不是业务逻辑。</p><p>然后循着<em>Pool-Default-schedule-0</em>和<em>Pool-Monitor-schedule-0</em>这两个自定义的线程池名字去找线程池调用的地方(这里说明了自定义线程池名字非常重要！)，却发现调用的地方逻辑都非常简单，诸如:</p><pre><code class="java">executorService.scheduleAtFixedRate(this::refreshBalancer, 0, 1, TimeUnit.MINUTES);</code></pre><p>这根本不可能有死循环产生！</p><h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><p>后来利用关键字”ScheduledThreadPoolExecutor high cpu”到谷歌一搜，才发现原来是ScheduledThreadPoolExecutor在JDK8版本有bug。参考:<a href="https://bugs.openjdk.java.net/browse/JDK-8129861">《High processor load for ScheduledThreadPoolExecutor with 0 core threads》</a>.</p><p>问题就是：在JDK8中，ScheduledThreadPoolExecutor的coreSize为0的话，存在CPU占用100%的BUG。</p><p>解决办法：coreSize改为非0值，或者升级到JDK9。</p>]]></content>
      
      
      <categories>
          
          <category> 总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生产问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入JAVA语言—CAS原理剖析</title>
      <link href="/2020/01/05/%E6%B7%B1%E5%85%A5JAVA%E8%AF%AD%E8%A8%80%E2%80%94CAS%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90/"/>
      <url>/2020/01/05/%E6%B7%B1%E5%85%A5JAVA%E8%AF%AD%E8%A8%80%E2%80%94CAS%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<p>JAVA的并发编程包（java.util.concurrent）中的源码大量用到CAS操作。<br>CAS操作使得JAVA可以低成本地实现并发操作。<br>本文将深入探讨CAS操作的实现原理。</p><span id="more"></span><h2 id="什么是CAS操作"><a href="#什么是CAS操作" class="headerlink" title="什么是CAS操作"></a>什么是CAS操作</h2><p>CAS（Compare and Swap），也就是比较并替换，简单说就是有三个值：当前内存值（current value)、内存期望值（expected value)、更新值（updated value),当且仅当当前内存值等于内存期望值的时候，将内存值修改为更新值，并且返回true，否则不作任何操作直接返回false。需要注意的事，该操作是<strong>原子操作</strong>。</p><p>例如，AtomicInteger里的compareAndSet方法</p><pre><code class="java">/**     * Atomically sets the value to the given updated value     * if the current value &#123;@code ==&#125; the expected value.     *     * @param expect the expected value     * @param update the new value     * @return &#123;@code true&#125; if successful. False return indicates that     * the actual value was not equal to the expected value.     */    public final boolean compareAndSet(int expect, int update) &#123;        return unsafe.compareAndSwapInt(this, valueOffset, expect, update);    &#125;</code></pre><h2 id="Unsafe类"><a href="#Unsafe类" class="headerlink" title="Unsafe类"></a>Unsafe类</h2><p>JAVA的CAS操作底层都是调用了Unsafe类内部的native方法。这些方法通过JNI调用，直接调用了底层的C语言接口，使得JAVA可以直接操作内存空间。</p><p>我们注意到前文提到的unsafe.compareAndSwapInt方法的入参中，有一个静态字段valueOffset。这个字段表示的是value字段在内存相对偏移量，在初始化的时候获取。如下：</p><pre><code class="java">    private static final long valueOffset;    static &#123;        try &#123;            valueOffset = unsafe.objectFieldOffset                (AtomicInteger.class.getDeclaredField(&quot;value&quot;));        &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;    &#125;</code></pre><p>所有的unsafe的native方法，追踪到hotspot源码，都在hotspot&#x2F;src&#x2F;share&#x2F;vm&#x2F;prims&#x2F;unsafe.cpp中实现。</p><h2 id="获取字段的字节偏移量"><a href="#获取字段的字节偏移量" class="headerlink" title="获取字段的字节偏移量"></a>获取字段的字节偏移量</h2><p>先来看unsafe.objectFieldOffset，我对C++不是特别熟悉，但从语义上其实可以看出，这个方法是根据字段类型<strong>获取其相对偏移字节数</strong>。</p><pre><code class="c++">// hotspot/src/share/vm/prims/unsafe.cppinline jlong field_offset_from_byte_offset(jlong byte_offset) &#123;  return byte_offset;&#125;jint find_field_offset(jobject field, int must_be_static, TRAPS) &#123;  if (field == NULL) &#123;    THROW_0(vmSymbols::java_lang_NullPointerException());  &#125;  oop reflected   = JNIHandles::resolve_non_null(field);  oop mirror      = java_lang_reflect_Field::clazz(reflected);  Klass* k      = java_lang_Class::as_Klass(mirror);  int slot        = java_lang_reflect_Field::slot(reflected);  int modifiers   = java_lang_reflect_Field::modifiers(reflected);  if (must_be_static &gt;= 0) &#123;    int really_is_static = ((modifiers &amp; JVM_ACC_STATIC) != 0);    if (must_be_static != really_is_static) &#123;      THROW_0(vmSymbols::java_lang_IllegalArgumentException());    &#125;  &#125;  int offset = InstanceKlass::cast(k)-&gt;field_offset(slot);  return field_offset_from_byte_offset(offset);&#125;UNSAFE_ENTRY(jlong, Unsafe_ObjectFieldOffset(JNIEnv *env, jobject unsafe, jobject field))  UnsafeWrapper(&quot;Unsafe_ObjectFieldOffset&quot;);  return find_field_offset(field, 0, THREAD);UNSAFE_END</code></pre><h2 id="原子操作的实现"><a href="#原子操作的实现" class="headerlink" title="原子操作的实现"></a>原子操作的实现</h2><p>然后接着来看compareAndSwapInt的native实现，先是利用上文获取的字节偏移量offset，获取需要进行CAS操作的对象所在的地址。这部分功能在index_oop_from_field_offset_long中实现，此处不作展开。此外可以看到，<br>该方法接着通过 Atomic::cmpxchg 来实现比较和替换操作，其中参数x是即将更新的值，参数e是原内存的值。如下：</p><pre><code>UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x))  UnsafeWrapper(&quot;Unsafe_CompareAndSwapInt&quot;);  oop p = JNIHandles::resolve(obj);  jint* addr = (jint *) index_oop_from_field_offset_long(p, offset);  return (jint)(Atomic::cmpxchg(x, addr, e)) == e;UNSAFE_END</code></pre><p>最关键的原子操作Atomic::cmpxchg。这个方法在不同的操作系统中实现不一样，这里以linux x86为例：</p><pre><code class="c++">// hotspot/src/os_cpu/linux_x86/vm/atomic_linux_x86.inline.hpp// Adding a lock prefix to an instruction on MP machine#define LOCK_IF_MP(mp) &quot;cmp $0, &quot; #mp &quot;; je 1f; lock; 1: &quot;inline jint     Atomic::cmpxchg    (jint     exchange_value, volatile jint*     dest, jint     compare_value) &#123;  int mp = os::is_MP();  __asm__ volatile (LOCK_IF_MP(%4) &quot;cmpxchgl %1,(%3)&quot;                    : &quot;=a&quot; (exchange_value)                    : &quot;r&quot; (exchange_value), &quot;a&quot; (compare_value), &quot;r&quot; (dest), &quot;r&quot; (mp)                    : &quot;cc&quot;, &quot;memory&quot;);  return exchange_value;&#125;</code></pre><p>LOCK_IF_MP 表示如果是多处理器，则添加一个lock指令作为前缀，反之，就省略lock前缀（单处理器会不需要lock前缀提供的内存屏障效果）。这里的lock前缀就是使用了处理器的总线锁（最新的处理器都使用缓存锁代替总线锁来提高性能）。从而，实现了原子地交换更新值。</p><h2 id="CAS操作的几个问题"><a href="#CAS操作的几个问题" class="headerlink" title="CAS操作的几个问题"></a>CAS操作的几个问题</h2><h3 id="ABA问题"><a href="#ABA问题" class="headerlink" title="ABA问题"></a>ABA问题</h3><p>CAS操作只有在检查值等于期望值的时候，才会发生替换，但是如果期间发生了两次替换，使得值从A–&gt;B–&gt;A，虽然检查值依然是A，但是期间其实发生了变化。因此，CAS无法检测到ABA问题。</p><p>解决办法就是给每个值附带上版本号，每次更新数据都要递增版本号。</p><p>因此，JDK1.5中引入了AtomicStampedReference类。如它的compareAndSet方法，需要指定期望版本号expectedStamp，只有在版本号对得上的情况下，才会发生值替换。如下：</p><pre><code class="java"> /**     * Atomically sets the value of both the reference and stamp     * to the given update values if the     * current reference is &#123;@code ==&#125; to the expected reference     * and the current stamp is equal to the expected stamp.     *     * @param expectedReference the expected value of the reference     * @param newReference the new value for the reference     * @param expectedStamp the expected value of the stamp     * @param newStamp the new value for the stamp     * @return &#123;@code true&#125; if successful     */    public boolean compareAndSet(V   expectedReference,                                 V   newReference,                                 int expectedStamp,                                 int newStamp) &#123;        Pair&lt;V&gt; current = pair;        return            expectedReference == current.reference &amp;&amp;            expectedStamp == current.stamp &amp;&amp;            ((newReference == current.reference &amp;&amp;              newStamp == current.stamp) ||             casPair(current, Pair.of(newReference, newStamp)));    &#125;</code></pre><h3 id="自旋耗时问题"><a href="#自旋耗时问题" class="headerlink" title="自旋耗时问题"></a>自旋耗时问题</h3><p>CAS操作一般是在循环里不断重试，直到成功才中断循环。在并发量高的情况下，这种自旋会增加循环次数，从而增加耗时。比如CountDownLatch类里有如下代码：</p><pre><code class="java">protected boolean tryReleaseShared(int releases) &#123;    // Decrement count; signal when transition to zero    for (;;) &#123;        int c = getState();        if (c == 0)            return false;        int nextc = c-1;        if (compareAndSetState(c, nextc))            // 不断重试，直到更新成功才中断循环            return nextc == 0;    &#125;&#125;</code></pre><h3 id="单个变量问题"><a href="#单个变量问题" class="headerlink" title="单个变量问题"></a>单个变量问题</h3><p>上述提到的CAS操作只适合单个变量。如果要同时对多个变量进行CAS操作，就无能为力了。为此JDK1.5中有AtomicReference类，这个类支持对一个复杂对象的原子操作，底层同样适用了unsafe。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CAS原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring源码分析3-对Bean循环依赖的处理</title>
      <link href="/2018/10/12/Spring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%903-%E5%AF%B9Bean%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E7%9A%84%E5%A4%84%E7%90%86/"/>
      <url>/2018/10/12/Spring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%903-%E5%AF%B9Bean%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E7%9A%84%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p>本文主要是分析Spring如何处理循环依赖，分别从构造器注入循环依赖、setter注入循环依赖、prototype范围的循环依赖三个方面进行详细分析。</p><span id="more"></span><p>正式开始前先废话一下：</p><p>之前写了两篇近似于流水账的Spring源码分析，写到后边越来越多看不懂的地方（所以<a href="http://blog.duval.top/2018/07/12/Spring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-RESTful%20Web%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/">分析1</a>和<a href="http://blog.duval.top/2018/07/12/Spring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%B7%E6%96%B0%E8%BF%87%E7%A8%8B/">分析2</a>大家就当是流水账看看罢了，没什么营养）。之后回头细细一想，感觉精力都花在了Spring的上下文环节，至于面向切面编程AOP、控制反转IOC、依赖注入DI等等机制的实现原理都一窍不通。后来我看了一本书<a href="https://pan.baidu.com/s/1dbVQ6QFxwxp9_noNCy6xHg">《Spring源码深度解析》</a>，终于开始恍然大悟。</p><p>我明白直接研究Spring的核心机制，不应该从RestfultWeb入手，因为那样子其实是从Spring boot层面开始阅读源码了。</p><p>可以阅读这篇文章<a href="https://www.jianshu.com/p/42620a0a2c33">《Spring,Spring MVC及Spring Boot区别》</a>大致了解。</p><p>所以直接按照书上介绍的内容去啃源码就对了。另外提一下就是书上的Spring版本要比现在的版本老了，但是核心思想一样的，底层的源码改动不大，可以正常阅读。</p><p>读到《Spring源码深度解析》5章6节的循环依赖的时候，感觉有挺多不明白的地方，后来逐个调试后，发现了很多有趣的东西。所以通过这篇文章记录下来。</p><p>首先要知道Spring框架允许setter注入循环依赖，但对于构造器注入循环依赖、prototype范围的循环依赖，框架都没法很好解决，<br>然后直接抛异常终止程序。我们尝试从源码层面去分析这三者的不同。</p><p>我们先定义两个类：</p><pre><code class="java">@Data@AllArgsConstructor@NoArgsConstructorpublic class TestA &#123;    private TestB testB;    @Override    public String toString() &#123;        return &quot;TestA&quot;;    &#125;&#125;@Data@AllArgsConstructor@NoArgsConstructorpublic class TestB &#123;    private TestA testA;    @Override    public String toString() &#123;        return &quot;TestB&quot;;    &#125;&#125;</code></pre><p>这里我采用了lombock的注解@Data来自动生成getter&#x2F;setter、构造器、toString等方法，例外地我特地重写了toString方法。因为lombock自动生成的toString方法会导致栈溢出，后文我会提及这个。</p><h2 id="构造器注入循环依赖"><a href="#构造器注入循环依赖" class="headerlink" title="构造器注入循环依赖"></a>构造器注入循环依赖</h2><p>在xml中注入这两个bean，使其出现循环依赖。scope默认是singleton的。</p><pre><code class="xml">    &lt;bean id=&quot;testA&quot; class=&quot;com.example.circle.TestA&quot;&gt;        &lt;constructor-arg index=&quot;0&quot; ref=&quot;testB&quot;&gt;&lt;/constructor-arg&gt;    &lt;/bean&gt;    &lt;bean id=&quot;testB&quot; class=&quot;com.example.circle.TestB&quot;&gt;        &lt;constructor-arg index=&quot;0&quot; ref=&quot;testA&quot;&gt;&lt;/constructor-arg&gt;    &lt;/bean&gt;</code></pre><p>在main方法里尝试去加载和获取这些bean（后文的类似，不再重复）</p><pre><code class="java">    //测试构造器注入的依赖处理    context = new ClassPathXmlApplicationContext(&quot;classpath:circle/constructor/circle.xml&quot;);    testA = (TestA) context.getBean(&quot;testA&quot;);    System.out.println(testA.toString());</code></pre><p>运行后，可以注意到报错如下：</p><pre><code>Exception in thread &quot;main&quot; org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#39;testA&#39; defined in class path resource [circle/constructor/circle.xml]: Cannot resolve reference to bean &#39;testB&#39; while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#39;testB&#39; defined in class path resource [circle/constructor/circle.xml]: Cannot resolve reference to bean &#39;testA&#39; while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name &#39;testA&#39;: Requested bean is currently in creation: Is there an unresolvable circular reference?    at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:378)    at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)    at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:625)    at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:153)    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1267)    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1124)    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)    at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:759)    at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:869)    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:550)    at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:144)    at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:85)    at com.example.circle.CircleMain.main(CircleMain.java:29)Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#39;testB&#39; defined in class path resource [circle/constructor/circle.xml]: Cannot resolve reference to bean &#39;testA&#39; while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name &#39;testA&#39;: Requested bean is currently in creation: Is there an unresolvable circular reference?    at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:378)    at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:110)    at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:625)    at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:153)    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1267)    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1124)    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535)    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495)    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317)    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222)    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)    at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)    ... 17 moreCaused by: org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name &#39;testA&#39;: Requested bean is currently in creation: Is there an unresolvable circular reference?    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.beforeSingletonCreation(DefaultSingletonBeanRegistry.java:339)    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:215)    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315)    at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199)    at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:367)    ... 29 more</code></pre><p>里边的异常堆栈是我们分析源码得好帮手，顺着堆栈一步步进去看看吧。</p><p>看到最开始新建上下文的时候，上下文主动刷新，代码逻辑进入了finishBeanFactoryInitialization(beanFactory)，这个方法的作用是实例化所有的剩余的非懒加载的单例。</p><p>继续深究，我们看到进入了下边这段代码里。因为默认的scope是singleton的，所以会进入这段逻辑里去。这里的关键是getSingleton方法，这个方法的第二个入参是个函数ObjectFactory&lt;?&gt; singletonFactory，函数调用的createBean是个实例化Bean的动作。所有的bean实例化都会经过createBean这个方法，prototype范围的bean也不例外，区别就在于它不需要经过。getSingleton的逻辑。</p><pre><code class="java">// Create bean instance.if (mbd.isSingleton()) &#123;    sharedInstance = getSingleton(beanName, () -&gt; &#123;        try &#123;            return createBean(beanName, mbd, args);        &#125;        catch (BeansException ex) &#123;            // Explicitly remove instance from singleton cache: It might have been put there            // eagerly by the creation process, to allow for circular reference resolution.            // Also remove any beans that received a temporary reference to the bean.            destroySingleton(beanName);            throw ex;        &#125;    &#125;);    bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);&#125;</code></pre><p>对于getSingleton,他其实最关键是做了三个事情，第一是通过beforeSingletonCreation(beanName)标注这个bean正在创建中，第二是通过第二个入参函数获得实例化后的bean singletonFactory.getObject()，第三是将步骤一的标注删除。</p><pre><code class="java">public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123;        Assert.notNull(beanName, &quot;Bean name must not be null&quot;);        synchronized (this.singletonObjects) &#123;            Object singletonObject = this.singletonObjects.get(beanName);            //当这个单例还没有实例化            if (singletonObject == null) &#123;                if (this.singletonsCurrentlyInDestruction) &#123;                    throw new BeanCreationNotAllowedException(beanName,                            &quot;Singleton bean creation not allowed while singletons of this factory are in destruction &quot; +                            &quot;(Do not request a bean from a BeanFactory in a destroy method implementation!)&quot;);                &#125;                if (logger.isDebugEnabled()) &#123;                    logger.debug(&quot;Creating shared instance of singleton bean &#39;&quot; + beanName + &quot;&#39;&quot;);                &#125;                //创建单例前，做标记                beforeSingletonCreation(beanName);                boolean newSingleton = false;                boolean recordSuppressedExceptions = (this.suppressedExceptions == null);                if (recordSuppressedExceptions) &#123;                    this.suppressedExceptions = new LinkedHashSet&lt;&gt;();                &#125;                try &#123;                    //调用工厂方法获得实例化后的bean                    singletonObject = singletonFactory.getObject();                    newSingleton = true;                &#125;                catch (IllegalStateException ex) &#123;                    // Has the singleton object implicitly appeared in the meantime -&gt;                    // if yes, proceed with it since the exception indicates that state.                    singletonObject = this.singletonObjects.get(beanName);                    if (singletonObject == null) &#123;                        throw ex;                    &#125;                &#125;                catch (BeanCreationException ex) &#123;                    if (recordSuppressedExceptions) &#123;                        for (Exception suppressedException : this.suppressedExceptions) &#123;                            ex.addRelatedCause(suppressedException);                        &#125;                    &#125;                    throw ex;                &#125;                finally &#123;                    if (recordSuppressedExceptions) &#123;                        this.suppressedExceptions = null;                    &#125;                    //创建单例后，删除标记                    afterSingletonCreation(beanName);                &#125;                if (newSingleton) &#123;                    addSingleton(beanName, singletonObject);                &#125;            &#125;            return singletonObject;        &#125;    &#125;</code></pre><p>着重留意这个标注单例bean正在创建的过程，其实就是在singletonsCurrentlyInCreation添加一个集合元素。这个动作在循环依赖检测中起到关键作用。</p><pre><code class="java">protected void beforeSingletonCreation(String beanName) &#123;        if (!this.inCreationCheckExclusions.contains(beanName) &amp;&amp; !this.singletonsCurrentlyInCreation.add(beanName)) &#123;            throw new BeanCurrentlyInCreationException(beanName);        &#125;&#125;</code></pre><p>当这个bean被标注正在创建中后，就会进入创建阶段，我们深究下去，代码到了AbstractAutowireCapableBeanFactory#doCreateBean里，这里有个关键的动作：</p><pre><code class="java">if (instanceWrapper == null) &#123;    instanceWrapper = createBeanInstance(beanName, mbd, args);&#125;</code></pre><p>展开createBeanInstance方法。我们看到最后，注意到构造BeanWrapper的时候，会根据bean的注入方式选择构造方法。像现在所调试的构造器注入方式，会去bean里找到相应的构造器来对bean进行实例化TestA，但因为TestA通过构造器注入了TestB，就会触发一个新的doGetBean动作，去实例化这个TestB。恩，正是这个地方会引发构造器循环依赖。后文会说到的setter注入，因为使用的是默认的构造函数，所以在这个地方不存在循环依赖的问题。</p><pre><code class="java">protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) &#123;        // Make sure bean class is actually resolved at this point.        Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName);        if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123;            throw new BeanCreationException(mbd.getResourceDescription(), beanName,                    &quot;Bean class isn&#39;t public, and non-public access not allowed: &quot; + beanClass.getName());        &#125;        Supplier&lt;?&gt; instanceSupplier = mbd.getInstanceSupplier();        if (instanceSupplier != null) &#123;            return obtainFromSupplier(instanceSupplier, beanName);        &#125;        if (mbd.getFactoryMethodName() != null)  &#123;            return instantiateUsingFactoryMethod(beanName, mbd, args);        &#125;        // Shortcut when re-creating the same bean...        boolean resolved = false;        boolean autowireNecessary = false;        if (args == null) &#123;            synchronized (mbd.constructorArgumentLock) &#123;                if (mbd.resolvedConstructorOrFactoryMethod != null) &#123;                    resolved = true;                    autowireNecessary = mbd.constructorArgumentsResolved;                &#125;            &#125;        &#125;        if (resolved) &#123;            if (autowireNecessary) &#123;                return autowireConstructor(beanName, mbd, null, null);            &#125;            else &#123;                return instantiateBean(beanName, mbd);            &#125;        &#125;        // Need to determine the constructor...        //根据入参情况（是否为构造器注入)选择对应的构造器来实例化这个bean        Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName);        if (ctors != null ||                mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR ||                mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args))  &#123;            return autowireConstructor(beanName, mbd, ctors, args);        &#125;        // No special handling: simply use no-arg constructor.        //使用默认构造函数实例化这个bean        return instantiateBean(beanName, mbd);    &#125;</code></pre><p>OK，上文已经因为实例化TestA,然后触发了TestB的实例化。其实TestB的实例化过程和TestA是一模一样的，同样到了createBeanInstance也会尝试实例化TestA。好的，现在又到了实例化TestA的过程，我们来看看这一次有啥不一样。我们发现又回到了这里：</p><pre><code class="java">// Create bean instance.if (mbd.isSingleton()) &#123;    sharedInstance = getSingleton(beanName, () -&gt; &#123;        try &#123;            return createBean(beanName, mbd, args);        &#125;        catch (BeansException ex) &#123;            // Explicitly remove instance from singleton cache: It might have been put there            // eagerly by the creation process, to allow for circular reference resolution.            // Also remove any beans that received a temporary reference to the bean.            destroySingleton(beanName);            throw ex;        &#125;    &#125;);    bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);&#125;</code></pre><pre><code class="java">protected void beforeSingletonCreation(String beanName) &#123;    if (!this.inCreationCheckExclusions.contains(beanName) &amp;&amp; !this.singletonsCurrentlyInCreation.add(beanName)) &#123;        throw new BeanCurrentlyInCreationException(beanName);    &#125;&#125;</code></pre><p>当再一次因为TestA来到这个beforeSingletonCreation的时候，会发现他已经处于单例创建中。那就糟了，直接抛异常终止了。</p><p>这就是构造器循环依赖注入的处理逻辑。</p><h2 id="setter注入循环依赖"><a href="#setter注入循环依赖" class="headerlink" title="setter注入循环依赖"></a>setter注入循环依赖</h2><p>我们知道setter单例注入循环依赖是Spring框架允许的，为什么会有这个差异呢，我们先来了解DefaultSingletonBeanRegistry里的几个重要的缓存数据。</p><pre><code class="java">    /** Cache of singleton objects: bean name --&gt; bean instance */    /**已经实例化完毕的单例缓存**/    private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);    /** Cache of singleton factories: bean name --&gt; ObjectFactory */    /**单例工厂类缓存**/    private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);    /** Cache of early singleton objects: bean name --&gt; bean instance */    /**提前曝光的单例实例对象缓存**/    private final Map&lt;String, Object&gt; earlySingletonObjects = new HashMap&lt;&gt;(16);    /** Names of beans that are currently in creation */    /**正在创建中的单例名字集合**/    private final Set&lt;String&gt; singletonsCurrentlyInCreation =            Collections.newSetFromMap(new ConcurrentHashMap&lt;&gt;(16));</code></pre><p>从上边我们可以大致推测，已经创建好的Bean存放在singletonObjects，正在创建中还没注入完毕的bean暂存在earlySingletonObjects，那些创建中的单例bean的工厂类放在singletonFactories，正在创建中的bean的名字放在singletonsCurrentlyInCreation；</p><p>下边我们看看这几个东西怎么发挥作用。</p><p>先看看这个常用的getSingleton方法，第二个入参是限定是否需要获取那些为了解决循环依赖而被提前曝光的半成品bean（部分属性还没注入，属性为null)。可以看到其实这个方法是一个三级缓存机制，如果有成品的bean在singletonObjects，直接返回；如果有提前曝光的bean在earlySingletonObjects，获取并返回；如果有半成品bean的工厂方法在singletonFactories，那就用工厂类生成实例，放进earlySingletonObjects，并且删除工厂方法.</p><pre><code class="java">protected Object getSingleton(String beanName, boolean allowEarlyReference) &#123;    Object singletonObject = this.singletonObjects.get(beanName);    if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &#123;        synchronized (this.singletonObjects) &#123;            singletonObject = this.earlySingletonObjects.get(beanName);            if (singletonObject == null &amp;&amp; allowEarlyReference) &#123;                ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName);                if (singletonFactory != null) &#123;                    singletonObject = singletonFactory.getObject();                    this.earlySingletonObjects.put(beanName, singletonObject);                    this.singletonFactories.remove(beanName);                &#125;            &#125;        &#125;    &#125;    return singletonObject;&#125;</code></pre><p>我们再回到AbstractAutowireCapableBeanFactory#doCreateBean，setter注入的循环依赖也会经过</p><pre><code class="java">if (instanceWrapper == null) &#123;    instanceWrapper = createBeanInstance(beanName, mbd, args);&#125;</code></pre><p>上文我们说到，因为使用的是默认构造函数，不存在递归调用获取bean的问题，所以程序可以继续往下执行到：</p><pre><code class="java">// Eagerly cache singletons to be able to resolve circular references// even when triggered by lifecycle interfaces like BeanFactoryAware.boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp;        isSingletonCurrentlyInCreation(beanName));if (earlySingletonExposure) &#123;    if (logger.isDebugEnabled()) &#123;        logger.debug(&quot;Eagerly caching bean &#39;&quot; + beanName +                &quot;&#39; to allow for resolving potential circular references&quot;);    &#125;    addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));&#125;</code></pre><p>这个地方很有意思，注解也写到提前缓存这个单例bean以解决循环依赖。这里通过addSingletonFactory提前暴露了这个bean的一个工厂方法，以及bean自身。这里要注意也暴露的bean本身，因为getEarlyBeanReference(beanName, mbd, bean)的第三个入参。</p><pre><code class="java">protected void addSingletonFactory(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123;    Assert.notNull(singletonFactory, &quot;Singleton factory must not be null&quot;);    synchronized (this.singletonObjects) &#123;        if (!this.singletonObjects.containsKey(beanName)) &#123;            this.singletonFactories.put(beanName, singletonFactory);            this.earlySingletonObjects.remove(beanName);            this.registeredSingletons.add(beanName);        &#125;    &#125;&#125;</code></pre><p>正式因为这个地方提前暴露了这个构造中的bean，当别的bean构造过程中依赖他的时候，能够获取到一个半成品的bean，并且在属性注入的时候，注入这个半成品。从而避免了循环引用。举个例子：经过createBeanInstance方法得到一个半成品TestA后，并且提前曝光TestA这个半成品，然后尝试通过populateBean对这个半成品进行属性TestB的注入，发现TestB还没创建，从而调用GetBean获取TestB的实例。接着TestB进入创建环节，同样是经过createBeanInstance方法得到一个半成品TestB，并提前曝光自己，然后尝试通过populateBean对这个半成品进行属性TestA的注入，找到一个创建中的半成品TestA，成功注入返回。返回后，TestA半成品得到TestB后也成功注入，得到全部返回。</p><p>这样子就成功解决了循环依赖的问题。</p><h2 id="prototype范围的循环依赖"><a href="#prototype范围的循环依赖" class="headerlink" title="prototype范围的循环依赖"></a>prototype范围的循环依赖</h2><p>prototype范围的bean在创建时候的待遇不太一样，看最关键的代码AbstractBeanFactory#doGetBean：</p><pre><code class="java">if (mbd.isPrototype()) &#123;    // It&#39;s a prototype -&gt; create a new instance.    Object prototypeInstance = null;    try &#123;        beforePrototypeCreation(beanName);        prototypeInstance = createBean(beanName, mbd, args);    &#125;    finally &#123;        afterPrototypeCreation(beanName);    &#125;    bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);&#125;</code></pre><p>这里边直接调用了createBean，而不像单例情况下，前后分别做标记的添加和删除。那样子上边说到的三级缓存就没有效果啦，因为第一个if判断条件不成立，直接返回了，只剩下一级缓存。而且创建前还做了一个特别的动作：</p><pre><code class="java">beforePrototypeCreation(beanName);</code></pre><p>这其实也是一个打标记，也是用作循环检测的。这个标记在前文用到了，请看：</p><pre><code class="java">// Fail if we&#39;re already creating this bean instance:// We&#39;re assumably within a circular reference.if (isPrototypeCurrentlyInCreation(beanName)) &#123;    throw new BeanCurrentlyInCreationException(beanName);&#125;</code></pre><p>这里看到检测出循环依赖就马上短路了。</p><p>测试demo请移步：<a href="https://github.com/duvalCC/SpringDemo">https://github.com/duvalCC/SpringDemo</a></p><p><strong>参考资料</strong><br>1.<a href="https://www.iflym.com/index.php/code/201208280001.html">Spring中循环引用的处理-1</a><br>2.<a href="https://www.iflym.com/index.php/code/201208280002.html">Spring中循环引用的处理-2</a><br>3.<a href="https://www.iflym.com/index.php/code/201208280003.html">Spring中循环引用的处理-3</a></p>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 源码分析 </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring源码分析1-RESTfulWeb启动过程</title>
      <link href="/2018/07/12/Spring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-RESTful%20Web%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/"/>
      <url>/2018/07/12/Spring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-RESTful%20Web%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>Spring框架用的很多了，但是没有深入研究过原理。因为对原理不了解，如果遇到复杂的应用情景，需要修改Spring源码；或者是奇怪的报错，需要通过源码来进行分析的时候，就只能束手无策了。所以现在开始正式阅读Spring源码，这是系列的第一篇，希望能坚持下去。</p><span id="more"></span><p><strong>说在前边：本文是我阅读RestfulWeb启动过程写的流水账，瑕疵多多。</strong></p><p>第一篇先从最简单的情景入手，分析<strong>RESTful Web应用的启动加载流程</strong>。</p><h2 id="RESTfulWeb-应用"><a href="#RESTfulWeb-应用" class="headerlink" title="RESTfulWeb 应用"></a>RESTfulWeb 应用</h2><h3 id="什么是REST"><a href="#什么是REST" class="headerlink" title="什么是REST"></a>什么是REST</h3><p>REST（Representational State Transfer 表述性状态传输）是2000年的时候 Roy Fielding 在他的博士论文中的定义。REST是设计分布式系统的一种架构风格，它并不是一个标准，而是一系列的约束，包括：无状态、客户端&#x2F;服务端关系、统一接口等。REST跟HTTP不是强相关，但最常见的是这两者的关联。</p><p>其他文绉绉的定义请详见<a href="http://spring.io/understanding/REST">Understanding REST</a></p><h3 id="应用实践"><a href="#应用实践" class="headerlink" title="应用实践"></a>应用实践</h3><p>使用spring教程提供的样例<a href="https://github.com/spring-guides/gs-rest-service.git">gs-rest-service</a></p><ul><li>标准的spring boot application 入口</li></ul><pre><code class="java">@SpringBootApplicationpublic class Application &#123;    public static void main(String[] args) &#123;        SpringApplication.run(Application.class, args);    &#125;&#125;</code></pre><ul><li>暴露的controller</li></ul><pre><code class="java">@RestControllerpublic class GreetingController &#123;    private static final String template = &quot;Hello, %s!&quot;;    private final AtomicLong counter = new AtomicLong();    @RequestMapping(&quot;/greeting&quot;)    public Greeting greeting(@RequestParam(value=&quot;name&quot;, defaultValue=&quot;World&quot;) String name) &#123;        return new Greeting(counter.incrementAndGet(),                            String.format(template, name));    &#125;&#125;</code></pre><p>好的，断点打好，debug启动，准备就绪。</p><p>欢迎来到Spring世界！</p><h2 id="构造SpringApplication"><a href="#构造SpringApplication" class="headerlink" title="构造SpringApplication"></a>构造SpringApplication</h2><pre><code class="java">SpringApplication.run(Application.class, args);</code></pre><pre><code class="java">/**     * Static helper that can be used to run a &#123;@link SpringApplication&#125; from the     * specified source using default settings.     * @param primarySource the primary source to load     * @param args the application arguments (usually passed from a Java main method)     * @return the running &#123;@link ApplicationContext&#125;     */    public static ConfigurableApplicationContext run(Class&lt;?&gt; primarySource,            String... args) &#123;        return run(new Class&lt;?&gt;[] &#123; primarySource &#125;, args);    &#125;</code></pre><p>第一行代码是一个run，从这里进去后，可以看到这是SpringApplication提供的一个静态方法，这个Helper用于使用默认配置和指定的资源（这里是Application.class）来运行一个SpringApplication。简单说，就是按照默认方式构造一个SpringApplication！入参里还有个String[]args ,这其实就是寻常的main方法入参列表！</p><p>继续往下</p><pre><code class="java">/**     * Create a new &#123;@link SpringApplication&#125; instance. The application context will load     * beans from the specified primary sources (see &#123;@link SpringApplication class-level&#125;     * documentation for details. The instance can be customized before calling     * &#123;@link #run(String...)&#125;.     * @param resourceLoader the resource loader to use     * @param primarySources the primary bean sources     * @see #run(Class, String[])     * @see #setSources(Set)     */    @SuppressWarnings(&#123; &quot;unchecked&quot;, &quot;rawtypes&quot; &#125;)    public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123;        //资源加载器，这里传入的是Null        this.resourceLoader = resourceLoader;        //主资源不能为null，其实就是Application.class        Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;);        this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources));        //推断web应用类型        this.webApplicationType = deduceWebApplicationType();        //获取初始化器实例们        setInitializers((Collection) getSpringFactoriesInstances(                ApplicationContextInitializer.class));        //获取监听器实例们        setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));        //推断应用主类        this.mainApplicationClass = deduceMainApplicationClass();    &#125;</code></pre><p>从上边的代码可以看到，构造SpringApplication的伟大使命，只要走四步！真是太容易了！请看：</p><h3 id="推断web应用类型"><a href="#推断web应用类型" class="headerlink" title="推断web应用类型"></a>推断web应用类型</h3><pre><code class="java">private WebApplicationType deduceWebApplicationType() &#123;        if (ClassUtils.isPresent(REACTIVE_WEB_ENVIRONMENT_CLASS, null)                &amp;&amp; !ClassUtils.isPresent(MVC_WEB_ENVIRONMENT_CLASS, null)) &#123;            return WebApplicationType.REACTIVE;        &#125;        for (String className : WEB_ENVIRONMENT_CLASSES) &#123;            if (!ClassUtils.isPresent(className, null)) &#123;                return WebApplicationType.NONE;            &#125;        &#125;        return WebApplicationType.SERVLET;    &#125;</code></pre><p>这里是根据某些特征类来确定web应用类型的。web应用类型居然有三种！</p><pre><code class="java">public enum WebApplicationType &#123;    /**     * The application should not run as a web application and should not start an embedded web server.     *普通应用，不作为web应用运行，不需要启动内嵌web server     */    NONE,    /**     * The application should run as a servlet-based web application and should start an embedded servlet web server.     * 基于servlet的web应用，需要启动内嵌web server     */    SERVLET,    /**     * The application should run as a reactive web application and should start an embedded reactive web server.     *交互式web应用，需要启动内嵌web server     */    REACTIVE&#125;</code></pre><p>这三种有啥区别，我不知道！我也是一脸懵逼的！反正这次是SERVLET类型。他们的区别我以后肯定会知道的，先用小笔笔记下来。</p><h3 id="获取初始化器实例"><a href="#获取初始化器实例" class="headerlink" title="获取初始化器实例"></a>获取初始化器实例</h3><pre><code class="java">private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type) &#123;        return getSpringFactoriesInstances(type, new Class&lt;?&gt;[] &#123;&#125;); &#125;private &lt;T&gt; Collection&lt;T&gt; getSpringFactoriesInstances(Class&lt;T&gt; type,        Class&lt;?&gt;[] parameterTypes, Object... args) &#123;    ClassLoader classLoader = Thread.currentThread().getContextClassLoader();    // Use names and ensure unique to protect against duplicates    //从SpringFactoriesLoader那里搞来一堆实例的类名    Set&lt;String&gt; names = new LinkedHashSet&lt;&gt;(            SpringFactoriesLoader.loadFactoryNames(type, classLoader));    //然后将那堆类名，通过classloader给实例化了！    List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes,            classLoader, args, names);    AnnotationAwareOrderComparator.sort(instances);    return instances;&#125;</code></pre><p>从上边可以看到，实例化之前，先去SpringFactoriesLoader弄来一个集合的类名。我们看看怎么弄出来的,逐层深入，看到：</p><pre><code class="java">//这里classloader不是空，正是上文获取的当前线程的classloader//然后从FACTORIES_RESOURCE_LOCATION这个资源文件里获取了一把urlEnumeration&lt;URL&gt; urls = (classLoader != null ?        classLoader.getResources(FACTORIES_RESOURCE_LOCATION) :        ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION));result = new LinkedMultiValueMap&lt;&gt;();//将拿到的urls解析，获得一大把类名while (urls.hasMoreElements()) &#123;    URL url = urls.nextElement();    UrlResource resource = new UrlResource(url);    Properties properties = PropertiesLoaderUtils.loadProperties(resource);    for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123;        List&lt;String&gt; factoryClassNames = Arrays.asList(                StringUtils.commaDelimitedListToStringArray((String) entry.getValue()));        result.addAll((String) entry.getKey(), factoryClassNames);    &#125;&#125;cache.put(classLoader, result);return result;</code></pre><p>一看，呵！原来类名都是写死在文件FACTORIES_RESOURCE_LOCATION&#x3D;”META-INF&#x2F;spring.factories”里的。因为传入的classloader是当前线程ClassLoader，调用classLoader.getResources(String）的时候会把所有jar里的spring.factories都找出来。所以，其中一个spring.factories文件是在spring-boot包下的。打开瞧一瞧，里边东西还真不少：</p><pre><code class="xml"># PropertySource Loadersorg.springframework.boot.env.PropertySourceLoader=\org.springframework.boot.env.PropertiesPropertySourceLoader,\org.springframework.boot.env.YamlPropertySourceLoader# Run Listenersorg.springframework.boot.SpringApplicationRunListener=\org.springframework.boot.context.event.EventPublishingRunListener# Error Reportersorg.springframework.boot.SpringBootExceptionReporter=\org.springframework.boot.diagnostics.FailureAnalyzers# Application Context Initializersorg.springframework.context.ApplicationContextInitializer=\org.springframework.boot.context.ConfigurationWarningsApplicationContextInitializer,\org.springframework.boot.context.ContextIdApplicationContextInitializer,\org.springframework.boot.context.config.DelegatingApplicationContextInitializer,\org.springframework.boot.web.context.ServerPortInfoApplicationContextInitializer# Application Listenersorg.springframework.context.ApplicationListener=\org.springframework.boot.ClearCachesApplicationListener,\org.springframework.boot.builder.ParentContextCloserApplicationListener,\org.springframework.boot.context.FileEncodingApplicationListener,\org.springframework.boot.context.config.AnsiOutputApplicationListener,\org.springframework.boot.context.config.ConfigFileApplicationListener,\org.springframework.boot.context.config.DelegatingApplicationListener,\org.springframework.boot.context.logging.ClasspathLoggingApplicationListener,\org.springframework.boot.context.logging.LoggingApplicationListener,\org.springframework.boot.liquibase.LiquibaseServiceLocatorApplicationListener# Environment Post Processorsorg.springframework.boot.env.EnvironmentPostProcessor=\org.springframework.boot.cloud.CloudFoundryVcapEnvironmentPostProcessor,\org.springframework.boot.env.SpringApplicationJsonEnvironmentPostProcessor,\org.springframework.boot.env.SystemEnvironmentPropertySourceEnvironmentPostProcessor# Failure Analyzersorg.springframework.boot.diagnostics.FailureAnalyzer=\org.springframework.boot.diagnostics.analyzer.BeanCurrentlyInCreationFailureAnalyzer,\org.springframework.boot.diagnostics.analyzer.BeanNotOfRequiredTypeFailureAnalyzer,\org.springframework.boot.diagnostics.analyzer.BindFailureAnalyzer,\org.springframework.boot.diagnostics.analyzer.BindValidationFailureAnalyzer,\org.springframework.boot.diagnostics.analyzer.UnboundConfigurationPropertyFailureAnalyzer,\org.springframework.boot.diagnostics.analyzer.ConnectorStartFailureAnalyzer,\org.springframework.boot.diagnostics.analyzer.NoUniqueBeanDefinitionFailureAnalyzer,\org.springframework.boot.diagnostics.analyzer.PortInUseFailureAnalyzer,\org.springframework.boot.diagnostics.analyzer.ValidationExceptionFailureAnalyzer,\org.springframework.boot.diagnostics.analyzer.InvalidConfigurationPropertyNameFailureAnalyzer,\org.springframework.boot.diagnostics.analyzer.InvalidConfigurationPropertyValueFailureAnalyzer# FailureAnalysisReportersorg.springframework.boot.diagnostics.FailureAnalysisReporter=\org.springframework.boot.diagnostics.LoggingFailureAnalysisReporter</code></pre><p>当然这里就提示了我们，我们可以在自己的META-INF&#x2F;spring.factories，spring也可以找的到里边的listener，然后进行注册。</p><p>好了，刚说到拿到了上边那包类名了。继续 ~</p><pre><code class="java">public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, @Nullable ClassLoader classLoader) &#123;        String factoryClassName = factoryClass.getName();        return loadSpringFactories(classLoader).getOrDefault(factoryClassName, Collections.emptyList());    &#125;</code></pre><p>弱水三千，我只取一瓢。根据factoryClassName（这里是org.springframework.context.ApplicationContextInitializer)，我只取这包类名的一小部分。被取的也就是下边这几个：</p><pre><code class="xml">org.springframework.boot.context.ConfigurationWarningsApplicationContextInitializerorg.springframework.boot.context.ContextIdApplicationContextInitializerorg.springframework.boot.context.config.DelegatingApplicationContextInitializerorg.springframework.boot.web.context.ServerPortInfoApplicationContextInitializer</code></pre><pre><code class="java">List&lt;T&gt; instances = createSpringFactoriesInstances(type, parameterTypes,                classLoader, args, names);</code></pre><p>拿到类名了，这里就开始实例化了。</p><pre><code class="java">setInitializers((Collection) getSpringFactoriesInstances(                ApplicationContextInitializer.class));</code></pre><p>实例化完了，就结束了！设置到SpringApplication里以备后用！</p><h3 id="获取监听器实例"><a href="#获取监听器实例" class="headerlink" title="获取监听器实例"></a>获取监听器实例</h3><p>这一步跟获取初始化器是一模一样的，只有key不一样，这里用的key是org.springframework.context.ApplicationListener。好了，跳过跳过，拿到了一包监听器实例，如下：</p><pre><code class="xml">org.springframework.boot.ClearCachesApplicationListener,\org.springframework.boot.builder.ParentContextCloserApplicationListener,\org.springframework.boot.context.FileEncodingApplicationListener,\org.springframework.boot.context.config.AnsiOutputApplicationListener,\org.springframework.boot.context.config.ConfigFileApplicationListener,\org.springframework.boot.context.config.DelegatingApplicationListener,\org.springframework.boot.context.logging.ClasspathLoggingApplicationListener,\org.springframework.boot.context.logging.LoggingApplicationListener,\org.springframework.boot.liquibase.LiquibaseServiceLocatorApplicationListener</code></pre><p>也设置到SpringApplication里以备后用！</p><h3 id="推断主类"><a href="#推断主类" class="headerlink" title="推断主类"></a>推断主类</h3><pre><code class="java">private Class&lt;?&gt; deduceMainApplicationClass() &#123;        try &#123;            StackTraceElement[] stackTrace = new RuntimeException().getStackTrace();            for (StackTraceElement stackTraceElement : stackTrace) &#123;                if (&quot;main&quot;.equals(stackTraceElement.getMethodName())) &#123;                    return Class.forName(stackTraceElement.getClassName());                &#125;            &#125;        &#125;        catch (ClassNotFoundException ex) &#123;            // Swallow and continue        &#125;        return null;    &#125;</code></pre><p>取巧，从栈信息里，找到有个方法叫main的类的类名，然后返回。</p><h2 id="运行SpringApplication"><a href="#运行SpringApplication" class="headerlink" title="运行SpringApplication"></a>运行SpringApplication</h2><p>重头戏来了，进入run方法，可以看到非常复杂的一个方法。浏览一遍，然后我们一步一步分析</p><pre><code class="java">    /**     * Run the Spring application, creating and refreshing a new     * &#123;@link ApplicationContext&#125;.     * @param args the application arguments (usually passed from a Java main method)     * @return a running &#123;@link ApplicationContext&#125;     */    public ConfigurableApplicationContext run(String... args) &#123;        //计时器开动        StopWatch stopWatch = new StopWatch();        stopWatch.start();        ConfigurableApplicationContext context = null;        Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;();        //写入headless模式的环境变量 java.awt.headless=true        configureHeadlessProperty();        //获得运行时监听器，并调用start        SpringApplicationRunListeners listeners = getRunListeners(args);        listeners.starting();        try &#123;            ApplicationArguments applicationArguments = new DefaultApplicationArguments(                    args);            //准备环境容器            ConfigurableEnvironment environment = prepareEnvironment(listeners,                    applicationArguments);            configureIgnoreBeanInfo(environment);            //准备环境容器            Banner printedBanner = printBanner(environment);            //创建上下文            context = createApplicationContext();            //构建exceptionReporters            exceptionReporters = getSpringFactoriesInstances(                    SpringBootExceptionReporter.class,                    new Class[] &#123; ConfigurableApplicationContext.class &#125;, context);            //准备上下文            prepareContext(context, environment, listeners, applicationArguments,                    printedBanner);            //刷新上下文            refreshContext(context);            //上下文后置处理            afterRefresh(context, applicationArguments);            //计时器停止            stopWatch.stop();            //打印启动日志            if (this.logStartupInfo) &#123;                new StartupInfoLogger(this.mainApplicationClass)                        .logStarted(getApplicationLog(), stopWatch);            &#125;            //触发started事件            listeners.started(context);            //调用Runner            callRunners(context, applicationArguments);        &#125;        catch (Throwable ex) &#123;            handleRunFailure(context, ex, exceptionReporters, listeners);            throw new IllegalStateException(ex);        &#125;        try &#123;            listeners.running(context);        &#125;        catch (Throwable ex) &#123;            handleRunFailure(context, ex, exceptionReporters, null);            throw new IllegalStateException(ex);        &#125;        return context;    &#125;</code></pre><h3 id="打开HeadlessMode"><a href="#打开HeadlessMode" class="headerlink" title="打开HeadlessMode"></a>打开HeadlessMode</h3><p>一开始先打开headless模式，这个玩意儿没接触过，简单了解下。就是当设置了java.awt.headless&#x3D;true的时候，java应用就会默认进入headless模式。Headless模式是一个没有键盘、鼠标、屏幕的一个模式，所以当你进入headless模式，就意味着进行GUI开发，就会受限制，甚至出现异常，可以看看Button的代码：</p><pre><code class="java">static &#123;    /* ensure that the necessary native libraries are loaded */    Toolkit.loadLibraries();    if (!GraphicsEnvironment.isHeadless()) &#123;        initIDs();    &#125;&#125;/**     * Initialize JNI field and method IDs for fields that may be     * accessed from C.     */    private static native void initIDs();</code></pre><p>一上来先检查是不是headless模式再决定是否initIDs().</p><p>headless模式更多信息，可以看看<a href="http://www.oracle.com/technetwork/articles/javase/headless-136834.html">oracle的文档</a></p><h3 id="运行时监听器"><a href="#运行时监听器" class="headerlink" title="运行时监听器"></a>运行时监听器</h3><pre><code class="java">private SpringApplicationRunListeners getRunListeners(String[] args) &#123;    Class&lt;?&gt;[] types = new Class&lt;?&gt;[] &#123;SpringApplication.class,String[].class&#125;;    return new SpringApplicationRunListeners(logger,getSpringFactoriesInstances(SpringApplicationRunListener.class, types, this, args));&#125;</code></pre><p>呵！又跑去META-INF&#x2F;spring.factories 去捞类名了，这次的key是org.springframework.boot.SpringApplicationRunListener，捞出来一堆listeners实例之后，塞到SpringApplicationRunListeners里封装起来备用！对了，这次捞出来的实例只有一个，是它：</p><pre><code class="java">org.springframework.boot.context.event.EventPublishingRunListener</code></pre><p>有个地方要注意下，这个构造的时候做了个小动作。他把SpringApplication的监听器，一股脑全注册到他自己名下了。呵！listener ！</p><pre><code class="java">public EventPublishingRunListener(SpringApplication application, String[] args) &#123;        this.application = application;        this.args = args;        this.initialMulticaster = new SimpleApplicationEventMulticaster();        for (ApplicationListener&lt;?&gt; listener : application.getListeners()) &#123;            this.initialMulticaster.addApplicationListener(listener);        &#125;    &#125;</code></pre><p>紧接着麻烦就通过将第一个ApplicationStartingEvent传递给这些listeners。当然不是所有的监听器都会处理这个Event，里边有复杂的判断逻辑，暂时跳过。监听器收到event之后，自然会做自己的一些准备工作。</p><pre><code class="java">@Override    public void starting() &#123;        this.initialMulticaster.multicastEvent(                new ApplicationStartingEvent(this.application, this.args));    &#125;</code></pre><p>可以看到，这个listener的机制，可以使得启动加载环节的可拓展性非常强，可以自己酌情增减listener。因为SpringApplication暴露了添加listener的接口：</p><pre><code>/**     * Add &#123;@link ApplicationListener&#125;s to be applied to the SpringApplication and     * registered with the &#123;@link ApplicationContext&#125;.     * @param listeners the listeners to add     */public void addListeners(ApplicationListener&lt;?&gt;... listeners) &#123;    this.listeners.addAll(Arrays.asList(listeners));&#125;</code></pre><p>另外，也可以定义自己的META-INF&#x2F;spring.factories文件，在里边注册自己的listener。</p><h3 id="准备环境容器"><a href="#准备环境容器" class="headerlink" title="准备环境容器"></a>准备环境容器</h3><pre><code class="java">private ConfigurableEnvironment prepareEnvironment(            SpringApplicationRunListeners listeners,            ApplicationArguments applicationArguments) &#123;    // Create and configure the environment    ConfigurableEnvironment environment = getOrCreateEnvironment();    //处理propertySource和profile    configureEnvironment(environment, applicationArguments.getSourceArgs());    //通知监听器    listeners.environmentPrepared(environment);    //将环境容器和SpringApplication绑定    bindToSpringApplication(environment);    if (this.webApplicationType == WebApplicationType.NONE) &#123;        environment = new EnvironmentConverter(getClassLoader())                .convertToStandardEnvironmentIfNecessary(environment);    &#125;    ConfigurationPropertySources.attach(environment);    return environment;&#125;</code></pre><h3 id="打印Banner"><a href="#打印Banner" class="headerlink" title="打印Banner"></a>打印Banner</h3><pre><code>Banner printedBanner = printBanner(environment);</code></pre><p>这个没啥，打印banner。spring支持多种banner，可以酌情使用。默认使用SpringBootBanner，打印出来，如下样式：</p><pre><code>  .   ____          _            __ _ _ /\\ / ___&#39;_ __ _ _(_)_ __  __ _ \ \ \ \( ( )\___ | &#39;_ | &#39;_| | &#39;_ \/ _` | \ \ \ \ \\/  ___)| |_)| | | | | || (_| |  ) ) ) )  &#39;  |____| .__|_| |_|_| |_\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot ::        (v2.0.3.RELEASE)</code></pre><h3 id="创建上下文"><a href="#创建上下文" class="headerlink" title="创建上下文"></a>创建上下文</h3><pre><code>context = createApplicationContext();</code></pre><p>这一步创建web应用的上下文，啥叫上下文，我现在也说不清楚。以后肯定会知道的。</p><p>SERVLET类型的应用在这里实例化的其实是这个类：<br>org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext</p><h3 id="构建exceptionReporters"><a href="#构建exceptionReporters" class="headerlink" title="构建exceptionReporters"></a>构建exceptionReporters</h3><pre><code class="java">exceptionReporters = getSpringFactoriesInstances(                    SpringBootExceptionReporter.class,                    new Class[] &#123; ConfigurableApplicationContext.class &#125;, context);</code></pre><p>又又又是那个熟悉的“捞类”方法！<br>这里捞出的类是这个：<br>org.springframework.boot.diagnostics.FailureAnalyzers</p><p>捞出来存在了临时变量exceptionReporters里，后文里看到当启动过程抛异常的时候，会使用到这个实例。有啥用途，字面看就是报告异常，以后再深入研究。</p><h3 id="准备上下文"><a href="#准备上下文" class="headerlink" title="准备上下文"></a>准备上下文</h3><pre><code class="java">private void prepareContext(ConfigurableApplicationContext context,            ConfigurableEnvironment environment, SpringApplicationRunListeners listeners,            ApplicationArguments applicationArguments, Banner printedBanner) &#123;        context.setEnvironment(environment);        //给上下文context预设ResourceLoader、Classloader等        postProcessApplicationContext(context);        //应用初始化器        applyInitializers(context);        // 触发Spring Boot启动过程的contextPrepared事件        listeners.contextPrepared(context);        if (this.logStartupInfo) &#123;            logStartupInfo(context.getParent() == null);            logStartupProfileInfo(context);        &#125;        // Add boot specific singleton beans         //添加两个spring boot启动过程中的特殊的单例beans          context.getBeanFactory().registerSingleton(&quot;springApplicationArguments&quot;,                applicationArguments);        if (printedBanner != null) &#123;            context.getBeanFactory().registerSingleton(&quot;springBootBanner&quot;, printedBanner);        &#125;        // Load the sources        //获得需要加载的资源        Set&lt;Object&gt; sources = getAllSources();        Assert.notEmpty(sources, &quot;Sources must not be empty&quot;);        //创建BeanDefinitionLoader，并加载sources到应用上下文context        load(context, sources.toArray(new Object[0]));        // 触发Spring Boot启动过程的contextLoaded事件        listeners.contextLoaded(context);    &#125;</code></pre><p>这里边东西挺多的，可以着重看下applyInitializers(context) 和 加载bean到context的这两个步骤。</p><h3 id="刷新上下文"><a href="#刷新上下文" class="headerlink" title="刷新上下文"></a>刷新上下文</h3><pre><code class="java">@Override    public void refresh() throws BeansException, IllegalStateException &#123;        synchronized (this.startupShutdownMonitor) &#123;            // Prepare this context for refreshing.            prepareRefresh();            // Tell the subclass to refresh the internal bean factory.            ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();            // Prepare the bean factory for use in this context.            prepareBeanFactory(beanFactory);            try &#123;                // Allows post-processing of the bean factory in context subclasses.                postProcessBeanFactory(beanFactory);                // Invoke factory processors registered as beans in the context.                invokeBeanFactoryPostProcessors(beanFactory);                // Register bean processors that intercept bean creation.                registerBeanPostProcessors(beanFactory);                // Initialize message source for this context.                initMessageSource();                // Initialize event multicaster for this context.                initApplicationEventMulticaster();                // Initialize other special beans in specific context subclasses.                onRefresh();                // Check for listener beans and register them.                registerListeners();                // Instantiate all remaining (non-lazy-init) singletons.                finishBeanFactoryInitialization(beanFactory);                // Last step: publish corresponding event.                finishRefresh();            &#125;            catch (BeansException ex) &#123;                if (logger.isWarnEnabled()) &#123;                    logger.warn(&quot;Exception encountered during context initialization - &quot; +                            &quot;cancelling refresh attempt: &quot; + ex);                &#125;                // Destroy already created singletons to avoid dangling resources.                destroyBeans();                // Reset &#39;active&#39; flag.                cancelRefresh(ex);                // Propagate exception to caller.                throw ex;            &#125;            finally &#123;                // Reset common introspection caches in Spring&#39;s core, since we                // might not ever need metadata for singleton beans anymore...                resetCommonCaches();            &#125;        &#125;    &#125;</code></pre><p>呵！好家伙，debug进去发现父类的refresh是个超级复杂的方法，刷新上下文居然做了这么多东西。本文抱着粗糙概览spring启动过程的想法，所以这里先不对这个方法展开分析。</p><p>需要注意下就是刷新完上下文之后，spring顺手注册了ShutdownHook,在doClose()做了很多资源释放以及触发ContextClosedEvent事件：</p><pre><code class="java">    @Override    public void registerShutdownHook() &#123;        if (this.shutdownHook == null) &#123;            // No shutdown hook registered yet.            this.shutdownHook = new Thread() &#123;                @Override                public void run() &#123;                    synchronized (startupShutdownMonitor) &#123;                        doClose();                    &#125;                &#125;            &#125;;            Runtime.getRuntime().addShutdownHook(this.shutdownHook);        &#125;    &#125;</code></pre><h3 id="上下文后置处理"><a href="#上下文后置处理" class="headerlink" title="上下文后置处理"></a>上下文后置处理</h3><pre><code class="java">/**     * Called after the context has been refreshed.     * @param context the application context     * @param args the application arguments     */    protected void afterRefresh(ConfigurableApplicationContext context,            ApplicationArguments args) &#123;    &#125;</code></pre><p>略感意外的是这里居然是空的protected方法，网上有些教程说到在这里会调用callRunners，估计现在最新的代码已经把这个挪到了后边了吧。</p><h3 id="调用Runner"><a href="#调用Runner" class="headerlink" title="调用Runner"></a>调用Runner</h3><pre><code class="java">private void callRunners(ApplicationContext context, ApplicationArguments args) &#123;        List&lt;Object&gt; runners = new ArrayList&lt;&gt;();        runners.addAll(context.getBeansOfType(ApplicationRunner.class).values());        runners.addAll(context.getBeansOfType(CommandLineRunner.class).values());        AnnotationAwareOrderComparator.sort(runners);        for (Object runner : new LinkedHashSet&lt;&gt;(runners)) &#123;            if (runner instanceof ApplicationRunner) &#123;                callRunner((ApplicationRunner) runner, args);            &#125;            if (runner instanceof CommandLineRunner) &#123;                callRunner((CommandLineRunner) runner, args);            &#125;        &#125;    &#125;</code></pre><p>可以看到会有两种Runner，分别为ApplicationRunner 和 CommandLineRunner。凡事实现了这两个接口的Bean，都会在这个地方被调用。这两种runner没特别大的区别，都是实现run方法，只有入参不一样，一个是封装好的ApplicationArguments类型，另一个是直接的String不定长数组类型。</p><p>然后就结束啦，这就是RESTful Web启动的过程概览啦！</p><p><strong>参考资料</strong></p><p>[1] <a href="http://spring.io/guides">Spring 官方教程</a><br>[2] <a href="https://blog.csdn.net/dm_vincent/article/details/76735888">SpringBoot 启动过程源码分析</a><br>[3] <a href="https://blog.csdn.net/dm_vincent/article/details/77151122">Spring Boot启动过程的定制化</a></p>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 源码分析 </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring源码分析2-上下文刷新过程分析</title>
      <link href="/2018/07/12/Spring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%B7%E6%96%B0%E8%BF%87%E7%A8%8B/"/>
      <url>/2018/07/12/Spring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%902-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%B7%E6%96%B0%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>上一篇《<a href="https://duvalcc.github.io/2018/07/12/Spring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%901-RESTful%20Web%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/">Spring源码分析1-RESTfulWeb启动过程</a>》已经对RESTfulWeb的启动过程进行了概览。其中跳过了比较复杂的上下文刷新过程，这篇文章将对上下文刷新过程进行详细分析。请看！</p><span id="more"></span><p><strong>说在前边：本文是我阅读RestfulWeb启动过程写的流水账，瑕疵多多。</strong></p><p>刷新上下文关键代码：</p><pre><code class="java">@Override    public void refresh() throws BeansException, IllegalStateException &#123;        synchronized (this.startupShutdownMonitor) &#123;            // Prepare this context for refreshing. 刷新前准备工作            prepareRefresh();            // Tell the subclass to refresh the internal bean factory.              ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();            // Prepare the bean factory for use in this context.            prepareBeanFactory(beanFactory);            try &#123;                // Allows post-processing of the bean factory in context subclasses.                postProcessBeanFactory(beanFactory);                // Invoke factory processors registered as beans in the context.                invokeBeanFactoryPostProcessors(beanFactory);                // Register bean processors that intercept bean creation.                registerBeanPostProcessors(beanFactory);                // Initialize message source for this context.                initMessageSource();                // Initialize event multicaster for this context.                initApplicationEventMulticaster();                // Initialize other special beans in specific context subclasses.                onRefresh();                // Check for listener beans and register them.                registerListeners();                // Instantiate all remaining (non-lazy-init) singletons.                finishBeanFactoryInitialization(beanFactory);                // Last step: publish corresponding event.                finishRefresh();            &#125;            catch (BeansException ex) &#123;                if (logger.isWarnEnabled()) &#123;                    logger.warn(&quot;Exception encountered during context initialization - &quot; +                            &quot;cancelling refresh attempt: &quot; + ex);                &#125;                // Destroy already created singletons to avoid dangling resources.                destroyBeans();                // Reset &#39;active&#39; flag.                cancelRefresh(ex);                // Propagate exception to caller.                throw ex;            &#125;            finally &#123;                // Reset common introspection caches in Spring&#39;s core, since we                // might not ever need metadata for singleton beans anymore...                resetCommonCaches();            &#125;        &#125;    &#125;</code></pre><p>下边对这些调用的方法逐个分析</p><h2 id="prepareRefresh"><a href="#prepareRefresh" class="headerlink" title="prepareRefresh"></a>prepareRefresh</h2><p>这个方法是做刷新前的一些准备工作</p><pre><code class="java">/**     * Prepare this context for refreshing, setting its startup date and     * active flag as well as performing any initialization of property sources.     */    protected void prepareRefresh() &#123;        this.startupDate = System.currentTimeMillis();        this.closed.set(false);        this.active.set(true);        if (logger.isInfoEnabled()) &#123;            logger.info(&quot;Refreshing &quot; + this);        &#125;        // Initialize any placeholder property sources in the context environment        initPropertySources();        // Validate that all properties marked as required are resolvable        // see ConfigurablePropertyResolver#setRequiredProperties        getEnvironment().validateRequiredProperties();        // Allow for the collection of early ApplicationEvents,        // to be published once the multicaster is available...        this.earlyApplicationEvents = new LinkedHashSet&lt;&gt;();    &#125;</code></pre><p><strong>initPropertySources</strong>其实是为了替换两个servlet有关的属性,我暂时没搞懂这两个属性是干嘛的,mark之:</p><pre><code class="java">public static void initServletPropertySources(MutablePropertySources sources,            @Nullable ServletContext servletContext, @Nullable ServletConfig servletConfig) &#123;        Assert.notNull(sources, &quot;&#39;propertySources&#39; must not be null&quot;);        String name = StandardServletEnvironment.SERVLET_CONTEXT_PROPERTY_SOURCE_NAME;        if (servletContext != null &amp;&amp; sources.contains(name) &amp;&amp; sources.get(name) instanceof StubPropertySource) &#123;            sources.replace(name, new ServletContextPropertySource(name, servletContext));        &#125;        name = StandardServletEnvironment.SERVLET_CONFIG_PROPERTY_SOURCE_NAME;        if (servletConfig != null &amp;&amp; sources.contains(name) &amp;&amp; sources.get(name) instanceof StubPropertySource) &#123;            sources.replace(name, new ServletConfigPropertySource(name, servletConfig));        &#125;    &#125;</code></pre><p><strong>validateRequiredProperties</strong>是为了校验一些必需的参数。<br><strong>earlyApplicationEvents</strong>在这里进行初始化为LinkedHashSet，用来存放早期的一些Applicationevents。<br>这里调试发现，对于<a href="https://github.com/spring-guides/gs-rest-service.git">gs-rest-service</a>，其实initPropertySources 和 validateRequiredProperties 都没有做任何动作。</p><h2 id="obtainFreshBeanFactory"><a href="#obtainFreshBeanFactory" class="headerlink" title="obtainFreshBeanFactory"></a>obtainFreshBeanFactory</h2><pre><code class="java">/**     * Tell the subclass to refresh the internal bean factory.     * @return the fresh BeanFactory instance     * @see #refreshBeanFactory()     * @see #getBeanFactory()     */    protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123;        refreshBeanFactory();        ConfigurableListableBeanFactory beanFactory = getBeanFactory();        if (logger.isDebugEnabled()) &#123;            logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory);        &#125;        return beanFactory;    &#125;</code></pre><p>这里并没有做很多动作，首先是刷新一下BeanFactory，其实就是在实现子类GenericApplicationContext里设置一下新的序列化ID；然后getBeanFactory()其实拿的是子类GenericApplicationContext里的DefaultListableBeanFactory,这是在其默认构造函数里新建的实例。</p><h2 id="prepareBeanFactory"><a href="#prepareBeanFactory" class="headerlink" title="prepareBeanFactory"></a>prepareBeanFactory</h2><pre><code class="java">/**     * Configure the factory&#39;s standard context characteristics,     * such as the context&#39;s ClassLoader and post-processors.     * @param beanFactory the BeanFactory to configure     */    protected void prepareBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123;        // Tell the internal bean factory to use the context&#39;s class loader etc.        beanFactory.setBeanClassLoader(getClassLoader());        //设置标准的Bean解释器，解释形如&quot;#&#123;&#125;&quot;        beanFactory.setBeanExpressionResolver(new StandardBeanExpressionResolver(beanFactory.getBeanClassLoader()));        //添加PropertyEditor注册器        beanFactory.addPropertyEditorRegistrar(new ResourceEditorRegistrar(this, getEnvironment()));        // Configure the bean factory with context callbacks.        //添加一个BeanPostProcessor        beanFactory.addBeanPostProcessor(new ApplicationContextAwareProcessor(this));        //忽略这些接口的自动注入        beanFactory.ignoreDependencyInterface(EnvironmentAware.class);        beanFactory.ignoreDependencyInterface(EmbeddedValueResolverAware.class);        beanFactory.ignoreDependencyInterface(ResourceLoaderAware.class);        beanFactory.ignoreDependencyInterface(ApplicationEventPublisherAware.class);        beanFactory.ignoreDependencyInterface(MessageSourceAware.class);        beanFactory.ignoreDependencyInterface(ApplicationContextAware.class);        // BeanFactory interface not registered as resolvable type in a plain factory.        // MessageSource registered (and found for autowiring) as a bean.        //使用注入值来注册几个特殊的依赖        beanFactory.registerResolvableDependency(BeanFactory.class, beanFactory);        beanFactory.registerResolvableDependency(ResourceLoader.class, this);        beanFactory.registerResolvableDependency(ApplicationEventPublisher.class, this);        beanFactory.registerResolvableDependency(ApplicationContext.class, this);        // Register early post-processor for detecting inner beans as ApplicationListeners.        // 添加一个BeanPostProcessor        beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(this));        // Detect a LoadTimeWeaver and prepare for weaving, if found.        //添加一个BeanPostProcessor，这个LoadTimeWeaverAwareProcessor跟第三方织入有关，以后再深入了解        if (beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123;            beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));            // Set a temporary ClassLoader for type matching.            beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));        &#125;        // Register default environment beans.        //注册几个单例        if (!beanFactory.containsLocalBean(ENVIRONMENT_BEAN_NAME)) &#123;            beanFactory.registerSingleton(ENVIRONMENT_BEAN_NAME, getEnvironment());        &#125;        if (!beanFactory.containsLocalBean(SYSTEM_PROPERTIES_BEAN_NAME)) &#123;            beanFactory.registerSingleton(SYSTEM_PROPERTIES_BEAN_NAME, getEnvironment().getSystemProperties());        &#125;        if (!beanFactory.containsLocalBean(SYSTEM_ENVIRONMENT_BEAN_NAME)) &#123;            beanFactory.registerSingleton(SYSTEM_ENVIRONMENT_BEAN_NAME, getEnvironment().getSystemEnvironment());        &#125;    &#125;</code></pre><p>过程直接看上边注释就可以大致了解。这里再看看BeanPostProcessor接口是干嘛的:</p><pre><code class="java">/** * Factory hook that allows for custom modification of new bean instances, * e.g. checking for marker interfaces or wrapping them with proxies. * * &lt;p&gt;ApplicationContexts can autodetect BeanPostProcessor beans in their * bean definitions and apply them to any beans subsequently created. * Plain bean factories allow for programmatic registration of post-processors, * applying to all beans created through this factory. * * &lt;p&gt;Typically, post-processors that populate beans via marker interfaces * or the like will implement &#123;@link #postProcessBeforeInitialization&#125;, * while post-processors that wrap beans with proxies will normally * implement &#123;@link #postProcessAfterInitialization&#125;. * * @author Juergen Hoeller * @since 10.10.2003 * @see InstantiationAwareBeanPostProcessor * @see DestructionAwareBeanPostProcessor * @see ConfigurableBeanFactory#addBeanPostProcessor * @see BeanFactoryPostProcessor */public interface BeanPostProcessor &#123;    /**     * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;before&lt;/i&gt; any bean     * initialization callbacks (like InitializingBean&#39;s &#123;@code afterPropertiesSet&#125;     * or a custom init-method). The bean will already be populated with property values.     * The returned bean instance may be a wrapper around the original.     * &lt;p&gt;The default implementation returns the given &#123;@code bean&#125; as-is.     * @param bean the new bean instance     * @param beanName the name of the bean     * @return the bean instance to use, either the original or a wrapped one;     * if &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked     * @throws org.springframework.beans.BeansException in case of errors     * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet     */    @Nullable    default Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123;        return bean;    &#125;    /**     * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;after&lt;/i&gt; any bean     * initialization callbacks (like InitializingBean&#39;s &#123;@code afterPropertiesSet&#125;     * or a custom init-method). The bean will already be populated with property values.     * The returned bean instance may be a wrapper around the original.     * &lt;p&gt;In case of a FactoryBean, this callback will be invoked for both the FactoryBean     * instance and the objects created by the FactoryBean (as of Spring 2.0). The     * post-processor can decide whether to apply to either the FactoryBean or created     * objects or both through corresponding &#123;@code bean instanceof FactoryBean&#125; checks.     * &lt;p&gt;This callback will also be invoked after a short-circuiting triggered by a     * &#123;@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation&#125; method,     * in contrast to all other BeanPostProcessor callbacks.     * &lt;p&gt;The default implementation returns the given &#123;@code bean&#125; as-is.     * @param bean the new bean instance     * @param beanName the name of the bean     * @return the bean instance to use, either the original or a wrapped one;     * if &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked     * @throws org.springframework.beans.BeansException in case of errors     * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet     * @see org.springframework.beans.factory.FactoryBean     */    @Nullable    default Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123;        return bean;    &#125;&#125;</code></pre><p>注释非常长，其实可以看到接口需要实现两个方法postProcessBeforeInitialization和postProcessAfterInitialization，顾名思义，可以知道这个接口的作用是在bean初始化前后分别做一些操作。</p><p>所以上边的ApplicationContextAwareProcessor正是实现了BeanPostProcessor，具体的作用是想在postProcessBeforeInitialization里,对实现了EnvironmentAware, EmbeddedValueResolverAware, ResourceLoaderAware, ApplicationEventPublisherAware, MessageSourceAware, ApplicationContextAware 等Aware接口的Bean进行一些接口特定的初始化动作。</p><p><strong>另外还有添加另外一个BeanPostProcessor为 LoadTimeWeaverAwareProcessor，这个是跟织入有关的，因为对AOP还不熟悉，后续再深入研究，这里mark之。</strong></p><h3 id="postProcessBeanFactory"><a href="#postProcessBeanFactory" class="headerlink" title="postProcessBeanFactory"></a>postProcessBeanFactory</h3><pre><code class="java">beanFactory.addBeanPostProcessor(new WebApplicationContextServletContextAwareProcessor(this));beanFactory.ignoreDependencyInterface(ServletContextAware.class);</code></pre><p>这里的postProcessBeanFactory#postProcessBeanFactory是个空方法，调用这个方法其实是调用了子类ServletWebServerApplicationContext和AnnotationConfigServletWebServerApplicationContext的里实现的方法。也只是看到注册了一个BeanPostProcessor,名叫WebApplicationContextServletContextAwareProcessor，没有做别的操作。</p><h3 id="invokeBeanFactoryPostProcessors"><a href="#invokeBeanFactoryPostProcessors" class="headerlink" title="invokeBeanFactoryPostProcessors"></a>invokeBeanFactoryPostProcessors</h3><p>这应该是最复杂的一个过程了，断断续续看了我一周多才看完。好吧， 请看：</p><pre><code class="java">/**     * Instantiate and invoke all registered BeanFactoryPostProcessor beans,     * respecting explicit order if given.     * &lt;p&gt;Must be called before singleton instantiation.     */    protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123;        PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors());        // Detect a LoadTimeWeaver and prepare for weaving, if found in the meantime        // (e.g. through an @Bean method registered by ConfigurationClassPostProcessor)        if (beanFactory.getTempClassLoader() == null &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123;            beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));            beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));        &#125;    &#125;</code></pre><p>入口非常简单，大部分逻辑都放在了工具类的方法invokeBeanFactoryPostProcessors。最后会检查是否有LoadTimeWeaver，如果有则做一些织入前的准备。我对Java的织入切面不够熟悉，大致分三类：编译期织入、类加载期织入和运行期织入。这个留到以后再去拓展一下。</p><p>下面对工具类的方法展开：</p><pre><code class="java">public static void invokeBeanFactoryPostProcessors(            ConfigurableListableBeanFactory beanFactory, List&lt;BeanFactoryPostProcessor&gt; beanFactoryPostProcessors) &#123;        // Invoke BeanDefinitionRegistryPostProcessors first, if any.        Set&lt;String&gt; processedBeans = new HashSet&lt;&gt;();        if (beanFactory instanceof BeanDefinitionRegistry) &#123;            BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory;            List&lt;BeanFactoryPostProcessor&gt; regularPostProcessors = new LinkedList&lt;&gt;();            List&lt;BeanDefinitionRegistryPostProcessor&gt; registryProcessors = new LinkedList&lt;&gt;();            for (BeanFactoryPostProcessor postProcessor : beanFactoryPostProcessors) &#123;                if (postProcessor instanceof BeanDefinitionRegistryPostProcessor) &#123;                    BeanDefinitionRegistryPostProcessor registryProcessor =                            (BeanDefinitionRegistryPostProcessor) postProcessor;                    registryProcessor.postProcessBeanDefinitionRegistry(registry);                    registryProcessors.add(registryProcessor);                &#125;                else &#123;                    regularPostProcessors.add(postProcessor);                &#125;            &#125;            // Do not initialize FactoryBeans here: We need to leave all regular beans            // uninitialized to let the bean factory post-processors apply to them!            // Separate between BeanDefinitionRegistryPostProcessors that implement            // PriorityOrdered, Ordered, and the rest.            List&lt;BeanDefinitionRegistryPostProcessor&gt; currentRegistryProcessors = new ArrayList&lt;&gt;();            // First, invoke the BeanDefinitionRegistryPostProcessors that implement PriorityOrdered.            String[] postProcessorNames =                    beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);            for (String ppName : postProcessorNames) &#123;                if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123;                    currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));                    processedBeans.add(ppName);                &#125;            &#125;            sortPostProcessors(currentRegistryProcessors, beanFactory);            registryProcessors.addAll(currentRegistryProcessors);            invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);            currentRegistryProcessors.clear();            // Next, invoke the BeanDefinitionRegistryPostProcessors that implement Ordered.            postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);            for (String ppName : postProcessorNames) &#123;                if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123;                    currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));                    processedBeans.add(ppName);                &#125;            &#125;            sortPostProcessors(currentRegistryProcessors, beanFactory);            registryProcessors.addAll(currentRegistryProcessors);            invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);            currentRegistryProcessors.clear();            // Finally, invoke all other BeanDefinitionRegistryPostProcessors until no further ones appear.            boolean reiterate = true;            while (reiterate) &#123;                reiterate = false;                postProcessorNames = beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);                for (String ppName : postProcessorNames) &#123;                    if (!processedBeans.contains(ppName)) &#123;                        currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));                        processedBeans.add(ppName);                        reiterate = true;                    &#125;                &#125;                sortPostProcessors(currentRegistryProcessors, beanFactory);                registryProcessors.addAll(currentRegistryProcessors);                invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);                currentRegistryProcessors.clear();            &#125;            // Now, invoke the postProcessBeanFactory callback of all processors handled so far.            invokeBeanFactoryPostProcessors(registryProcessors, beanFactory);            invokeBeanFactoryPostProcessors(regularPostProcessors, beanFactory);        &#125;        else &#123;            // Invoke factory processors registered with the context instance.            invokeBeanFactoryPostProcessors(beanFactoryPostProcessors, beanFactory);        &#125;        // Do not initialize FactoryBeans here: We need to leave all regular beans        // uninitialized to let the bean factory post-processors apply to them!        String[] postProcessorNames =                beanFactory.getBeanNamesForType(BeanFactoryPostProcessor.class, true, false);        // Separate between BeanFactoryPostProcessors that implement PriorityOrdered,        // Ordered, and the rest.        List&lt;BeanFactoryPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;();        List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;();        List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;();        for (String ppName : postProcessorNames) &#123;            if (processedBeans.contains(ppName)) &#123;                // skip - already processed in first phase above            &#125;            else if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123;                priorityOrderedPostProcessors.add(beanFactory.getBean(ppName, BeanFactoryPostProcessor.class));            &#125;            else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123;                orderedPostProcessorNames.add(ppName);            &#125;            else &#123;                nonOrderedPostProcessorNames.add(ppName);            &#125;        &#125;        // First, invoke the BeanFactoryPostProcessors that implement PriorityOrdered.        sortPostProcessors(priorityOrderedPostProcessors, beanFactory);        invokeBeanFactoryPostProcessors(priorityOrderedPostProcessors, beanFactory);        // Next, invoke the BeanFactoryPostProcessors that implement Ordered.        List&lt;BeanFactoryPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;();        for (String postProcessorName : orderedPostProcessorNames) &#123;            orderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));        &#125;        sortPostProcessors(orderedPostProcessors, beanFactory);        invokeBeanFactoryPostProcessors(orderedPostProcessors, beanFactory);        // Finally, invoke all other BeanFactoryPostProcessors.        List&lt;BeanFactoryPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;();        for (String postProcessorName : nonOrderedPostProcessorNames) &#123;            nonOrderedPostProcessors.add(beanFactory.getBean(postProcessorName, BeanFactoryPostProcessor.class));        &#125;        invokeBeanFactoryPostProcessors(nonOrderedPostProcessors, beanFactory);        // Clear cached merged bean definitions since the post-processors might have        // modified the original metadata, e.g. replacing placeholders in values...        beanFactory.clearMetadataCache();    &#125;</code></pre><p>非常长的方法，大致可以从第一个if那里划分两块逻辑。第一部分是处理BeanDefinitionRegistryPostProcessor的，第二部分是处理BeanFactoryPostProcessor。先看第一部分的流程：</p><ul><li>先看传入的beanFactory是不是BeanDefinitionRegistry类型，然后将传入的beanFactoryPostProcessors分为两类，一类实现了BeanDefinitionRegistryPostProcessor接口，存在registryProcessors；另一类没有实现该接口，存在regularPostProcessors。</li><li>接着，去beanFactory里捞出所有的实现了BeanDefinitionRegistryPostProcessor的Bean的名字，并从中捞出实现了PriorityOrdered接口的Bean，排序后，存到了上一步的registryProcessors中。然后触发<strong>invokeBeanDefinitionRegistryPostProcessors</strong>，这个方法主要是解析Configuratio类的，具体比较复杂，后文详细分析。</li><li>再接着，跟上边的类似，捞出所有的实现了BeanDefinitionRegistryPostProcessor以及Ordered接口的Bean，做类似的动作。由此可以看到PriorityOrdered接口优先级更高。这两个排序接口的应用还可以看看<a href="https://github.com/spring-projects/spring-framework/blob/master/spring-core/src/main/java/org/springframework/core/OrderComparator.java">OrderComparator</a>.</li><li>接下来还是跟上边类似，这次用了一个while循环，确保不会遗漏任何一个实现了BeanDefinitionRegistryPostProcessor接口的bean</li><li>最后对上边所有的调用<strong>invokeBeanFactoryPostProcessors</strong>，这也是一个复杂的方法，后文详细分析。</li></ul><p>第一部分总结：主要是周而复始地处理实现了BeanDefinitionRegistryPostProcessor接口的bean，一共重复了三次。另外，比较重要的方法有两个<strong>invokeBeanDefinitionRegistryPostProcessors</strong> 和 <strong>invokeBeanFactoryPostProcessors</strong></p><p>再来看看第二部分：</p><ul><li>跟第一部分类似，捞出所有实现了BeanFactoryPostProcessor接口的bean的名字，然后根据是否实现了PriorityOrdered 和 Ordered ，分成三类，分别存到三个不同的list里去。</li><li>分别对priorityOrderedPostProcessors和orderedPostProcessors，进行排序，并且调用<strong>invokeBeanFactoryPostProcessors</strong></li><li>再对nonOrderedPostProcessors调用<strong>invokeBeanFactoryPostProcessors</strong></li></ul><p>第二部分总结：跟第一部分类似，有一个相同的重要方法：<strong>invokeBeanFactoryPostProcessors</strong></p><p>现在开始重点分析这两个重要方法：</p><h4 id="重要方法1：invokeBeanDefinitionRegistryPostProcessors"><a href="#重要方法1：invokeBeanDefinitionRegistryPostProcessors" class="headerlink" title="重要方法1：invokeBeanDefinitionRegistryPostProcessors"></a>重要方法1：invokeBeanDefinitionRegistryPostProcessors</h4><pre><code class="java">/**     * Invoke the given BeanDefinitionRegistryPostProcessor beans.     */    private static void invokeBeanDefinitionRegistryPostProcessors(            Collection&lt;? extends BeanDefinitionRegistryPostProcessor&gt; postProcessors, BeanDefinitionRegistry registry) &#123;        for (BeanDefinitionRegistryPostProcessor postProcessor : postProcessors) &#123;            postProcessor.postProcessBeanDefinitionRegistry(registry);        &#125;    &#125;</code></pre><p>调试发现，这个方法进去，只有一个postProcessor，类型为ConfigurationClassPostProcessor,看看注释说到：<br>ConfigurationClassPostProcessor是一个用于引导加载@Configuration标注的类的BeanFactoryPostProcessor接口的实例。xml加载方式一般用<a href="context:annotation-config/">context:annotation-config/</a> 或者 <a href="context:component-scan/">context:component-scan/</a>注册，spring boot的的非xml注册方式的话在ApplicationContext对象创建时，会调用 AnnotationConfigUtils.registerAnnotationConfigProcessors() 注册这个BeanFactoryPostProcessor。然后说到这个ConfigurationClassPostProcessor拥有最高优先级，因为其他的通过方法注入的bean都要等这个ConfigurationClassPostProcessor执行完后才能注册。</p><p>这里有点奇怪的是ConfigurationClassPostProcessor的Orderd接口的是实现方法返回的是最低优先级，这里应该跟上文的最高优先级没啥联系，应该是BeanDefinitionRegistryPostProcessor之间的优先级，但为啥这玩意儿的优先级要最低呢？不懂…以后会懂的…</p><pre><code class="java">@Override    public int getOrder() &#123;        return Ordered.LOWEST_PRECEDENCE;  // within PriorityOrdered    &#125;</code></pre><p>接着看ConfigurationClassPostProcessor的postProcessBeanDefinitionRegistry方法：</p><pre><code class="java">/**     * Derive further bean definitions from the configuration classes in the registry.     */    @Override    public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) &#123;        int registryId = System.identityHashCode(registry);        if (this.registriesPostProcessed.contains(registryId)) &#123;            throw new IllegalStateException(                    &quot;postProcessBeanDefinitionRegistry already called on this post-processor against &quot; + registry);        &#125;        if (this.factoriesPostProcessed.contains(registryId)) &#123;            throw new IllegalStateException(                    &quot;postProcessBeanFactory already called on this post-processor against &quot; + registry);        &#125;        this.registriesPostProcessed.add(registryId);        processConfigBeanDefinitions(registry);    &#125;</code></pre><p>先是获取这个registry的identityHashCode，这个code其实是对象object的内存地址，一旦对象实例化后就不会再变动，但对象的hashcode一般是重载过的，一般是伴随对象的字段值变化而变化。</p><p>这里先拿到registryId，然后看看这个registry有没有被处理过。</p><p>然后就进入了processConfigBeanDefinitions(registry)方法：</p><pre><code class="java">/**     * Build and validate a configuration model based on the registry of     * &#123;@link Configuration&#125; classes.     */    public void processConfigBeanDefinitions(BeanDefinitionRegistry registry) &#123;        List&lt;BeanDefinitionHolder&gt; configCandidates = new ArrayList&lt;&gt;();        String[] candidateNames = registry.getBeanDefinitionNames();        for (String beanName : candidateNames) &#123;            BeanDefinition beanDef = registry.getBeanDefinition(beanName);            if (ConfigurationClassUtils.isFullConfigurationClass(beanDef) ||                    ConfigurationClassUtils.isLiteConfigurationClass(beanDef)) &#123;                if (logger.isDebugEnabled()) &#123;                    logger.debug(&quot;Bean definition has already been processed as a configuration class: &quot; + beanDef);                &#125;            &#125;            else if (ConfigurationClassUtils.checkConfigurationClassCandidate(beanDef, this.metadataReaderFactory)) &#123;                configCandidates.add(new BeanDefinitionHolder(beanDef, beanName));            &#125;        &#125;        // Return immediately if no @Configuration classes were found        if (configCandidates.isEmpty()) &#123;            return;        &#125;        // Sort by previously determined @Order value, if applicable        configCandidates.sort((bd1, bd2) -&gt; &#123;            int i1 = ConfigurationClassUtils.getOrder(bd1.getBeanDefinition());            int i2 = ConfigurationClassUtils.getOrder(bd2.getBeanDefinition());            return Integer.compare(i1, i2);        &#125;);        // Detect any custom bean name generation strategy supplied through the enclosing application context        SingletonBeanRegistry sbr = null;        if (registry instanceof SingletonBeanRegistry) &#123;            sbr = (SingletonBeanRegistry) registry;            if (!this.localBeanNameGeneratorSet) &#123;                BeanNameGenerator generator = (BeanNameGenerator) sbr.getSingleton(CONFIGURATION_BEAN_NAME_GENERATOR);                if (generator != null) &#123;                    this.componentScanBeanNameGenerator = generator;                    this.importBeanNameGenerator = generator;                &#125;            &#125;        &#125;        if (this.environment == null) &#123;            this.environment = new StandardEnvironment();        &#125;        // Parse each @Configuration class        ConfigurationClassParser parser = new ConfigurationClassParser(                this.metadataReaderFactory, this.problemReporter, this.environment,                this.resourceLoader, this.componentScanBeanNameGenerator, registry);        Set&lt;BeanDefinitionHolder&gt; candidates = new LinkedHashSet&lt;&gt;(configCandidates);        Set&lt;ConfigurationClass&gt; alreadyParsed = new HashSet&lt;&gt;(configCandidates.size());        do &#123;            parser.parse(candidates);            parser.validate();            Set&lt;ConfigurationClass&gt; configClasses = new LinkedHashSet&lt;&gt;(parser.getConfigurationClasses());            configClasses.removeAll(alreadyParsed);            // Read the model and create bean definitions based on its content            if (this.reader == null) &#123;                this.reader = new ConfigurationClassBeanDefinitionReader(                        registry, this.sourceExtractor, this.resourceLoader, this.environment,                        this.importBeanNameGenerator, parser.getImportRegistry());            &#125;            this.reader.loadBeanDefinitions(configClasses);            alreadyParsed.addAll(configClasses);            candidates.clear();            if (registry.getBeanDefinitionCount() &gt; candidateNames.length) &#123;                String[] newCandidateNames = registry.getBeanDefinitionNames();                Set&lt;String&gt; oldCandidateNames = new HashSet&lt;&gt;(Arrays.asList(candidateNames));                Set&lt;String&gt; alreadyParsedClasses = new HashSet&lt;&gt;();                for (ConfigurationClass configurationClass : alreadyParsed) &#123;                    alreadyParsedClasses.add(configurationClass.getMetadata().getClassName());                &#125;                for (String candidateName : newCandidateNames) &#123;                    if (!oldCandidateNames.contains(candidateName)) &#123;                        BeanDefinition bd = registry.getBeanDefinition(candidateName);                        if (ConfigurationClassUtils.checkConfigurationClassCandidate(bd, this.metadataReaderFactory) &amp;&amp;                                !alreadyParsedClasses.contains(bd.getBeanClassName())) &#123;                            candidates.add(new BeanDefinitionHolder(bd, candidateName));                        &#125;                    &#125;                &#125;                candidateNames = newCandidateNames;            &#125;        &#125;        while (!candidates.isEmpty());        // Register the ImportRegistry as a bean in order to support ImportAware @Configuration classes        if (sbr != null &amp;&amp; !sbr.containsSingleton(IMPORT_REGISTRY_BEAN_NAME)) &#123;            sbr.registerSingleton(IMPORT_REGISTRY_BEAN_NAME, parser.getImportRegistry());        &#125;        if (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) &#123;            // Clear cache in externally provided MetadataReaderFactory; this is a no-op            // for a shared cache since it&#39;ll be cleared by the ApplicationContext.            ((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache();        &#125;    &#125;</code></pre><p>方法很长，逐步分析：</p><ul><li>第一，先是去registry里取出全部注册的的名字，然后看看这些bean，如果已经标记了是FullConfiguration或者LiteConfiguration的话，表示已经处理过了，跳过；否则的话，通过工具类方法ConfigurationClassUtils.checkConfigurationClassCandidate去检查是不是@Configuration和@Component标记的bean，是的话，加入候选configCandidates中；</li></ul><blockquote><p>这里先对工具类ConfigurationClassUtils出现的三个方法进行展开看看：<br><strong>isFullConfigurationCandidate</strong> 判断bean是否被@Configuration注解标记<br><strong>isLiteConfigurationCandidate</strong> 判断bean是否被@Component、@ComponentScan、@Import、@ImportResource 注解标记，或者包含一个被@Bean注解标记的方法。<br><strong>checkConfigurationClassCandidate</strong> 检查bean是不是Full或者Lite的Configuration候选类。这个方法主要是获取该类的AnnotationMetadata，然后根据包含的注解情况，给标注为Full或者是Lite</p></blockquote><ul><li>第二，如果configCandidates为空，直接返回结束方法；否则，对其排序，取@Order指定的值进行比较（默认Ordered#LOWEST_PRECEDENCE）；</li><li>第三，看看是否有注册单例的BeanNameGenerator，这个玩意儿是用于生成bean名字的。举个例子，比如@Reposity注解的类会被spring自动识别为bean，这个bean默认的名字是类名首字母小写，如果有注册BeanNameGenerator的话，就可以自定义这个bean的名字；</li><li>第四，这一块实例化一个ConfigurationClassParser，顾名思义，就是用来解析@Configuration的类的解析器。这里一个do…while…循环，直到所有的类都被解析完毕。</li></ul><p>现在重点分析ConfigurationClassParser，先看parse方法：</p><pre><code class="java">public void parse(Set&lt;BeanDefinitionHolder&gt; configCandidates) &#123;        this.deferredImportSelectors = new LinkedList&lt;&gt;();        for (BeanDefinitionHolder holder : configCandidates) &#123;            BeanDefinition bd = holder.getBeanDefinition();            try &#123;                if (bd instanceof AnnotatedBeanDefinition) &#123;                    parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName());                &#125;                else if (bd instanceof AbstractBeanDefinition &amp;&amp; ((AbstractBeanDefinition) bd).hasBeanClass()) &#123;                    parse(((AbstractBeanDefinition) bd).getBeanClass(), holder.getBeanName());                &#125;                else &#123;                    parse(bd.getBeanClassName(), holder.getBeanName());                &#125;            &#125;            catch (BeanDefinitionStoreException ex) &#123;                throw ex;            &#125;            catch (Throwable ex) &#123;                throw new BeanDefinitionStoreException(                        &quot;Failed to parse configuration class [&quot; + bd.getBeanClassName() + &quot;]&quot;, ex);            &#125;        &#125;        processDeferredImportSelectors();    &#125;</code></pre><p>parse方法一进来就可以看到，根据BeanDefinition的类型，分别调用三个不同的parse方法。然后看三个parse方法殊途同归，最后都是调用了processConfigurationClass方法，看下这个方法代码：</p><pre><code class="java">protected void processConfigurationClass(ConfigurationClass configClass) throws IOException &#123;        if (this.conditionEvaluator.shouldSkip(configClass.getMetadata(), ConfigurationPhase.PARSE_CONFIGURATION)) &#123;            return;        &#125;        ConfigurationClass existingClass = this.configurationClasses.get(configClass);        if (existingClass != null) &#123;            if (configClass.isImported()) &#123;                if (existingClass.isImported()) &#123;                    existingClass.mergeImportedBy(configClass);                &#125;                // Otherwise ignore new imported config class; existing non-imported class overrides it.                return;            &#125;            else &#123;                // Explicit bean definition found, probably replacing an import.                // Let&#39;s remove the old one and go with the new one.                this.configurationClasses.remove(configClass);                this.knownSuperclasses.values().removeIf(configClass::equals);            &#125;        &#125;        // Recursively process the configuration class and its superclass hierarchy.        SourceClass sourceClass = asSourceClass(configClass);        do &#123;            sourceClass = doProcessConfigurationClass(configClass, sourceClass);        &#125;        while (sourceClass != null);        this.configurationClasses.put(configClass, configClass);    &#125;</code></pre><p>processConfigurationClass一开始先是检查configuration的Condition条件是否满足，不满足的话直接返回。shouldSkip方法展开看看，有点小意思：</p><pre><code class="java">/**     * Determine if an item should be skipped based on &#123;@code @Conditional&#125; annotations.     * @param metadata the meta data     * @param phase the phase of the call     * @return if the item should be skipped     */    public boolean shouldSkip(@Nullable AnnotatedTypeMetadata metadata, @Nullable ConfigurationPhase phase) &#123;        if (metadata == null || !metadata.isAnnotated(Conditional.class.getName())) &#123;            return false;        &#125;        if (phase == null) &#123;            if (metadata instanceof AnnotationMetadata &amp;&amp;                    ConfigurationClassUtils.isConfigurationCandidate((AnnotationMetadata) metadata)) &#123;                return shouldSkip(metadata, ConfigurationPhase.PARSE_CONFIGURATION);            &#125;            return shouldSkip(metadata, ConfigurationPhase.REGISTER_BEAN);        &#125;        List&lt;Condition&gt; conditions = new ArrayList&lt;&gt;();        for (String[] conditionClasses : getConditionClasses(metadata)) &#123;            for (String conditionClass : conditionClasses) &#123;                Condition condition = getCondition(conditionClass, this.context.getClassLoader());                conditions.add(condition);            &#125;        &#125;        AnnotationAwareOrderComparator.sort(conditions);        for (Condition condition : conditions) &#123;            ConfigurationPhase requiredPhase = null;            if (condition instanceof ConfigurationCondition) &#123;                requiredPhase = ((ConfigurationCondition) condition).getConfigurationPhase();            &#125;            if ((requiredPhase == null || requiredPhase == phase) &amp;&amp; !condition.matches(this.context, metadata)) &#123;                return true;            &#125;        &#125;        return false;    &#125;</code></pre><p>在shouldSkip里看到从getConditionClasses(metadata)里获取所有的Conditional条件，然后一个for循环遍历所有的<br>condition看是否match，一旦没有match就意味着要skip了。这里可以看到@Conditional、ConditionalOnBean等Condition类的注解是与关系的。Condition类的注解使用不在本文讨论范围，以后会展开看看。mark</p><p>继续看processConfigurationClass方法，判断完是否skip之后，再看看是否已经解析过这个Configuration，一旦解析过，如果两者都是import进来的，则合并两者的ImportedBy；如果先解析的是import进来的的，则抛弃之，重新解析。</p><p>然后将configClass转化为SourceClass类型，SourceClass类型里有很多强大的方法，比如获得内部类getMemberClasses()。</p><p>然后循环进行doProcessConfigurationClass(configClass, sourceClass) 去看看：</p><pre><code class="java">/**     * Apply processing and build a complete &#123;@link ConfigurationClass&#125; by reading the     * annotations, members and methods from the source class. This method can be called     * multiple times as relevant sources are discovered.     * @param configClass the configuration class being build     * @param sourceClass a source class     * @return the superclass, or &#123;@code null&#125; if none found or previously processed     */    @Nullable    protected final SourceClass doProcessConfigurationClass(ConfigurationClass configClass, SourceClass sourceClass)            throws IOException &#123;        // Recursively process any member (nested) classes first        processMemberClasses(configClass, sourceClass);        // Process any @PropertySource annotations        for (AnnotationAttributes propertySource : AnnotationConfigUtils.attributesForRepeatable(                sourceClass.getMetadata(), PropertySources.class,                org.springframework.context.annotation.PropertySource.class)) &#123;            if (this.environment instanceof ConfigurableEnvironment) &#123;                processPropertySource(propertySource);            &#125;            else &#123;                logger.warn(&quot;Ignoring @PropertySource annotation on [&quot; + sourceClass.getMetadata().getClassName() +                        &quot;]. Reason: Environment must implement ConfigurableEnvironment&quot;);            &#125;        &#125;        // Process any @ComponentScan annotations        Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable(                sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class);        if (!componentScans.isEmpty() &amp;&amp;                !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) &#123;            for (AnnotationAttributes componentScan : componentScans) &#123;                // The config class is annotated with @ComponentScan -&gt; perform the scan immediately                Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions =                        this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName());                // Check the set of scanned definitions for any further config classes and parse recursively if needed                for (BeanDefinitionHolder holder : scannedBeanDefinitions) &#123;                    BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition();                    if (bdCand == null) &#123;                        bdCand = holder.getBeanDefinition();                    &#125;                    if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) &#123;                        parse(bdCand.getBeanClassName(), holder.getBeanName());                    &#125;                &#125;            &#125;        &#125;        // Process any @Import annotations        processImports(configClass, sourceClass, getImports(sourceClass), true);        // Process any @ImportResource annotations        AnnotationAttributes importResource =                AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(), ImportResource.class);        if (importResource != null) &#123;            String[] resources = importResource.getStringArray(&quot;locations&quot;);            Class&lt;? extends BeanDefinitionReader&gt; readerClass = importResource.getClass(&quot;reader&quot;);            for (String resource : resources) &#123;                String resolvedResource = this.environment.resolveRequiredPlaceholders(resource);                configClass.addImportedResource(resolvedResource, readerClass);            &#125;        &#125;        // Process individual @Bean methods        Set&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(sourceClass);        for (MethodMetadata methodMetadata : beanMethods) &#123;            configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass));        &#125;        // Process default methods on interfaces        processInterfaces(configClass, sourceClass);        // Process superclass, if any        if (sourceClass.getMetadata().hasSuperClass()) &#123;            String superclass = sourceClass.getMetadata().getSuperClassName();            if (superclass != null &amp;&amp; !superclass.startsWith(&quot;java&quot;) &amp;&amp;                    !this.knownSuperclasses.containsKey(superclass)) &#123;                this.knownSuperclasses.put(superclass, configClass);                // Superclass found, return its annotation metadata and recurse                return sourceClass.getSuperClass();            &#125;        &#125;        // No superclass -&gt; processing is complete        return null;    &#125;</code></pre><p>很长的方法，但是清晰，从上而下分别是解析嵌套类（member class)、@PropertySource、@ComponentScan、@Import、@ImportResource、@Bean、接口方法、超类等；</p><p>分别看看：</p><ul><li><strong>解析嵌套类（member class)</strong> 调用<strong>processMemberClasses</strong>方法，先从sourceClass里取出所有的memberClass，判断如果是Configuration类的话，加入候选集。然后通过importStack栈来避免死循环，接下来又调用processConfigurationClass方法递归下去解析</li></ul><pre><code class="java">/**     * Register member (nested) classes that happen to be configuration classes themselves.     */    private void processMemberClasses(ConfigurationClass configClass, SourceClass sourceClass) throws IOException &#123;        Collection&lt;SourceClass&gt; memberClasses = sourceClass.getMemberClasses();        if (!memberClasses.isEmpty()) &#123;            List&lt;SourceClass&gt; candidates = new ArrayList&lt;&gt;(memberClasses.size());            for (SourceClass memberClass : memberClasses) &#123;                if (ConfigurationClassUtils.isConfigurationCandidate(memberClass.getMetadata()) &amp;&amp;                        !memberClass.getMetadata().getClassName().equals(configClass.getMetadata().getClassName())) &#123;                    candidates.add(memberClass);                &#125;            &#125;            OrderComparator.sort(candidates);            for (SourceClass candidate : candidates) &#123;                if (this.importStack.contains(configClass)) &#123;                    this.problemReporter.error(new CircularImportProblem(configClass, this.importStack));                &#125;                else &#123;                    this.importStack.push(configClass);                    try &#123;                        processConfigurationClass(candidate.asConfigClass(configClass));                    &#125;                    finally &#123;                        this.importStack.pop();                    &#125;                &#125;            &#125;        &#125;    &#125;</code></pre><ul><li><strong>@PropertySource</strong> 获取所有的@PropertySource，然后逐个解析呗，没啥复杂的，请直接看代码：</li></ul><pre><code class="java">/**     * Process the given &lt;code&gt;@PropertySource&lt;/code&gt; annotation metadata.     * @param propertySource metadata for the &lt;code&gt;@PropertySource&lt;/code&gt; annotation found     * @throws IOException if loading a property source failed     */    private void processPropertySource(AnnotationAttributes propertySource) throws IOException &#123;        String name = propertySource.getString(&quot;name&quot;);        if (!StringUtils.hasLength(name)) &#123;            name = null;        &#125;        String encoding = propertySource.getString(&quot;encoding&quot;);        if (!StringUtils.hasLength(encoding)) &#123;            encoding = null;        &#125;        String[] locations = propertySource.getStringArray(&quot;value&quot;);        Assert.isTrue(locations.length &gt; 0, &quot;At least one @PropertySource(value) location is required&quot;);        boolean ignoreResourceNotFound = propertySource.getBoolean(&quot;ignoreResourceNotFound&quot;);        Class&lt;? extends PropertySourceFactory&gt; factoryClass = propertySource.getClass(&quot;factory&quot;);        PropertySourceFactory factory = (factoryClass == PropertySourceFactory.class ?                DEFAULT_PROPERTY_SOURCE_FACTORY : BeanUtils.instantiateClass(factoryClass));        for (String location : locations) &#123;            try &#123;                String resolvedLocation = this.environment.resolveRequiredPlaceholders(location);                Resource resource = this.resourceLoader.getResource(resolvedLocation);                addPropertySource(factory.createPropertySource(name, new EncodedResource(resource, encoding)));            &#125;            catch (IllegalArgumentException | FileNotFoundException | UnknownHostException ex) &#123;                // Placeholders not resolvable or resource not found when trying to open it                if (ignoreResourceNotFound) &#123;                    if (logger.isInfoEnabled()) &#123;                        logger.info(&quot;Properties location [&quot; + location + &quot;] not resolvable: &quot; + ex.getMessage());                    &#125;                &#125;                else &#123;                    throw ex;                &#125;            &#125;        &#125;    &#125;</code></pre><ul><li><strong>@ComponentScan</strong></li></ul><p>遍历这个Configuration的所有的@ComponentScan注解，对每一个ComponentScan进行扫描，找出所有注册的Bean存放在Set<BeanDefinitionHolder> scannedBeanDefinitions里，然后对这个Set遍历，然后逐个检查是否是Configuration候选类，是的话，递归调用parse方法进行解析。请看代码：</p><pre><code class="java">// Process any @ComponentScan annotations        Set&lt;AnnotationAttributes&gt; componentScans = AnnotationConfigUtils.attributesForRepeatable(                sourceClass.getMetadata(), ComponentScans.class, ComponentScan.class);        if (!componentScans.isEmpty() &amp;&amp;                !this.conditionEvaluator.shouldSkip(sourceClass.getMetadata(), ConfigurationPhase.REGISTER_BEAN)) &#123;            for (AnnotationAttributes componentScan : componentScans) &#123;                // The config class is annotated with @ComponentScan -&gt; perform the scan immediately                Set&lt;BeanDefinitionHolder&gt; scannedBeanDefinitions =                        this.componentScanParser.parse(componentScan, sourceClass.getMetadata().getClassName());                // Check the set of scanned definitions for any further config classes and parse recursively if needed                for (BeanDefinitionHolder holder : scannedBeanDefinitions) &#123;                    BeanDefinition bdCand = holder.getBeanDefinition().getOriginatingBeanDefinition();                    if (bdCand == null) &#123;                        bdCand = holder.getBeanDefinition();                    &#125;                    if (ConfigurationClassUtils.checkConfigurationClassCandidate(bdCand, this.metadataReaderFactory)) &#123;                        parse(bdCand.getBeanClassName(), holder.getBeanName());                    &#125;                &#125;            &#125;        &#125;</code></pre><ul><li><strong>@Import</strong> 同样是先处理死循环的情形，然后根据import导入的class的类型，分为实现了接口ImportSelector、实现了接口ImportBeanDefinitionRegistrar、两者都没实现等三种情况进行解析，其中ImportSelector里，还划分出延迟导入的类型，实现了DeferredImportSelector接口，这个接口也是继承了ImportSelector。关于这几个接口的细节不是本文讨论内容，请移步：<a href="https://my.oschina.net/u/3058881/blog/1673957">https://my.oschina.net/u/3058881/blog/1673957</a>,延迟导入接口资料比较少，后文还会提及。</li></ul><pre><code class="java">private void processImports(ConfigurationClass configClass, SourceClass currentSourceClass,            Collection&lt;SourceClass&gt; importCandidates, boolean checkForCircularImports) &#123;        if (importCandidates.isEmpty()) &#123;            return;        &#125;        if (checkForCircularImports &amp;&amp; isChainedImportOnStack(configClass)) &#123;            this.problemReporter.error(new CircularImportProblem(configClass, this.importStack));        &#125;        else &#123;            this.importStack.push(configClass);            try &#123;                for (SourceClass candidate : importCandidates) &#123;                    if (candidate.isAssignable(ImportSelector.class)) &#123;                        // Candidate class is an ImportSelector -&gt; delegate to it to determine imports                        Class&lt;?&gt; candidateClass = candidate.loadClass();                        ImportSelector selector = BeanUtils.instantiateClass(candidateClass, ImportSelector.class);                        ParserStrategyUtils.invokeAwareMethods(                                selector, this.environment, this.resourceLoader, this.registry);                        if (this.deferredImportSelectors != null &amp;&amp; selector instanceof DeferredImportSelector) &#123;                            this.deferredImportSelectors.add(                                    new DeferredImportSelectorHolder(configClass, (DeferredImportSelector) selector));                        &#125;                        else &#123;                            String[] importClassNames = selector.selectImports(currentSourceClass.getMetadata());                            Collection&lt;SourceClass&gt; importSourceClasses = asSourceClasses(importClassNames);                            processImports(configClass, currentSourceClass, importSourceClasses, false);                        &#125;                    &#125;                    else if (candidate.isAssignable(ImportBeanDefinitionRegistrar.class)) &#123;                        // Candidate class is an ImportBeanDefinitionRegistrar -&gt;                        // delegate to it to register additional bean definitions                        Class&lt;?&gt; candidateClass = candidate.loadClass();                        ImportBeanDefinitionRegistrar registrar =                                BeanUtils.instantiateClass(candidateClass, ImportBeanDefinitionRegistrar.class);                        ParserStrategyUtils.invokeAwareMethods(                                registrar, this.environment, this.resourceLoader, this.registry);                        configClass.addImportBeanDefinitionRegistrar(registrar, currentSourceClass.getMetadata());                    &#125;                    else &#123;                        // Candidate class not an ImportSelector or ImportBeanDefinitionRegistrar -&gt;                        // process it as an @Configuration class                        this.importStack.registerImport(                                currentSourceClass.getMetadata(), candidate.getMetadata().getClassName());                        processConfigurationClass(candidate.asConfigClass(configClass));                    &#125;                &#125;            &#125;            catch (BeanDefinitionStoreException ex) &#123;                throw ex;            &#125;            catch (Throwable ex) &#123;                throw new BeanDefinitionStoreException(                        &quot;Failed to process import candidates for configuration class [&quot; +                        configClass.getMetadata().getClassName() + &quot;]&quot;, ex);            &#125;            finally &#123;                this.importStack.pop();            &#125;        &#125;    &#125;</code></pre><ul><li><strong>@ImportResource</strong> 非常简单，直接看代码：</li></ul><pre><code class="java">// Process any @ImportResource annotations        AnnotationAttributes importResource =                AnnotationConfigUtils.attributesFor(sourceClass.getMetadata(), ImportResource.class);        if (importResource != null) &#123;            String[] resources = importResource.getStringArray(&quot;locations&quot;);            Class&lt;? extends BeanDefinitionReader&gt; readerClass = importResource.getClass(&quot;reader&quot;);            for (String resource : resources) &#123;                String resolvedResource = this.environment.resolveRequiredPlaceholders(resource);                configClass.addImportedResource(resolvedResource, readerClass);            &#125;        &#125;</code></pre><ul><li><strong>@Bean methods</strong> 先获取所有的带有@Bean注释的方法，然后全部添加到configClass里，这里并没有实例化。再看看获取方法的代码，可以看到，方法里尝试使用Java字节码解析技术ASM解析获取所有的方法，然后对从AnnotationMetadata里获得的方法进行简单的过滤 ：</li></ul><pre><code class="java">    /**     * Retrieve the metadata for all &lt;code&gt;@Bean&lt;/code&gt; methods.     */    private Set&lt;MethodMetadata&gt; retrieveBeanMethodMetadata(SourceClass sourceClass) &#123;        AnnotationMetadata original = sourceClass.getMetadata();        Set&lt;MethodMetadata&gt; beanMethods = original.getAnnotatedMethods(Bean.class.getName());        if (beanMethods.size() &gt; 1 &amp;&amp; original instanceof StandardAnnotationMetadata) &#123;            // Try reading the class file via ASM for deterministic declaration order...            // Unfortunately, the JVM&#39;s standard reflection returns methods in arbitrary            // order, even between different runs of the same application on the same JVM.            try &#123;                AnnotationMetadata asm =                        this.metadataReaderFactory.getMetadataReader(original.getClassName()).getAnnotationMetadata();                Set&lt;MethodMetadata&gt; asmMethods = asm.getAnnotatedMethods(Bean.class.getName());                if (asmMethods.size() &gt;= beanMethods.size()) &#123;                    Set&lt;MethodMetadata&gt; selectedMethods = new LinkedHashSet&lt;&gt;(asmMethods.size());                    for (MethodMetadata asmMethod : asmMethods) &#123;                        for (MethodMetadata beanMethod : beanMethods) &#123;                            if (beanMethod.getMethodName().equals(asmMethod.getMethodName())) &#123;                                selectedMethods.add(beanMethod);                                break;                            &#125;                        &#125;                    &#125;                    if (selectedMethods.size() == beanMethods.size()) &#123;                        // All reflection-detected methods found in ASM method set -&gt; proceed                        beanMethods = selectedMethods;                    &#125;                &#125;            &#125;            catch (IOException ex) &#123;                logger.debug(&quot;Failed to read class file via ASM for determining @Bean method order&quot;, ex);                // No worries, let&#39;s continue with the reflection metadata we started with...            &#125;        &#125;        return beanMethods;    &#125;</code></pre><ul><li><strong>接口方法</strong> 遍历实现的所有接口，或者这些接口的方法中被@Bean注解的方法，同样添加到configclass的beanMethods中。</li></ul><pre><code class="java">/**     * Register default methods on interfaces implemented by the configuration class.     */    private void processInterfaces(ConfigurationClass configClass, SourceClass sourceClass) throws IOException &#123;        for (SourceClass ifc : sourceClass.getInterfaces()) &#123;            Set&lt;MethodMetadata&gt; beanMethods = retrieveBeanMethodMetadata(ifc);            for (MethodMetadata methodMetadata : beanMethods) &#123;                if (!methodMetadata.isAbstract()) &#123;                    // A default method or other concrete method on a Java 8+ interface...                    configClass.addBeanMethod(new BeanMethod(methodMetadata, configClass));                &#125;            &#125;            processInterfaces(configClass, ifc);        &#125;    &#125;</code></pre><ul><li><strong>超类</strong> 也是很简单，递归遍历超类，排除java内部类。</li></ul><pre><code class="java">// Process superclass, if any        if (sourceClass.getMetadata().hasSuperClass()) &#123;            String superclass = sourceClass.getMetadata().getSuperClassName();            if (superclass != null &amp;&amp; !superclass.startsWith(&quot;java&quot;) &amp;&amp;                    !this.knownSuperclasses.containsKey(superclass)) &#123;                this.knownSuperclasses.put(superclass, configClass);                // Superclass found, return its annotation metadata and recurse                return sourceClass.getSuperClass();            &#125;        &#125;</code></pre><p>好了，processConfigurationClass分析得差不多了，回过头，重新回到ConfigurationClassParser#parse方法，可以看到，三个分叉的parse结束之后，我们其实已经完成了Configuration类的解析工作，最后还有一步processDeferredImportSelectors(),请看：</p><pre><code class="java">private void processDeferredImportSelectors() &#123;        List&lt;DeferredImportSelectorHolder&gt; deferredImports = this.deferredImportSelectors;        this.deferredImportSelectors = null;        if (deferredImports == null) &#123;            return;        &#125;        deferredImports.sort(DEFERRED_IMPORT_COMPARATOR);        Map&lt;Object, DeferredImportSelectorGrouping&gt; groupings = new LinkedHashMap&lt;&gt;();        Map&lt;AnnotationMetadata, ConfigurationClass&gt; configurationClasses = new HashMap&lt;&gt;();        for (DeferredImportSelectorHolder deferredImport : deferredImports) &#123;            Class&lt;? extends Group&gt; group = deferredImport.getImportSelector().getImportGroup();            DeferredImportSelectorGrouping grouping = groupings.computeIfAbsent(                    (group == null ? deferredImport : group),                    (key) -&gt; new DeferredImportSelectorGrouping(createGroup(group)));            grouping.add(deferredImport);            configurationClasses.put(deferredImport.getConfigurationClass().getMetadata(),                    deferredImport.getConfigurationClass());        &#125;        for (DeferredImportSelectorGrouping grouping : groupings.values()) &#123;            grouping.getImports().forEach((entry) -&gt; &#123;                ConfigurationClass configurationClass = configurationClasses.get(                        entry.getMetadata());                try &#123;                    processImports(configurationClass, asSourceClass(configurationClass),                            asSourceClasses(entry.getImportClassName()), false);                &#125;                catch (BeanDefinitionStoreException ex) &#123;                    throw ex;                &#125;                catch (Throwable ex) &#123;                    throw new BeanDefinitionStoreException(                            &quot;Failed to process import candidates for configuration class [&quot; +                                    configurationClass.getMetadata().getClassName() + &quot;]&quot;, ex);                &#125;            &#125;);        &#125;    &#125;</code></pre><p>这里处理的就是上文提及的延迟导入。这里先将deferredImportSelectors分组，然后各组分别调用processImports，为啥要分组，这个问题先mark下。这里有个小细节要注意下，就是this.deferredImportSelectors &#x3D; null，下边会提到。</p><p>继续看processImports方法,这个方法上文其实已经分析过了，这里只看一小部分代码：</p><pre><code class="java">    if (this.deferredImportSelectors != null &amp;&amp; selector instanceof DeferredImportSelector) &#123;        this.deferredImportSelectors.add(                new DeferredImportSelectorHolder(configClass, (DeferredImportSelector) selector));    &#125;    else &#123;        String[] importClassNames = selector.selectImports(currentSourceClass.getMetadata());        Collection&lt;SourceClass&gt; importSourceClasses = asSourceClasses(importClassNames);        processImports(configClass, currentSourceClass, importSourceClasses, false);    &#125;</code></pre><p>可以看到，将deferredImportSelectors置为null在这里发挥了作用，代码逻辑走进了else里。在else里不断地递归下去。</p><p>到这里，ConfigurationClassParser#parse已经分析完毕，重新回到ConfigurationClassPostProcessor#processConfigBeanDefinitions。</p><p>接下来，就是parser.validate()。这里主要是做一些校验工作，比如：</p><ul><li>@Configuration 注解的Bean不能被final关键字修饰</li><li>@Bean修饰的静态方法，不用校验，没有限制</li><li>@Configuration 注解的Bean里的@Bean方法必须是可重写的（不能被static、final、private 修饰)</li></ul><p>校验结束后，就开始加载beanDefinitions ：</p><pre><code class="java">        // Read the model and create bean definitions based on its content        if (this.reader == null) &#123;            this.reader = new ConfigurationClassBeanDefinitionReader(                    registry, this.sourceExtractor, this.resourceLoader, this.environment,                    this.importBeanNameGenerator, parser.getImportRegistry());        &#125;        this.reader.loadBeanDefinitions(configClasses);        alreadyParsed.addAll(configClasses);</code></pre><p>从loadBeanDefinitions进去，可以看到：</p><pre><code class="java">/**     * Read a particular &#123;@link ConfigurationClass&#125;, registering bean definitions     * for the class itself and all of its &#123;@link Bean&#125; methods.     */    private void loadBeanDefinitionsForConfigurationClass(            ConfigurationClass configClass, TrackedConditionEvaluator trackedConditionEvaluator) &#123;        if (trackedConditionEvaluator.shouldSkip(configClass)) &#123;            String beanName = configClass.getBeanName();            if (StringUtils.hasLength(beanName) &amp;&amp; this.registry.containsBeanDefinition(beanName)) &#123;                this.registry.removeBeanDefinition(beanName);            &#125;            this.importRegistry.removeImportingClass(configClass.getMetadata().getClassName());            return;        &#125;        if (configClass.isImported()) &#123;            registerBeanDefinitionForImportedConfigurationClass(configClass);        &#125;        for (BeanMethod beanMethod : configClass.getBeanMethods()) &#123;            loadBeanDefinitionsForBeanMethod(beanMethod);        &#125;        loadBeanDefinitionsFromImportedResources(configClass.getImportedResources());        loadBeanDefinitionsFromRegistrars(configClass.getImportBeanDefinitionRegistrars());    &#125;</code></pre><p>这里分为几种情况进行处理：1.import的；2.@Bean方法注入的；3.资源文件导入的(groovy、xml、properties)；4.通过ImportBeanDefinitionRegistrar导入的。</p><p>这几个情况都是注册了bean，但貌似都没有实例化。好吧，不细细展开了。另外，ImportBeanDefinitionRegistrar接口动态加载bean这个地方以后文章再展开，mark一下。</p><p>好了，回到ConfigurationClassPostProcessor#processConfigBeanDefinitions，看到最后跳出do…while…后，注册了一个单例ConfigurationClassPostProcessor.importRegistry,干啥用的不知道，以后会懂，mark!</p><p>最后还有个清理缓存的步骤，到这里第一个重要方法invokeBeanDefinitionRegistryPostProcessors，已经分析完毕。总体看，就是为了解析Configuration类的。</p><h4 id="重要方法2：invokeBeanFactoryPostProcessors"><a href="#重要方法2：invokeBeanFactoryPostProcessors" class="headerlink" title="重要方法2：invokeBeanFactoryPostProcessors"></a>重要方法2：invokeBeanFactoryPostProcessors</h4><p>先看方法入口：</p><pre><code class="java">/**     * Invoke the given BeanFactoryPostProcessor beans.     */    private static void invokeBeanFactoryPostProcessors(            Collection&lt;? extends BeanFactoryPostProcessor&gt; postProcessors, ConfigurableListableBeanFactory beanFactory) &#123;        for (BeanFactoryPostProcessor postProcessor : postProcessors) &#123;            postProcessor.postProcessBeanFactory(beanFactory);        &#125;    &#125;</code></pre><p>看到这个方法处理的是BeanFactoryPostProcessor的子类，对所有的postProcessors，都有调用postProcessBeanFactory方法。这里边会有好几个子类，部分子类的postProcessBeanFactory是空方法，这里主要看看ConfigurationClassPostProcessor类好了。</p><pre><code class="java">    /**     * Prepare the Configuration classes for servicing bean requests at runtime     * by replacing them with CGLIB-enhanced subclasses.     */    @Override    public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) &#123;        int factoryId = System.identityHashCode(beanFactory);        if (this.factoriesPostProcessed.contains(factoryId)) &#123;            throw new IllegalStateException(                    &quot;postProcessBeanFactory already called on this post-processor against &quot; + beanFactory);        &#125;        this.factoriesPostProcessed.add(factoryId);        if (!this.registriesPostProcessed.contains(factoryId)) &#123;            // BeanDefinitionRegistryPostProcessor hook apparently not supported...            // Simply call processConfigurationClasses lazily at this point then.            processConfigBeanDefinitions((BeanDefinitionRegistry) beanFactory);        &#125;        enhanceConfigurationClasses(beanFactory);        beanFactory.addBeanPostProcessor(new ImportAwareBeanPostProcessor(beanFactory));    &#125;</code></pre><p>一开始也是检查是否处理过这个processor，没处理过的话，进入processConfigBeanDefinitions方法，这里跟上边的postProcessBeanDefinitionRegistry是一模一样的，不展开说了。</p><p>处理完之后到了enhanceConfigurationClasses(beanFactory) 展开看看：</p><pre><code class="java">/**     * Post-processes a BeanFactory in search of Configuration class BeanDefinitions;     * any candidates are then enhanced by a &#123;@link ConfigurationClassEnhancer&#125;.     * Candidate status is determined by BeanDefinition attribute metadata.     * @see ConfigurationClassEnhancer     */    public void enhanceConfigurationClasses(ConfigurableListableBeanFactory beanFactory) &#123;        Map&lt;String, AbstractBeanDefinition&gt; configBeanDefs = new LinkedHashMap&lt;&gt;();        for (String beanName : beanFactory.getBeanDefinitionNames()) &#123;            BeanDefinition beanDef = beanFactory.getBeanDefinition(beanName);            if (ConfigurationClassUtils.isFullConfigurationClass(beanDef)) &#123;                if (!(beanDef instanceof AbstractBeanDefinition)) &#123;                    throw new BeanDefinitionStoreException(&quot;Cannot enhance @Configuration bean definition &#39;&quot; +                            beanName + &quot;&#39; since it is not stored in an AbstractBeanDefinition subclass&quot;);                &#125;                else if (logger.isWarnEnabled() &amp;&amp; beanFactory.containsSingleton(beanName)) &#123;                    logger.warn(&quot;Cannot enhance @Configuration bean definition &#39;&quot; + beanName +                            &quot;&#39; since its singleton instance has been created too early. The typical cause &quot; +                            &quot;is a non-static @Bean method with a BeanDefinitionRegistryPostProcessor &quot; +                            &quot;return type: Consider declaring such methods as &#39;static&#39;.&quot;);                &#125;                configBeanDefs.put(beanName, (AbstractBeanDefinition) beanDef);            &#125;        &#125;        if (configBeanDefs.isEmpty()) &#123;            // nothing to enhance -&gt; return immediately            return;        &#125;        ConfigurationClassEnhancer enhancer = new ConfigurationClassEnhancer();        for (Map.Entry&lt;String, AbstractBeanDefinition&gt; entry : configBeanDefs.entrySet()) &#123;            AbstractBeanDefinition beanDef = entry.getValue();            // If a @Configuration class gets proxied, always proxy the target class            beanDef.setAttribute(AutoProxyUtils.PRESERVE_TARGET_CLASS_ATTRIBUTE, Boolean.TRUE);            try &#123;                // Set enhanced subclass of the user-specified bean class                Class&lt;?&gt; configClass = beanDef.resolveBeanClass(this.beanClassLoader);                if (configClass != null) &#123;                    Class&lt;?&gt; enhancedClass = enhancer.enhance(configClass, this.beanClassLoader);                    if (configClass != enhancedClass) &#123;                        if (logger.isDebugEnabled()) &#123;                            logger.debug(String.format(&quot;Replacing bean definition &#39;%s&#39; existing class &#39;%s&#39; with &quot; +                                    &quot;enhanced class &#39;%s&#39;&quot;, entry.getKey(), configClass.getName(), enhancedClass.getName()));                        &#125;                        beanDef.setBeanClass(enhancedClass);                    &#125;                &#125;            &#125;            catch (Throwable ex) &#123;                throw new IllegalStateException(&quot;Cannot load configuration class: &quot; + beanDef.getBeanClassName(), ex);            &#125;        &#125;    &#125;</code></pre><p>看起来时用CGLIB技术对bean进行增强的，这是个知识点，以后文章展开，mark.</p><p>回来后，添加了一个BeanPostProcessor，为</p><pre><code class="java">beanFactory.addBeanPostProcessor(new ImportAwareBeanPostProcessor(beanFactory));</code></pre><p>好吧，第二个方法就这样结束，感觉越来越水了。</p><p>这两个重要方法是我们在PostProcessorRegistrationDelegate#invokeBeanFactoryPostProcessors中展开的，现在分析完毕，我们重新回到调用处继续分析。调用处为AbstractApplicationContext#invokeBeanFactoryPostProcessors。回顾下代码：</p><pre><code class="java">/**     * Instantiate and invoke all registered BeanFactoryPostProcessor beans,     * respecting explicit order if given.     * &lt;p&gt;Must be called before singleton instantiation.     */    protected void invokeBeanFactoryPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123;        PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(beanFactory, getBeanFactoryPostProcessors());        // Detect a LoadTimeWeaver and prepare for weaving, if found in the meantime        // (e.g. through an @Bean method registered by ConfigurationClassPostProcessor)        if (beanFactory.getTempClassLoader() == null &amp;&amp; beanFactory.containsBean(LOAD_TIME_WEAVER_BEAN_NAME)) &#123;            beanFactory.addBeanPostProcessor(new LoadTimeWeaverAwareProcessor(beanFactory));            beanFactory.setTempClassLoader(new ContextTypeMatchClassLoader(beanFactory.getBeanClassLoader()));        &#125;    &#125;</code></pre><p>这段代码已经在上文分析过了，继续回到上一层调用点。哦哦，已经回到了refresh方法。好的，invokeBeanFactoryPostProcessors过程分析结束。</p><h3 id="registerBeanPostProcessors"><a href="#registerBeanPostProcessors" class="headerlink" title="registerBeanPostProcessors"></a>registerBeanPostProcessors</h3><p>从注解看，这个方法是注册那些拦截bean创建过程的bean processors。进入方法：</p><pre><code class="java">/**     * Instantiate and invoke all registered BeanPostProcessor beans,     * respecting explicit order if given.     * &lt;p&gt;Must be called before any instantiation of application beans.     */    protected void registerBeanPostProcessors(ConfigurableListableBeanFactory beanFactory) &#123;        PostProcessorRegistrationDelegate.registerBeanPostProcessors(beanFactory, this);    &#125;</code></pre><p>注释说到，实例化并且调用所有被注册的beanPostProcessor类型bean，并按照指定的顺序。这个方法一定要在应用bean实例化之前被调用。</p><p>再次进入这个PostProcessorRegistrationDelegate类看看代码：</p><pre><code class="java">public static void registerBeanPostProcessors(            ConfigurableListableBeanFactory beanFactory, AbstractApplicationContext applicationContext) &#123;        String[] postProcessorNames = beanFactory.getBeanNamesForType(BeanPostProcessor.class, true, false);        // Register BeanPostProcessorChecker that logs an info message when        // a bean is created during BeanPostProcessor instantiation, i.e. when        // a bean is not eligible for getting processed by all BeanPostProcessors.        int beanProcessorTargetCount = beanFactory.getBeanPostProcessorCount() + 1 + postProcessorNames.length;        beanFactory.addBeanPostProcessor(new BeanPostProcessorChecker(beanFactory, beanProcessorTargetCount));        // Separate between BeanPostProcessors that implement PriorityOrdered,        // Ordered, and the rest.        List&lt;BeanPostProcessor&gt; priorityOrderedPostProcessors = new ArrayList&lt;&gt;();        List&lt;BeanPostProcessor&gt; internalPostProcessors = new ArrayList&lt;&gt;();        List&lt;String&gt; orderedPostProcessorNames = new ArrayList&lt;&gt;();        List&lt;String&gt; nonOrderedPostProcessorNames = new ArrayList&lt;&gt;();        for (String ppName : postProcessorNames) &#123;            if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123;                BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);                priorityOrderedPostProcessors.add(pp);                if (pp instanceof MergedBeanDefinitionPostProcessor) &#123;                    internalPostProcessors.add(pp);                &#125;            &#125;            else if (beanFactory.isTypeMatch(ppName, Ordered.class)) &#123;                orderedPostProcessorNames.add(ppName);            &#125;            else &#123;                nonOrderedPostProcessorNames.add(ppName);            &#125;        &#125;        // First, register the BeanPostProcessors that implement PriorityOrdered.        sortPostProcessors(priorityOrderedPostProcessors, beanFactory);        registerBeanPostProcessors(beanFactory, priorityOrderedPostProcessors);        // Next, register the BeanPostProcessors that implement Ordered.        List&lt;BeanPostProcessor&gt; orderedPostProcessors = new ArrayList&lt;&gt;();        for (String ppName : orderedPostProcessorNames) &#123;            BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);            orderedPostProcessors.add(pp);            if (pp instanceof MergedBeanDefinitionPostProcessor) &#123;                internalPostProcessors.add(pp);            &#125;        &#125;        sortPostProcessors(orderedPostProcessors, beanFactory);        registerBeanPostProcessors(beanFactory, orderedPostProcessors);        // Now, register all regular BeanPostProcessors.        List&lt;BeanPostProcessor&gt; nonOrderedPostProcessors = new ArrayList&lt;&gt;();        for (String ppName : nonOrderedPostProcessorNames) &#123;            BeanPostProcessor pp = beanFactory.getBean(ppName, BeanPostProcessor.class);            nonOrderedPostProcessors.add(pp);            if (pp instanceof MergedBeanDefinitionPostProcessor) &#123;                internalPostProcessors.add(pp);            &#125;        &#125;        registerBeanPostProcessors(beanFactory, nonOrderedPostProcessors);        // Finally, re-register all internal BeanPostProcessors.        sortPostProcessors(internalPostProcessors, beanFactory);        registerBeanPostProcessors(beanFactory, internalPostProcessors);        // Re-register post-processor for detecting inner beans as ApplicationListeners,        // moving it to the end of the processor chain (for picking up proxies etc).        beanFactory.addBeanPostProcessor(new ApplicationListenerDetector(applicationContext));    &#125;</code></pre><p>这个方法主要做的事情有几件：</p><ul><li>捞出所有的实现了BeanPostProcessor接口的Bean，然后注册一个新的BeanPostProcessorChecker，也是实现了BeanPostProcessor接口的实例</li><li>然后将BeanPostProcessor分为四类，分别是priorityOrderedPostProcessors、orderedPostProcessorNames、nonOrderedPostProcessorNames以及internalPostProcessors。需要排序的就排序，最后都是调用registerBeanPostProcessors进行注册</li><li>最后再注册一个ApplicationListenerDetector，实现了MergedBeanDefinitionPostProcessor接口</li></ul><p>然后所谓的注册环节，其实只是在beanFactory里做简单的add操作。</p><pre><code class="java">@Override    public void addBeanPostProcessor(BeanPostProcessor beanPostProcessor) &#123;        Assert.notNull(beanPostProcessor, &quot;BeanPostProcessor must not be null&quot;);        this.beanPostProcessors.remove(beanPostProcessor);        this.beanPostProcessors.add(beanPostProcessor);        if (beanPostProcessor instanceof InstantiationAwareBeanPostProcessor) &#123;            this.hasInstantiationAwareBeanPostProcessors = true;        &#125;        if (beanPostProcessor instanceof DestructionAwareBeanPostProcessor) &#123;            this.hasDestructionAwareBeanPostProcessors = true;        &#125;    &#125;</code></pre><h3 id="initMessageSource"><a href="#initMessageSource" class="headerlink" title="initMessageSource"></a>initMessageSource</h3><p>MessageSource是spring提供的一个接口，以用于支持信息的国际化和包含参数的信息的替换。国际化也是一个知识拓展点，Mark之。先简单看看：</p><pre><code class="java">/**     * Initialize the MessageSource.     * Use parent&#39;s if none defined in this context.     */    protected void initMessageSource() &#123;        ConfigurableListableBeanFactory beanFactory = getBeanFactory();        if (beanFactory.containsLocalBean(MESSAGE_SOURCE_BEAN_NAME)) &#123;            this.messageSource = beanFactory.getBean(MESSAGE_SOURCE_BEAN_NAME, MessageSource.class);            // Make MessageSource aware of parent MessageSource.            if (this.parent != null &amp;&amp; this.messageSource instanceof HierarchicalMessageSource) &#123;                HierarchicalMessageSource hms = (HierarchicalMessageSource) this.messageSource;                if (hms.getParentMessageSource() == null) &#123;                    // Only set parent context as parent MessageSource if no parent MessageSource                    // registered already.                    hms.setParentMessageSource(getInternalParentMessageSource());                &#125;            &#125;            if (logger.isDebugEnabled()) &#123;                logger.debug(&quot;Using MessageSource [&quot; + this.messageSource + &quot;]&quot;);            &#125;        &#125;        else &#123;            // Use empty MessageSource to be able to accept getMessage calls.            DelegatingMessageSource dms = new DelegatingMessageSource();            dms.setParentMessageSource(getInternalParentMessageSource());            this.messageSource = dms;            beanFactory.registerSingleton(MESSAGE_SOURCE_BEAN_NAME, this.messageSource);            if (logger.isDebugEnabled()) &#123;                logger.debug(&quot;Unable to locate MessageSource with name &#39;&quot; + MESSAGE_SOURCE_BEAN_NAME +                        &quot;&#39;: using default [&quot; + this.messageSource + &quot;]&quot;);            &#125;        &#125;    &#125;</code></pre><p>initMessageSource 主要做的事情是：</p><ul><li>先去beanFactory看有没有注册一个名为messageSource的bean，如果存在，取出这个bean作为上下文的this.messageSource。</li><li>如果这是一个HierarchicalMessageSource，则会在父容器存在的情况下取父容器对应的messageSource作为当前messageSource的parentMessageSource</li><li>如果当前bean容器中不存在beanName为messageSource的bean，则会生成一个DelegatingMessageSource来作为当前的MessageSource。DelegatingMessageSource基本算是对MessageSource的一个空的实现，在对应父容器的messageSource存在时就使用父容器的messageSource处理，否则就不处理，具体可以参考Spring的API文档或查看DelegatingMessageSource的源码。</li></ul><p>国际化的更多内容，以后通过文章拓展，mark。可参考<a href="http://elim.iteye.com/blog/2392583">国际化MessageSource</a></p><h3 id="initApplicationEventMulticaster"><a href="#initApplicationEventMulticaster" class="headerlink" title="initApplicationEventMulticaster"></a>initApplicationEventMulticaster</h3><p>初始化事件广播器，跟上一步类似，去beanfactory里看有没有名叫applicationEventMulticaster的bean。如果存在，取出它作为上下文的事件广播器。如果不存在，则新建一个SimpleApplicationEventMulticaster作为上下文事件广播器。</p><pre><code class="java">/**     * Initialize the ApplicationEventMulticaster.     * Uses SimpleApplicationEventMulticaster if none defined in the context.     * @see org.springframework.context.event.SimpleApplicationEventMulticaster     */    protected void initApplicationEventMulticaster() &#123;        ConfigurableListableBeanFactory beanFactory = getBeanFactory();        if (beanFactory.containsLocalBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME)) &#123;            this.applicationEventMulticaster =                    beanFactory.getBean(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, ApplicationEventMulticaster.class);            if (logger.isDebugEnabled()) &#123;                logger.debug(&quot;Using ApplicationEventMulticaster [&quot; + this.applicationEventMulticaster + &quot;]&quot;);            &#125;        &#125;        else &#123;            this.applicationEventMulticaster = new SimpleApplicationEventMulticaster(beanFactory);            beanFactory.registerSingleton(APPLICATION_EVENT_MULTICASTER_BEAN_NAME, this.applicationEventMulticaster);            if (logger.isDebugEnabled()) &#123;                logger.debug(&quot;Unable to locate ApplicationEventMulticaster with name &#39;&quot; +                        APPLICATION_EVENT_MULTICASTER_BEAN_NAME +                        &quot;&#39;: using default [&quot; + this.applicationEventMulticaster + &quot;]&quot;);            &#125;        &#125;    &#125;</code></pre><p>参考<a href="https://blog.csdn.net/caihaijiang/article/details/7460888">Spring事件体系</a></p><h3 id="onRefresh"><a href="#onRefresh" class="headerlink" title="onRefresh"></a>onRefresh</h3><p>onRefresh的实现在类中，代码如下：</p><pre><code class="java">@Override    protected void onRefresh() &#123;        super.onRefresh();        try &#123;            createWebServer();        &#125;        catch (Throwable ex) &#123;            throw new ApplicationContextException(&quot;Unable to start web server&quot;, ex);        &#125;    &#125;</code></pre><p>第一句的super.onRefresh()先调用父类的方法，主要是做了一个初始化主题的动作,spring主题用的比较少，这里不展开，mark ：</p><pre><code class="java">@Override    protected void onRefresh() &#123;        this.themeSource = UiApplicationContextUtils.initThemeSource(this);    &#125;</code></pre><p>第二步做的是初始化Servlet容器的动作，支持3种内置的Servlet容器：Tomcat、Jetty、Undertow。这里初始化的是Tomcat类型的容器</p><pre><code class="java">private void createWebServer() &#123;        WebServer webServer = this.webServer;        ServletContext servletContext = getServletContext();        if (webServer == null &amp;&amp; servletContext == null) &#123;            ServletWebServerFactory factory = getWebServerFactory();            this.webServer = factory.getWebServer(getSelfInitializer());        &#125;        else if (servletContext != null) &#123;            try &#123;                getSelfInitializer().onStartup(servletContext);            &#125;            catch (ServletException ex) &#123;                throw new ApplicationContextException(&quot;Cannot initialize servlet context&quot;,                        ex);            &#125;        &#125;        initPropertySources();    &#125;</code></pre><h3 id="registerListeners"><a href="#registerListeners" class="headerlink" title="registerListeners"></a>registerListeners</h3><p>顾名思义，这个方法是用于注册监听器的，这里将之前上下文里的ApplicationListners全部注册到了事件广播器里，同时也取beanfactory里获取所有实现了ApplicationListener接口的bean的名字，添加到事件广播器里，但并没有初始化这些bean。注释说到，是为了等待post-processors应用他们，不是很懂，mark。然后广播多个early application events。</p><pre><code class="java">/**     * Add beans that implement ApplicationListener as listeners.     * Doesn&#39;t affect other listeners, which can be added without being beans.     */    protected void registerListeners() &#123;        // Register statically specified listeners first.        for (ApplicationListener&lt;?&gt; listener : getApplicationListeners()) &#123;            getApplicationEventMulticaster().addApplicationListener(listener);        &#125;        // Do not initialize FactoryBeans here: We need to leave all regular beans        // uninitialized to let post-processors apply to them!        String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false);        for (String listenerBeanName : listenerBeanNames) &#123;            getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName);        &#125;        // Publish early application events now that we finally have a multicaster...        Set&lt;ApplicationEvent&gt; earlyEventsToProcess = this.earlyApplicationEvents;        this.earlyApplicationEvents = null;        if (earlyEventsToProcess != null) &#123;            for (ApplicationEvent earlyEvent : earlyEventsToProcess) &#123;                getApplicationEventMulticaster().multicastEvent(earlyEvent);            &#125;        &#125;    &#125;</code></pre><h3 id="finishBeanFactoryInitialization"><a href="#finishBeanFactoryInitialization" class="headerlink" title="finishBeanFactoryInitialization"></a>finishBeanFactoryInitialization</h3><p>完成上下文beanFactory的初始化，初始化所有剩余的单例bean。</p><pre><code class="java">/**     * Finish the initialization of this context&#39;s bean factory,     * initializing all remaining singleton beans.     */    protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123;        // Initialize conversion service for this context.        if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp;                beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123;            beanFactory.setConversionService(                    beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class));        &#125;        // Register a default embedded value resolver if no bean post-processor        // (such as a PropertyPlaceholderConfigurer bean) registered any before:        // at this point, primarily for resolution in annotation attribute values.        if (!beanFactory.hasEmbeddedValueResolver()) &#123;            beanFactory.addEmbeddedValueResolver(strVal -&gt; getEnvironment().resolvePlaceholders(strVal));        &#125;        // Initialize LoadTimeWeaverAware beans early to allow for registering their transformers early.        String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false);        for (String weaverAwareName : weaverAwareNames) &#123;            getBean(weaverAwareName);        &#125;        // Stop using the temporary ClassLoader for type matching.        beanFactory.setTempClassLoader(null);        // Allow for caching all bean definition metadata, not expecting further changes.        beanFactory.freezeConfiguration();        // Instantiate all remaining (non-lazy-init) singletons.        beanFactory.preInstantiateSingletons();    &#125;</code></pre><ul><li>先查看beanFactory是否包含名为conversionService的bean，如果存在捞出来设置到beanFactory里。ConversionService是用于做类型转换的，拓展点 mark。</li><li>其他几步不知道干嘛的，先不管。</li><li>beanFactory.preInstantiateSingletons()开始实例化所有剩余的单例bean.</li></ul><p>对preInstantiateSingletons展开：</p><pre><code class="java">@Override    public void preInstantiateSingletons() throws BeansException &#123;        if (this.logger.isDebugEnabled()) &#123;            this.logger.debug(&quot;Pre-instantiating singletons in &quot; + this);        &#125;        // Iterate over a copy to allow for init methods which in turn register new bean definitions.        // While this may not be part of the regular factory bootstrap, it does otherwise work fine.        List&lt;String&gt; beanNames = new ArrayList&lt;&gt;(this.beanDefinitionNames);        // Trigger initialization of all non-lazy singleton beans...        for (String beanName : beanNames) &#123;            RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName);            if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123;                if (isFactoryBean(beanName)) &#123;                    Object bean = getBean(FACTORY_BEAN_PREFIX + beanName);                    if (bean instanceof FactoryBean) &#123;                        final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) bean;                        boolean isEagerInit;                        if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123;                            isEagerInit = AccessController.doPrivileged((PrivilegedAction&lt;Boolean&gt;)                                            ((SmartFactoryBean&lt;?&gt;) factory)::isEagerInit,                                    getAccessControlContext());                        &#125;                        else &#123;                            isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp;                                    ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit());                        &#125;                        if (isEagerInit) &#123;                            getBean(beanName);                        &#125;                    &#125;                &#125;                else &#123;                    getBean(beanName);                &#125;            &#125;        &#125;        // Trigger post-initialization callback for all applicable beans...        for (String beanName : beanNames) &#123;            Object singletonInstance = getSingleton(beanName);            if (singletonInstance instanceof SmartInitializingSingleton) &#123;                final SmartInitializingSingleton smartSingleton = (SmartInitializingSingleton) singletonInstance;                if (System.getSecurityManager() != null) &#123;                    AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; &#123;                        smartSingleton.afterSingletonsInstantiated();                        return null;                    &#125;, getAccessControlContext());                &#125;                else &#123;                    smartSingleton.afterSingletonsInstantiated();                &#125;            &#125;        &#125;    &#125;</code></pre><p>方法一开始捞出全部的beanNames,对于这些bean需要满足三个条件才能进行初始化：不是抽象类、单例、非懒加载。然后接着首先判断一下Bean是否FactoryBean的实现，接着判断Bean是否SmartFactoryBean的实现。这部分是Java开发基本用不到，不作展开。下边着重看下getBean方法，getBean方法最终调用的是DefaultListableBeanFactory的父类AbstractBeanFactory类的doGetBean方法，这个方法比较长，慢慢分析:</p><pre><code class="java">protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType,            @Nullable final Object[] args, boolean typeCheckOnly) </code></pre><p>先看方法定义：<br><strong>name</strong> 需要获取的bean名字<br><strong>requiredType</strong> 要检索的bean所需的类型<br><strong>args</strong> 使用显式参数创建bean 实例 时使用的参数（仅在创建新实例时应用，而不是在检索现有实例时应用）<br><strong>typeCheckOnly</strong> 是否为了类型检查而获取实例，而不是实际使用</p><pre><code class="java">// Eagerly check singleton cache for manually registered singletons.Object sharedInstance = getSingleton(beanName);if (sharedInstance != null &amp;&amp; args == null) &#123;    if (logger.isDebugEnabled()) &#123;        if (isSingletonCurrentlyInCreation(beanName)) &#123;            logger.debug(&quot;Returning eagerly cached instance of singleton bean &#39;&quot; + beanName +                    &quot;&#39; that is not fully initialized yet - a consequence of a circular reference&quot;);        &#125;        else &#123;            logger.debug(&quot;Returning cached instance of singleton bean &#39;&quot; + beanName + &quot;&#39;&quot;);        &#125;    &#125;    bean = getObjectForBeanInstance(sharedInstance, name, beanName, null);&#125;</code></pre><p>getSingleton(beanName)，一开始先通过这个方法检查是否已经手动注册过这个bean,然后进入了getObjectForBeanInstance方法里，在里边会判断这个bean是一个普通的bean还是一个FactoryBean。如果是普通bean,直接返回，但如果是FactoryBean的话，情况比较复杂，跳过之。</p><pre><code class="java">if (isPrototypeCurrentlyInCreation(beanName)) &#123;    throw new BeanCurrentlyInCreationException(beanName);&#125;</code></pre><p>但如果之前没有注册过这个bean，先检查这个bean是不是正在创建中（isPrototypeCurrentlyInCreation），如果是的话，直接抛异常BeanCurrentlyInCreationException。</p><pre><code class="java">// Check if bean definition exists in this factory.BeanFactory parentBeanFactory = getParentBeanFactory();if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123;    // Not found -&gt; check parent.    String nameToLookup = originalBeanName(name);    if (parentBeanFactory instanceof AbstractBeanFactory) &#123;        return ((AbstractBeanFactory) parentBeanFactory).doGetBean(                nameToLookup, requiredType, args, typeCheckOnly);    &#125;    else if (args != null) &#123;        // Delegation to parent with explicit args.        return (T) parentBeanFactory.getBean(nameToLookup, args);    &#125;    else &#123;        // No args -&gt; delegate to standard getBean method.        return parentBeanFactory.getBean(nameToLookup, requiredType);    &#125;&#125;</code></pre><p>再检查父类的BeanFactory是否有注册过这个bean，尝试获取并且返回。</p><pre><code class="java">if (!typeCheckOnly) &#123;    markBeanAsCreated(beanName);&#125;</code></pre><p>如果不仅仅是作类型检查的话，标记这个bean已经创建。</p><pre><code class="java">final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);checkMergedBeanDefinition(mbd, beanName, args);// Guarantee initialization of beans that the current bean depends on.String[] dependsOn = mbd.getDependsOn();if (dependsOn != null) &#123;    for (String dep : dependsOn) &#123;        if (isDependent(beanName, dep)) &#123;            throw new BeanCreationException(mbd.getResourceDescription(), beanName,                    &quot;Circular depends-on relationship between &#39;&quot; + beanName + &quot;&#39; and &#39;&quot; + dep + &quot;&#39;&quot;);        &#125;        registerDependentBean(dep, beanName);        try &#123;            getBean(dep);        &#125;        catch (NoSuchBeanDefinitionException ex) &#123;            throw new BeanCreationException(mbd.getResourceDescription(), beanName,                    &quot;&#39;&quot; + beanName + &quot;&#39; depends on missing bean &#39;&quot; + dep + &quot;&#39;&quot;, ex);        &#125;    &#125;&#125;</code></pre><p>这里检查这个bean依赖的其他bean，然后递归进去getBean。这里的循环依赖检测看着像是写反了，有点疑惑暂时不深究 mark。</p><pre><code class="java">// Create bean instance.if (mbd.isSingleton()) &#123;    sharedInstance = getSingleton(beanName, () -&gt; &#123;        try &#123;            return createBean(beanName, mbd, args);        &#125;        catch (BeansException ex) &#123;            // Explicitly remove instance from singleton cache: It might have been put there            // eagerly by the creation process, to allow for circular reference resolution.            // Also remove any beans that received a temporary reference to the bean.            destroySingleton(beanName);            throw ex;        &#125;    &#125;);    bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);&#125;</code></pre><p>单例创建bean，getSingleton方法里会回调getObject()方法，其实就是调用createBean(beanName, mbd, args)方法。<br>createBean往下太底层了，对普通开发者没多大影响，不分析下去了。</p><pre><code class="java">if (mbd.isPrototype()) &#123;    // It&#39;s a prototype -&gt; create a new instance.    Object prototypeInstance = null;    try &#123;        beforePrototypeCreation(beanName);        prototypeInstance = createBean(beanName, mbd, args);    &#125;    finally &#123;        afterPrototypeCreation(beanName);    &#125;    bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd);&#125;else &#123;    String scopeName = mbd.getScope();    final Scope scope = this.scopes.get(scopeName);    if (scope == null) &#123;        throw new IllegalStateException(&quot;No Scope registered for scope name &#39;&quot; + scopeName + &quot;&#39;&quot;);    &#125;    try &#123;        Object scopedInstance = scope.get(beanName, () -&gt; &#123;            beforePrototypeCreation(beanName);            try &#123;                return createBean(beanName, mbd, args);            &#125;            finally &#123;                afterPrototypeCreation(beanName);            &#125;        &#125;);        bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd);    &#125;    catch (IllegalStateException ex) &#123;        throw new BeanCreationException(beanName,                &quot;Scope &#39;&quot; + scopeName + &quot;&#39; is not active for the current thread; consider &quot; +                &quot;defining a scoped proxy for this bean if you intend to refer to it from a singleton&quot;,                ex);    &#125;&#125;</code></pre><p>接着处理Prototype类型以及其他类型，过程都差不多，最后都是调用了createBean(beanName, mbd, args)。</p><h3 id="finishRefresh"><a href="#finishRefresh" class="headerlink" title="finishRefresh"></a>finishRefresh</h3><p>最后一步主要是清理缓存、刷新生命周期处理器、发布ContextRefreshedEvent事件等。</p><p><strong>总结：启动过程粗略地浏览了一遍，感觉只掌握了两三成，还需要继续深入研究。</strong></p>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 源码分析 </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 线程池详解</title>
      <link href="/2017/08/10/Java-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%AF%A6%E8%A7%A3/"/>
      <url>/2017/08/10/Java-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h2 id="Java-线程池"><a href="#Java-线程池" class="headerlink" title="Java 线程池"></a>Java 线程池</h2><p>Java 线程池模型的关键几个类和接口包括：Executor，Executors，ExecutorService，ThreadPoolExecutor，Future，Callable </p><span id="more"></span><h3 id="ExecutorService-接口"><a href="#ExecutorService-接口" class="headerlink" title="ExecutorService 接口"></a>ExecutorService 接口</h3><p>&emsp;&emsp; 所有的线程池实现类都继承于ExecutorService  接口，包括ThreadPoolExecutor。在使用线程池的时候，其实也是通过这个接口动态绑定各个线程池实例进行调用，常用的接口方法包括：</p><pre><code>void execute(Runnable command);&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);void shutdown();boolean awaitTermination(long timeout, TimeUnit unit)</code></pre><h3 id="ThreadPoolExecutor"><a href="#ThreadPoolExecutor" class="headerlink" title="ThreadPoolExecutor"></a>ThreadPoolExecutor</h3><p>这个类是各种线程池类的<em>爸爸</em>或<em>干爹</em>,所有的常见的线程池类都是从他派生出来。怎么派生的呢？我们来看下他的构造方法：</p><pre><code class="java">public ThreadPoolExecutor(int corePoolSize,                              int maximumPoolSize,                              long keepAliveTime,                              TimeUnit unit,                              BlockingQueue&lt;Runnable&gt; workQueue)</code></pre><p>这里我们只看这个五个参数的构造方法（还有个6参数方法）：</p><p><strong>corePoolSize</strong> 核心线程数量，包含空闲线程<br><strong>maximumPoolSize</strong> 最大线程数量<br><strong>keepAliveTime</strong> 空闲的线程存活时间<br><strong>unit</strong>  时间单位<br><strong>workQueue</strong> 线程缓存队列，仅保存 execute方法提交的线程</p><p>详细的含义直接摘抄别人的总结：根据 ThreadPoolExecutor 源码前面大段的注释，我们可以看出，当试图通过 excute 方法讲一个 Runnable 任务添加到线程池中时，按照如下顺序来处理：</p><p>如果线程池中的线程数量少于 corePoolSize，即使线程池中有空闲线程，也会创建一个新的线程来执行新添加的任务；</p><p>如果线程池中的线程数量大于等于 corePoolSize，但缓冲队列 workQueue 未满，则将新添加的任务放到 workQueue 中，按照 FIFO 的原则依次等待执行（线程池中有线程空闲出来后依次将缓冲队列中的任务交付给空闲的线程执行）；</p><p>如果线程池中的线程数量大于等于 corePoolSize，且缓冲队列 workQueue 已满，但线程池中的线程数量小于 maximumPoolSize，则会创建新的线程来处理被添加的任务；</p><p>如果线程池中的线程数量等于了 maximumPoolSize，有 4 种才处理方式（该构造方法调用了含有 6 个参数的构造方法，并将最后一个构造方法为 RejectedExecutionHandler 类型，它在处理线程溢出时有 4 种方式，这里不再细说，要了解的，自己可以阅读下源码）。</p><p><strong>总结起来，也即是说，当有新的任务要处理时，先看线程池中的线程数量是否大于 corePoolSize，再看缓冲队列 workQueue 是否满，最后看线程池中的线程数量是否大于 maximumPoolSize。</strong></p><h3 id="Executors"><a href="#Executors" class="headerlink" title="Executors"></a>Executors</h3><p>Executors是一个工厂类，里边给我们提供了几个线程池的工厂方法，例如：</p><pre><code class="java">public static ExecutorService newCachedThreadPool() &#123;        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,                                      60L, TimeUnit.SECONDS,                                      new SynchronousQueue&lt;Runnable&gt;());&#125;public static ExecutorService newFixedThreadPool(int nThreads) &#123;        return new ThreadPoolExecutor(nThreads, nThreads,                                      0L, TimeUnit.MILLISECONDS,                                      new LinkedBlockingQueue&lt;Runnable&gt;());&#125;    public static ExecutorService newSingleThreadExecutor() &#123;        return new FinalizableDelegatedExecutorService            (new ThreadPoolExecutor(1, 1,                                    0L, TimeUnit.MILLISECONDS,                                    new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123;        return new ScheduledThreadPoolExecutor(corePoolSize);&#125;.........以下略掉N个方法.........</code></pre><h4 id="Executors-newCachedThreadPool"><a href="#Executors-newCachedThreadPool" class="headerlink" title="Executors.newCachedThreadPool"></a>Executors.newCachedThreadPool</h4><p>立马看下这个方法的调用的是哪个构造函数：</p><pre><code class="java">new ThreadPoolExecutor(0, Integer.MAX_VALUE,                                      60L, TimeUnit.SECONDS,                                      new SynchronousQueue&lt;Runnable&gt;());</code></pre><p>可以看到，核心线程数为0，空闲线程存活时长是60s，就是说一旦某个线程空闲下来超过60秒，他就会从池中拿掉。另外SynchronousQueue 是一个不缓存元素的队列，一旦有Runnable 通过execute提交进来，他立即传递给线程池去寻找空闲线程去执行，如果没有空闲线程，则新建一个。</p><p>像下边这段测试代码，因为每隔21秒才提交一个sleep20 秒的runnable，所以，线程池中的唯一个线程不断地被得到复用。</p><pre><code class="java">public class ExecutorTest &#123;    private static ExecutorService service;    static class SleepTask extends Thread &#123;        @Override        public void run() &#123;            try &#123;                Thread.sleep(20000);            &#125; catch (InterruptedException e) &#123;                            &#125;            System.out.println(Thread.currentThread().getName() + &quot; sleep 20 s &quot;);        &#125;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        service = Executors.newCachedThreadPool();        for (int i = 0; i &lt; 10; i++) &#123;            service.execute(new SleepTask());            Thread.sleep(21000);        &#125;         // 这里要使得主线程等待线程池结束        service.shutdown();        while (!service.awaitTermination(10, TimeUnit.SECONDS)) ;    &#125;&#125;输出：pool-1-thread-1 sleep 20 s pool-1-thread-1 sleep 20 s pool-1-thread-1 sleep 20 s pool-1-thread-1 sleep 20 s pool-1-thread-1 sleep 20 s pool-1-thread-1 sleep 20 s (以下略)</code></pre><h4 id="Executors-newFixedThreadPool"><a href="#Executors-newFixedThreadPool" class="headerlink" title="Executors.newFixedThreadPool"></a>Executors.newFixedThreadPool</h4><p>先看调用的构造方法：</p><pre><code class="java">public static ExecutorService newFixedThreadPool(int nThreads) &#123;        return new ThreadPoolExecutor(nThreads, nThreads,                                      0L, TimeUnit.MILLISECONDS,                                      new LinkedBlockingQueue&lt;Runnable&gt;());&#125;</code></pre><p>构造方法参数是，corePoolSize &#x3D;&#x3D; maximumPoolSize &#x3D;&#x3D; nThreads，线程空闲时长为0s，队列为无界(Integer.MAX)的先进先出阻塞队列。</p><p>这个意思就是，线程不会被复用，execute提交一个runnable，就新建一个线程去执行他，线程用完就销毁。当线程数量大于 corePoolSize ，就放到队列里缓存起来，知道有空闲的位置让出来。</p><h4 id="Executors-newSingleThreadExecutor"><a href="#Executors-newSingleThreadExecutor" class="headerlink" title="Executors.newSingleThreadExecutor"></a>Executors.newSingleThreadExecutor</h4><p>线程池空间为1，没有空闲时间。这个很简单，略过。跟newFixedThreadPool(1)类似。</p><pre><code class="java">  public static ExecutorService newSingleThreadExecutor() &#123;        return new FinalizableDelegatedExecutorService            (new ThreadPoolExecutor(1, 1,                                    0L, TimeUnit.MILLISECONDS,                                    new LinkedBlockingQueue&lt;Runnable&gt;()));    &#125; </code></pre><h4 id="Executors-newScheduledThreadPool"><a href="#Executors-newScheduledThreadPool" class="headerlink" title="Executors.newScheduledThreadPool"></a>Executors.newScheduledThreadPool</h4><p>这个线程池的使用姿势跟上边略有不同，先看构造方法调用：</p><pre><code class="java">public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123;        return new ScheduledThreadPoolExecutor(corePoolSize);&#125; //最终调用了这个方法：public ScheduledThreadPoolExecutor(int corePoolSize) &#123;        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,              new DelayedWorkQueue());&#125;</code></pre><p>可以看到，corePoolSize可以指定，maximumPoolSize 无穷大，空闲时间为0，队列使用的支持延时获取元素的无界阻塞队列。在调用的时候，需要使用ScheduledExecutorService 这个接口来动态绑定，才能发挥真正的作用。<br>比如 :<br><strong>scheduleAtFixedRate</strong> 这个方法，允许command 第一次延迟 initialDelay个时间单位才开始执行，第二次延迟initialDelay+period 个时间单位才开始，第三次延迟到initialDelay+period*2 个时间单位才开始。每次增加period 个时间单位。但不允许并发，前一个执行没结束，后继的执行会被推迟。见范例。测试结果表明，每隔5s 左右才会执行一次。</p><pre><code class="java">public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command,                                                  long initialDelay,                                                  long period,                                                  TimeUnit unit);</code></pre><p><strong>scheduleWithFixedDelay</strong> 这个方法，允许command第一次延迟 initialDelay个时间单位才开始执行，后继的每一次都要在前一次结束后，延迟period个时间单位才开始执行。将范例里的注释行去掉，测试结果符合该描述。</p><p>范例：</p><pre><code class="java">public class ExecutorTest &#123;    private static ScheduledExecutorService service;    static class SleepTask extends Thread &#123;        @Override        public void run() &#123;            System.out.println(Thread.currentThread().getName() + &quot; start &quot;);            try &#123;                Thread.sleep(5000);            &#125; catch (InterruptedException e) &#123;            &#125;            System.out.println(Thread.currentThread().getName() + &quot; finished &quot;);        &#125;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        service = Executors.newScheduledThreadPool(5);        service.scheduleAtFixedRate(new SleepTask(), 1, 1, TimeUnit.SECONDS);       // service.scheduleWithFixedDelay(new SleepTask(),1,1,TimeUnit.SECONDS);    &#125;&#125;&#125;</code></pre><h3 id="Callable-Future"><a href="#Callable-Future" class="headerlink" title="Callable  &amp;&amp; Future"></a>Callable  &amp;&amp; Future</h3><p>&emsp;&emsp;上面都是在讨论用线程池执行Runnable对象，还有另外一个实现了 Callable 接口的对象。实现了 Callable 接口的对象会有返回值，但是Runnable对象返回值为null。并且 Callable 的 call()方法只能通过 ExecutorService 的 submit(Callable task) 方法来执行，并且返回一个 Future，是表示任务等待完成的 Future。<br>&emsp;&emsp;当将一个 Callable 的对象传递给 ExecutorService 的 submit 方法，则该 call 方法自动在一个线程上执行，并且会返回执行结果 Future 对象。同样，将 Runnable 的对象传递给 ExecutorService 的 submit 方法，则该 run 方法自动在一个线程上执行，并且会返回执行结果 Future 对象，但是在该 Future 对象上调用 get 方法，将返回 null。<br>&emsp;&emsp;上范例：</p><pre><code class="java">public class ExecutorTest &#123;    private static ExecutorService service;    static class SleepTask implements Callable&lt;String&gt; &#123;        @Override        public String call() throws Exception &#123;            return Thread.currentThread().getName()+&quot; is finished.&quot;;        &#125;    &#125;    public static void main(String[] args) throws InterruptedException, ExecutionException &#123;        service = Executors.newCachedThreadPool();        Future&lt;String&gt; future = service.submit(new SleepTask());        System.out.println(future.get());    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线程池 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM性能监控工具总结</title>
      <link href="/2017/06/18/JVM%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E6%80%BB%E7%BB%93/"/>
      <url>/2017/06/18/JVM%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<p>最近在温故《深入理解Java虚拟机》,对第四章的工具进行笔记记录，备忘。</p><span id="more"></span><h3 id="jps"><a href="#jps" class="headerlink" title="jps"></a><strong>jps</strong></h3><p>用来查看正在运行的虚拟机进程，功能单一但高频的小工具。使用如下：</p><pre><code class="bash">hadoop@hzbxs-bigdata16:~$ jps40759 AzkabanWebServer41031 AzkabanExecutorServer11860 Jps</code></pre><p> 第一列是LVMID(Local Virtual Machine Identifier)，本地虚拟机进程的LVMID就是操作系统的进程ID；第二列是进程启动的主类。<br> jps的常用选项有：</p><table><thead><tr><th align="left">选项</th><th align="left">用途</th></tr></thead><tbody><tr><td align="left">-m</td><td align="left">输出虚拟机进程启动时传递给主类main()函数的参数</td></tr><tr><td align="left">-v</td><td align="left">输出虚拟机进程启动时JVM参数</td></tr></tbody></table><h3 id="jstat"><a href="#jstat" class="headerlink" title="jstat"></a><strong>jstat</strong></h3><p> 用来在虚拟机运行中监视各种运行状态信息，是运行期定位虚拟机性能问题的首选工具。格式如下：  jstat -<option>  <vmid> [<interval> [<count>]]<br> option是选项；vmid 对本地进程来说跟LVMID一样；interval 是查询间隔；count是查询次数。</p><p>下边是使用范例，jstat -gc  40759 2000 5 ，表示查询进程40759的Java堆情况，查询5次，间隔2000ms：</p><pre><code class="bash">hadoop@hzbxs-bigdata16:~$ jstat -gc  40759 2000 5 Warning: Unresolved Symbol: sun.gc.generation.2.space.0.capacity substituted NaNWarning: Unresolved Symbol: sun.gc.generation.2.space.0.used substituted NaN S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT   512.0  512.0   0.0   128.0  18432.0   3045.8   149504.0   90560.0     �      �      2433   12.128   5      0.475   12.603512.0  512.0   0.0   128.0  18432.0   3045.8   149504.0   90560.0     �      �      2433   12.128   5      0.475   12.603512.0  512.0   0.0   128.0  18432.0   3045.8   149504.0   90560.0     �      �      2433   12.128   5      0.475   12.603512.0  512.0   0.0   128.0  18432.0   3045.8   149504.0   90560.0     �      �      2433   12.128   5      0.475   12.603512.0  512.0   0.0   128.0  18432.0   3050.5   149504.0   90560.0     �      �      2433   12.128   5      0.475   12.603</code></pre><p>主要选项比较多，出了上边的-gc，下边再介绍 -gcutil，输出的内容和-gc基本相同，但是主要关注空间占用全部空间的总百分比。如下：</p><pre><code class="bash">hadoop@hzbxs-bigdata16:~$ jstat -gcutil  40759 2000 5 Warning: Unresolved Symbol: sun.gc.generation.2.space.0.capacity substituted NaNWarning: Unresolved Symbol: sun.gc.generation.2.space.0.used substituted NaNWarning: Unresolved Symbol: sun.gc.generation.2.space.0.capacity substituted NaN  S0     S1     E      O         P     YGC     YGCT    FGC    FGCT     GCT    31.25   0.00  43.46  60.57      �   2428   12.108     5    0.475   12.582 31.25   0.00  43.46  60.57      �   2428   12.108     5    0.475   12.582 31.25   0.00  43.46  60.57      �   2428   12.108     5    0.475   12.582 31.25   0.00  43.46  60.57      �   2428   12.108     5    0.475   12.582 31.25   0.00  43.46  60.57      �   2428   12.108     5    0.475   12.582</code></pre><p>各区含义详见书的前几章：S0 S1 代表两个Survivor区，E代表Eden区（新生代），O代表Old区（老年代）,P代表（永久代），YGC(Minor GC,Young GC发生次数），YGCT（耗时）,FGC(Full GC发生次数），FGCT（耗时），GCT（GC 总耗时）</p><h3 id="jinfo"><a href="#jinfo" class="headerlink" title="jinfo"></a><strong>jinfo</strong></h3><p> 用于是实时查看和修改虚拟机各项参数。感觉不好用，简单Mark算了：</p><pre><code class="bash">hadoop@hzbxs-bigdata16:~$ jinfo -flag CMSInitiatingOccupancyFraction 40759-XX:CMSInitiatingOccupancyFraction=-1</code></pre><h3 id="jmap"><a href="#jmap" class="headerlink" title="jmap"></a><strong>jmap</strong></h3><p>用于生成堆转储快照（也就是Heapdump文件）<br>下边仅介绍常用的-dump参数：</p><pre><code class="bash">hadoop@hzbxs-bigdata16:~$ jmap -dump:file=mydump.bin,format=b 40759Dumping heap to /home/hadoop/mydump.bin ...Heap dump file createdhadoop@hzbxs-bigdata16:~$ ls mydump.bin mydump.bin</code></pre><p>导出bin文件，用 内存分析工具打开，可以看到非常详尽的信息。工具可以去eclipse官网下载（Eclipse  Memory Analyzer）,可以下载插件模式或者是独立软件模式，建议后者。</p><p><img src="http://upload-images.jianshu.io/upload_images/2651681-900f13ddfe2337f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="image.png"></p><h3 id="jstack"><a href="#jstack" class="headerlink" title="jstack"></a><strong>jstack</strong></h3><p>  用于生成虚拟机当前时刻的线程堆栈信息。这个工具是定位线程死锁、死循环等等各种卡顿问题的利器。使用非常简单，如下：</p><pre><code class="bash">hadoop@hzbxs-bigdata16:~$ jstack 21024 &gt;&gt; mystack.log</code></pre><p>将jstack的输出重定向到我的文件mystack.log，然后就随意看，less、vim、notepad任君选择。如下：</p><pre><code class="bash">2017-06-18 16:17:42Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.72-b15 mixed mode):&quot;Attach Listener&quot; #96 daemon prio=9 os_prio=0 tid=0x0000000000f96000 nid=0xd25b waiting on condition [0x0000000000000000]   java.lang.Thread.State: RUNNABLE&quot;257026550@qtp-1033304734-10&quot; #90 prio=5 os_prio=0 tid=0x00007fbfba139800 nid=0x8624 in Object.wait() [0x00007fbfb729a000]   java.lang.Thread.State: TIMED_WAITING (on object monitor)        at java.lang.Object.wait(Native Method)        at org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:626)        - locked &lt;0x00000006c7ce6b80&gt; (a org.mortbay.thread.QueuedThreadPool$PoolThread)&quot;pool-1-thread-5&quot; #43 prio=5 os_prio=0 tid=0x00007fbfb9d94800 nid=0x5d0a waiting on condition [0x00007fbfb6591000]   java.lang.Thread.State: WAITING (parking)        at sun.misc.Unsafe.park(Native Method)        - parking to wait for  &lt;0x00000006c01cdcc0&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at java.lang.Thread.run(Thread.java:745)</code></pre><p>除了以上几个常用的命令工具，还有两个非常强大的可视化工具，分别是JConsole 和 VisualVM. 这两个工具很强大很简单，有时间再学。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM </tag>
            
            <tag> 性能分析 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
